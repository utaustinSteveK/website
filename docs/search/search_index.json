{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NetIntel-OCR v0.1.18.1","text":""},{"location":"#enterprise-document-intelligence-platform-with-complete-feature-parity","title":"Enterprise Document Intelligence Platform with Complete Feature Parity","text":"<p>NetIntel-OCR v0.1.18.1 is a comprehensive enterprise platform that transforms unstructured technical documentation into structured, searchable knowledge. This release achieves 100% feature parity between CLI and API v2, includes a complete test framework, and delivers production-ready document intelligence capabilities for building Semantic Configuration Management Databases (CMDB).</p>"},{"location":"#project-goal","title":"Project Goal","text":"<p>Create an intelligent document processing platform that achieves 94% accuracy through sophisticated Hybrid Knowledge GraphRAG capabilities, extracting network architectures, security configurations, and operational workflows from enterprise documentation to populate a Semantic CMDB.</p>"},{"location":"#performance-objectives","title":"Performance Objectives","text":"<p>The system strives to achieve Knowledge GraphRAG accuracy and performance outcomes using sophisticated hybrid capabilities:</p> Metric Traditional NetIntel-OCR Hybrid KG Improvement Accuracy 62% 94% +52% Query Speed 2.3-8.7s 180-410ms 5-20x faster Storage Efficiency 20 GB 11.3 GB 43.5% savings Dependency Analysis 2.3s 180ms 12.8x faster Compliance Check 5.1s 290ms 17.6x faster Incident Correlation 8.7s 410ms 21.2x faster <p>By combining graph traversal, vector similarity, and knowledge graph embeddings, NetIntel-OCR delivers enterprise-grade accuracy with sub-second response times.</p>"},{"location":"#key-use-cases","title":"Key Use Cases","text":""},{"location":"#network-domain","title":"Network Domain","text":"<ul> <li>Architecture Discovery: Extract network topologies from design documents</li> <li>Configuration Mapping: Parse firewall rules and routing configurations</li> <li>Dependency Analysis: Identify component relationships and data flows</li> <li>Change Impact: Track architecture evolution across document versions</li> </ul>"},{"location":"#security-domain","title":"Security Domain","text":"<ul> <li>Zone Identification: Detect DMZ, trust boundaries, and security zones</li> <li>Compliance Mapping: Extract security controls and policy implementations</li> <li>Risk Assessment: Identify exposed services and attack surfaces</li> <li>Audit Trail: Document security architecture decisions and rationale</li> </ul>"},{"location":"#whats-new-in-v01181","title":"\ud83c\udd95 What's New in v0.1.18.1","text":""},{"location":"#complete-feature-parity","title":"Complete Feature Parity","text":"<ul> <li>100% CLI-API Parity: All 30+ CLI options now available in API v2</li> <li>Multi-Model Support: Complete implementation of <code>--model</code>, <code>--network-model</code>, <code>--flow-model</code></li> <li>Enhanced Processing: All diagram, table, and vector options fully supported</li> <li>Milvus Default: Vector operations now default to Milvus instead of LanceDB</li> </ul>"},{"location":"#comprehensive-test-framework","title":"Comprehensive Test Framework","text":"<ul> <li>Docker Compose Environment: Complete containerized testing infrastructure</li> <li>Test Categories: Unit, integration, system, performance, and regression testing</li> <li>Quality Metrics: Code coverage, complexity analysis, security scoring</li> <li>CI/CD Integration: GitHub Actions with matrix testing across Python versions</li> <li>Real PDF Fixtures: Integration testing with actual technical documents</li> </ul>"},{"location":"#api-v2-enhancements-from-v01180","title":"API v2 Enhancements (from v0.1.18.0)","text":"<ul> <li>RESTful API: Complete <code>/api/v2</code> endpoints with full feature support</li> <li>GraphQL Support: Full schema with queries, mutations, and subscriptions</li> <li>WebSocket: Real-time updates for document processing and search results</li> <li>Streaming Upload: Chunked upload for files up to 5GB with resume capability</li> </ul>"},{"location":"#mcp-model-context-protocol-integration","title":"MCP (Model Context Protocol) Integration","text":"<ul> <li>15 MCP Tools: Document operations, Milvus management, Knowledge Graph queries</li> <li>6 Interactive Resources: Document explorer, topology visualizer, KG explorer</li> <li>5 Contextual Prompts: Analysis, synthesis, troubleshooting, security audit</li> <li>LLM-Ready: Seamless integration with Claude, ChatGPT, and other AI assistants</li> </ul>"},{"location":"#milvus-vector-database","title":"Milvus Vector Database","text":"<ul> <li>Collection Management: Full CRUD operations with dynamic schemas</li> <li>Advanced Search: Vector, hybrid, and expression-based queries</li> <li>Result Reranking: Cross-encoder, feature-based, and RRF strategies</li> <li>Index Optimization: IVF_FLAT, IVF_SQ8, HNSW, and more</li> </ul>"},{"location":"#enterprise-features","title":"Enterprise Features","text":"<ul> <li>Deduplication: MD5, SimHash, and CDC-based duplicate detection</li> <li>Performance Monitoring: Real-time metrics and benchmarking</li> <li>Batch Processing: Parallel processing with checkpoint/resume</li> <li>Module Management: Dynamic module configuration and optimization</li> <li>Configuration Templates: Pre-defined profiles for different deployments</li> </ul>"},{"location":"#production-ready","title":"Production Ready","text":"<ul> <li>OAuth2/OIDC: Enterprise authentication with JWT tokens</li> <li>RBAC System: Full role-based access control</li> <li>Multi-tier Caching: Memory, Redis, and hybrid caching</li> <li>Rate Limiting: Multiple strategies for API protection</li> <li>Health Monitoring: Comprehensive health checks and metrics</li> <li>Audit Logging: Complete audit trail for compliance</li> <li>Distributed Tracing: OpenTelemetry support</li> </ul>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#intelligent-detection","title":"\ud83c\udfaf Intelligent Detection","text":"<ul> <li>Network diagram recognition with 90%+ accuracy</li> <li>Flow chart and process diagram extraction</li> <li>Multi-diagram page processing</li> <li>Context-aware interpretation using surrounding text</li> </ul>"},{"location":"#mermaid-generation","title":"\ud83d\udd04 Mermaid Generation","text":"<ul> <li>Automatic conversion to Mermaid.js syntax</li> <li>Syntax validation and auto-correction</li> <li>Support for complex network topologies</li> <li>Preserves component relationships</li> </ul>"},{"location":"#context-extraction","title":"\ud83e\udde0 Context Extraction","text":"<ul> <li>Analyzes diagrams with document context</li> <li>Identifies critical components and data flows</li> <li>Provides security analysis and recommendations</li> <li>Generates architecture summaries</li> </ul>"},{"location":"#vector-search","title":"\ud83d\udd0d Vector Search","text":"<ul> <li>Semantic search across processed documents</li> <li>Milvus integration for scalable retrieval</li> <li>Component and relationship queries</li> <li>Cross-document knowledge linking</li> </ul>"},{"location":"#knowledge-graph-v0117","title":"\ud83d\udd78\ufe0f Knowledge Graph (v0.1.17)","text":"<ul> <li>Automatic entity and relationship extraction</li> <li>FalkorDB graph storage with PyKEEN embeddings</li> <li>8 embedding models (TransE, RotatE, ComplEx, etc.)</li> <li>Hybrid retrieval combining graph and vector search</li> <li>Query intent classification for optimal routing</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph TB\n    PDF[PDF Documents] --&gt; OCR[OCR Engine]\n    OCR --&gt; Detection[Diagram Detection]\n    Detection --&gt; Network[Network Processor]\n    Detection --&gt; Flow[Flow Processor]\n    Network --&gt; Mermaid[Mermaid Generator]\n    Flow --&gt; Mermaid\n    Mermaid --&gt; Context[Context Extractor]\n    Context --&gt; KG[Knowledge Graph]\n    Context --&gt; Vector[Vector Store]\n    KG --&gt; FalkorDB[FalkorDB Storage]\n    KG --&gt; Embeddings[PyKEEN Embeddings]\n    Vector --&gt; CMDB[Semantic CMDB]\n    FalkorDB --&gt; CMDB\n    Embeddings --&gt; CMDB</code></pre>"},{"location":"#whats-new-in-v01171","title":"What's New in v0.1.17.1","text":""},{"location":"#modular-installation","title":"\ud83c\udfaf Modular Installation","text":"<ul> <li>Reduced base size: From 2.5GB to just 500MB</li> <li>Choose your features: Install only what you need</li> <li>7 optional modules: kg, vector, api, mcp, performance, dev</li> <li>Quick install: <code>pip install netintel-ocr[kg]</code> for Knowledge Graph</li> </ul>"},{"location":"#enhanced-version-display","title":"\ud83d\udcca Enhanced Version Display","text":"<ul> <li>Complete visibility: See all installed and available modules</li> <li>Real-time status: Check service connections instantly</li> <li>Installation hints: Get exact commands for missing features</li> <li>JSON output: Programmatic access to version info</li> </ul> <pre><code># Check what's installed and available\nnetintel-ocr --version\n\n# Output shows:\n# \u2713 Installed modules with versions\n# \u2717 Available modules with install commands\n# \u2713 Active service connections\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#quick-installation","title":"Quick Installation","text":"<pre><code># Choose your installation:\n\n# Option 1: Minimal (500MB) - Core OCR only\npip install netintel-ocr\n\n# Option 2: With Knowledge Graph (2GB) - Recommended\npip install \"netintel-ocr[kg]\"\n\n# Option 3: Production (2.3GB) - KG + Vector + API\npip install \"netintel-ocr[production]\"\n\n# Option 4: Everything (2.5GB)\npip install \"netintel-ocr[all]\"\n</code></pre>"},{"location":"#processing-documents","title":"Processing Documents","text":"<p>NetIntel-OCR v0.1.17+ uses a hierarchical CLI structure:</p> <pre><code># Process network architecture document (v0.1.17+ syntax)\nnetintel-ocr process pdf network-architecture.pdf \\\n             --model Nanonets-OCR-s:latest \\\n             --network-model qwen2.5vl:7b\n</code></pre> <p>See the Quick Start Guide for installation and basic usage.</p>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#v01180-api-v2-enterprise-features","title":"\ud83c\udd95 v0.1.18.0 - API v2 &amp; Enterprise Features","text":""},{"location":"#core-api-integration","title":"Core API &amp; Integration","text":"<ul> <li>API v2 Complete Guide - Comprehensive RESTful API, GraphQL, WebSocket</li> <li>MCP Integration Guide - 15 tools, 6 resources, 5 prompts for LLM integration</li> <li>Milvus Vector Database Guide - Advanced vector operations &amp; search</li> <li>Enterprise Features Guide - Deduplication, monitoring, batch processing</li> </ul>"},{"location":"#security-production-coming-soon","title":"Security &amp; Production (Coming Soon)","text":"<ul> <li>Authentication &amp; Security Guide - OAuth2, RBAC, audit logging</li> <li>Production Deployment Guide - High availability, scaling, monitoring</li> <li>GraphQL API Guide - Schema, queries, mutations, subscriptions</li> <li>WebSocket Real-time Guide - Real-time updates &amp; notifications</li> </ul>"},{"location":"#core-guides","title":"Core Guides","text":"<ul> <li>Quick Start Guide - Installation and first steps</li> <li>Installation Guide - Detailed setup and configuration</li> <li>Knowledge Graph Guide - KG extraction and querying</li> <li>Deployment Guide - Docker and Kubernetes setup</li> <li>Customization Guide - Prompt engineering and tuning</li> <li>Configuration Guide - Complete configuration reference</li> <li>Migration Guide - Migrating to modular architecture</li> <li>CLI Reference - Complete CLI command reference</li> <li>Batch Processing Guide - Large-scale document processing</li> <li>MiniRAG Guide - RAG-powered question answering</li> <li>Multi-Model Guide - Using multiple AI models</li> <li>Performance Guide - Optimization and tuning</li> <li>Monitoring Guide - System monitoring and metrics</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>Ollama for LLM inference</li> <li>8GB+ RAM for processing</li> <li>GPU recommended for faster inference</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>Documentation: https://visionml.net/docs</li> <li>PyPI Package: https://pypi.org/project/netintel-ocr/</li> <li>GitHub: https://github.com/VisionMLNet/NetIntelOCR</li> <li>Discord Community: https://discord.gg/netintel-ocr</li> </ul>"},{"location":"api-v2-guide/","title":"API v2 Complete User Guide","text":""},{"location":"api-v2-guide/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.18.1 introduces API v2 with 100% feature parity to the CLI, providing enterprise-grade document intelligence capabilities through RESTful endpoints, GraphQL queries, and WebSocket real-time updates. All 30+ CLI options are now available programmatically!</p>"},{"location":"api-v2-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Getting Started</li> <li>Authentication</li> <li>Document Management</li> <li>Milvus Vector Operations</li> <li>Search and Query</li> <li>Knowledge Graph</li> <li>Enterprise Features</li> <li>GraphQL API</li> <li>WebSocket Real-time</li> <li>Error Handling</li> </ol>"},{"location":"api-v2-guide/#getting-started","title":"Getting Started","text":""},{"location":"api-v2-guide/#starting-the-api-server","title":"Starting the API Server","text":"<pre><code># Start the API server\nnetintel-ocr server api --port 8000\n\n# Start with authentication enabled\nnetintel-ocr server api --auth-enabled --port 8000\n\n# Start with all features\nnetintel-ocr server all --port 8000\n</code></pre>"},{"location":"api-v2-guide/#base-url","title":"Base URL","text":"<p>All API v2 endpoints are prefixed with <code>/api/v2</code>:</p> <pre><code>http://localhost:8000/api/v2\n</code></pre>"},{"location":"api-v2-guide/#health-check","title":"Health Check","text":"<pre><code># Check API health\ncurl http://localhost:8000/api/v2/health\n\n# Response\n{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.18.0\",\n  \"services\": {\n    \"milvus\": \"connected\",\n    \"falkordb\": \"connected\",\n    \"redis\": \"connected\",\n    \"ollama\": \"connected\"\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#authentication","title":"Authentication","text":""},{"location":"api-v2-guide/#oauth2-authentication","title":"OAuth2 Authentication","text":"<p>NetIntel-OCR supports OAuth2/OIDC authentication with JWT tokens.</p>"},{"location":"api-v2-guide/#login","title":"Login","text":"<pre><code># Login to get access token\ncurl -X POST http://localhost:8000/api/v2/auth/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"username\": \"admin\",\n    \"password\": \"your-password\"\n  }'\n\n# Response\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIs...\",\n  \"token_type\": \"Bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"refresh-token-here\"\n}\n</code></pre>"},{"location":"api-v2-guide/#using-the-token","title":"Using the Token","text":"<p>Include the token in the Authorization header for all subsequent requests:</p> <pre><code>curl http://localhost:8000/api/v2/documents \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIs...\"\n</code></pre>"},{"location":"api-v2-guide/#rbac-role-based-access-control","title":"RBAC (Role-Based Access Control)","text":"<p>The API supports different roles with varying permissions:</p> <ul> <li>admin: Full access to all endpoints</li> <li>analyst: Read/write access to documents and search</li> <li>viewer: Read-only access</li> <li>operator: System management access</li> </ul>"},{"location":"api-v2-guide/#complete-feature-parity-v01181","title":"\ud83c\udd95 Complete Feature Parity (v0.1.18.1)","text":""},{"location":"api-v2-guide/#all-cli-options-now-available-in-api","title":"All CLI Options Now Available in API","text":"<p>NetIntel-OCR v0.1.18.1 achieves 100% feature parity between CLI and API. Every single CLI option is now available through the API:</p> Feature Category CLI Options API Fields Status Multi-Model <code>--model</code>, <code>--network-model</code>, <code>--flow-model</code> \u2705 Complete 100% Processing 30+ options including all modes, extraction settings \u2705 Complete 100% Vector Milvus default, chunking strategies \u2705 Complete 100% Knowledge Graph Full KG extraction with embeddings \u2705 Complete 100%"},{"location":"api-v2-guide/#example-full-featured-document-upload","title":"Example: Full-Featured Document Upload","text":"<pre><code># Upload with ALL options (NEW in v0.1.18.1!)\ncurl -X POST http://localhost:8000/api/v2/documents/upload \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -F \"file=@document.pdf\" \\\n  -F 'options={\n    \"model\": \"nanonets-ocr-s\",\n    \"network_model\": \"qwen2.5vl\",\n    \"flow_model\": \"custom-flow\",\n    \"pages\": \"1-50\",\n    \"confidence\": 0.8,\n    \"fast_extraction\": true,\n    \"table_method\": \"hybrid\",\n    \"with_kg\": true,\n    \"vector_format\": \"milvus\",\n    \"chunk_strategy\": \"semantic\"\n  }'\n</code></pre>"},{"location":"api-v2-guide/#document-management","title":"Document Management","text":""},{"location":"api-v2-guide/#upload-document","title":"Upload Document","text":""},{"location":"api-v2-guide/#standard-upload-with-multi-model-support","title":"Standard Upload with Multi-Model Support","text":"<pre><code># Upload a PDF document with multi-model configuration\ncurl -X POST http://localhost:8000/api/v2/documents/upload \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -F \"file=@document.pdf\" \\\n  -F 'options={\n    \"model\": \"nanonets-ocr-s\",\n    \"network_model\": \"qwen2.5vl\",\n    \"extract_tables\": true,\n    \"with_kg\": true,\n    \"vector_format\": \"milvus\"\n  }'\n\n# Response\n{\n  \"document_id\": \"doc_123456\",\n  \"status\": \"processing\",\n  \"filename\": \"document.pdf\",\n  \"size\": 5242880,\n  \"pages\": 50,\n  \"processing_options\": {\n    \"ocr_enabled\": true,\n    \"kg_enabled\": true,\n    \"vector_enabled\": true\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#streaming-upload-large-files","title":"Streaming Upload (Large Files)","text":"<p>For files larger than 100MB, use streaming upload:</p> <pre><code>import requests\nimport os\n\n# Initialize streaming session\ndef init_streaming_upload(filename, file_size):\n    response = requests.post(\n        \"http://localhost:8000/api/v2/documents/upload/stream/init\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        json={\n            \"filename\": filename,\n            \"file_size\": file_size,\n            \"chunk_size\": 5 * 1024 * 1024  # 5MB chunks\n        }\n    )\n    return response.json()[\"session_id\"]\n\n# Upload chunks\ndef upload_chunk(session_id, chunk_number, chunk_data):\n    response = requests.post(\n        f\"http://localhost:8000/api/v2/documents/upload/stream/{session_id}/chunk\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        files={\"chunk\": chunk_data},\n        data={\"chunk_number\": chunk_number}\n    )\n    return response.json()\n\n# Complete upload\ndef complete_upload(session_id):\n    response = requests.post(\n        f\"http://localhost:8000/api/v2/documents/upload/stream/{session_id}/complete\",\n        headers={\"Authorization\": f\"Bearer {token}\"}\n    )\n    return response.json()\n\n# Example usage\nfile_path = \"large_document.pdf\"\nfile_size = os.path.getsize(file_path)\nchunk_size = 5 * 1024 * 1024  # 5MB\n\nsession_id = init_streaming_upload(\"large_document.pdf\", file_size)\n\nwith open(file_path, 'rb') as f:\n    chunk_number = 0\n    while True:\n        chunk = f.read(chunk_size)\n        if not chunk:\n            break\n        upload_chunk(session_id, chunk_number, chunk)\n        chunk_number += 1\n\nresult = complete_upload(session_id)\nprint(f\"Document uploaded: {result['document_id']}\")\n</code></pre>"},{"location":"api-v2-guide/#document-versioning","title":"Document Versioning","text":"<pre><code># Get document versions\ncurl http://localhost:8000/api/v2/documents/doc_123456/versions \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Create a new version\ncurl -X POST http://localhost:8000/api/v2/documents/doc_123456/versions \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -F \"file=@updated_document.pdf\" \\\n  -d \"comment=Updated section 3\"\n\n# Compare versions\ncurl http://localhost:8000/api/v2/documents/doc_123456/versions/compare?v1=1&amp;v2=2 \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"api-v2-guide/#batch-processing","title":"Batch Processing","text":"<pre><code># Submit batch processing job\ncurl -X POST http://localhost:8000/api/v2/documents/batch \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input_path\": \"/data/documents/\",\n    \"output_path\": \"/data/processed/\",\n    \"parallel_workers\": 8,\n    \"processing_options\": {\n      \"enable_ocr\": true,\n      \"enable_kg\": true,\n      \"enable_vector\": true,\n      \"enable_dedup\": true\n    }\n  }'\n\n# Check batch status\ncurl http://localhost:8000/api/v2/batch/batch_123/progress \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"api-v2-guide/#milvus-vector-operations","title":"Milvus Vector Operations","text":""},{"location":"api-v2-guide/#collection-management","title":"Collection Management","text":"<pre><code># Create a collection\ncurl -X POST http://localhost:8000/api/v2/milvus/collections \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"collection_name\": \"documents\",\n    \"fields\": [\n      {\n        \"name\": \"id\",\n        \"type\": \"int64\",\n        \"is_primary\": true,\n        \"auto_id\": true\n      },\n      {\n        \"name\": \"embedding\",\n        \"type\": \"float_vector\",\n        \"dim\": 768\n      },\n      {\n        \"name\": \"content\",\n        \"type\": \"varchar\",\n        \"max_length\": 65535\n      }\n    ],\n    \"enable_dynamic_field\": true\n  }'\n\n# List collections\ncurl http://localhost:8000/api/v2/milvus/collections \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Get collection details\ncurl http://localhost:8000/api/v2/milvus/collections/documents \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Load collection into memory\ncurl -X POST http://localhost:8000/api/v2/milvus/collections/documents/load \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"api-v2-guide/#index-management","title":"Index Management","text":"<pre><code># Create index\ncurl -X POST http://localhost:8000/api/v2/milvus/collections/documents/indexes \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"field_name\": \"embedding\",\n    \"index_type\": \"IVF_FLAT\",\n    \"metric_type\": \"L2\",\n    \"params\": {\n      \"nlist\": 1024\n    }\n  }'\n\n# Check index building progress\ncurl http://localhost:8000/api/v2/milvus/collections/documents/indexes/embedding/progress \\\n  -H \"Authorization: Bearer $TOKEN\"\n</code></pre>"},{"location":"api-v2-guide/#vector-operations","title":"Vector Operations","text":"<pre><code># Insert vectors\ncurl -X POST http://localhost:8000/api/v2/milvus/collections/documents/insert \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"data\": [\n      {\n        \"embedding\": [0.1, 0.2, 0.3, ...],\n        \"content\": \"Document content here\",\n        \"metadata\": {\n          \"source\": \"document.pdf\",\n          \"page\": 1\n        }\n      }\n    ]\n  }'\n\n# Search vectors\ncurl -X POST http://localhost:8000/api/v2/milvus/collections/documents/search \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"vector\": [0.1, 0.2, 0.3, ...],\n    \"top_k\": 10,\n    \"filter\": \"page &gt; 0\",\n    \"output_fields\": [\"content\", \"metadata\"]\n  }'\n</code></pre>"},{"location":"api-v2-guide/#search-and-query","title":"Search and Query","text":""},{"location":"api-v2-guide/#advanced-search","title":"Advanced Search","text":"<pre><code># Advanced multi-field search\ncurl -X POST http://localhost:8000/api/v2/search/advanced \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"network security architecture\",\n    \"filters\": {\n      \"document_type\": [\"pdf\", \"docx\"],\n      \"date_range\": {\n        \"start\": \"2024-01-01\",\n        \"end\": \"2024-12-31\"\n      },\n      \"confidence_min\": 0.8\n    },\n    \"search_options\": {\n      \"enable_semantic\": true,\n      \"enable_kg\": true,\n      \"rerank_strategy\": \"cross_encoder\",\n      \"max_results\": 20\n    }\n  }'\n</code></pre>"},{"location":"api-v2-guide/#hybrid-search","title":"Hybrid Search","text":"<pre><code># Hybrid vector + keyword search\ncurl -X POST http://localhost:8000/api/v2/search/hybrid \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text_query\": \"firewall configuration\",\n    \"vector_query\": [0.1, 0.2, 0.3, ...],\n    \"alpha\": 0.7,\n    \"filters\": {\n      \"document_type\": \"network_diagram\"\n    },\n    \"top_k\": 15\n  }'\n</code></pre>"},{"location":"api-v2-guide/#result-reranking","title":"Result Reranking","text":"<p>The API supports multiple reranking strategies:</p> <pre><code># Search with reranking\ncurl -X POST http://localhost:8000/api/v2/search/similarity \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"VPN setup guide\",\n    \"rerank_config\": {\n      \"strategy\": \"cross_encoder\",\n      \"model\": \"ms-marco-MiniLM-L-12-v2\",\n      \"top_k\": 10\n    }\n  }'\n</code></pre> <p>Available reranking strategies: - <code>cross_encoder</code>: Cross-encoder neural reranking - <code>feature_based</code>: Feature-based scoring - <code>reciprocal_rank_fusion</code>: RRF for combining multiple rankings - <code>mmr</code>: Maximal Marginal Relevance for diversity</p>"},{"location":"api-v2-guide/#knowledge-graph","title":"Knowledge Graph","text":""},{"location":"api-v2-guide/#initialize-knowledge-graph","title":"Initialize Knowledge Graph","text":"<pre><code># Initialize FalkorDB\ncurl -X POST http://localhost:8000/api/v2/kg/initialize \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"graph_name\": \"netintel_kg\",\n    \"clear_existing\": false\n  }'\n</code></pre>"},{"location":"api-v2-guide/#cypher-queries","title":"Cypher Queries","text":"<pre><code># Execute Cypher query\ncurl -X POST http://localhost:8000/api/v2/kg/cypher \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"MATCH (n:NetworkDevice)-[r:CONNECTS_TO]-&gt;(m:NetworkDevice) WHERE n.type = \\\"firewall\\\" RETURN n, r, m LIMIT 10\"\n  }'\n</code></pre>"},{"location":"api-v2-guide/#hybrid-kg-search","title":"Hybrid KG Search","text":"<pre><code># Hybrid search with Knowledge Graph\ncurl -X POST http://localhost:8000/api/v2/kg/hybrid-search \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"Show me all security devices in DMZ\",\n    \"strategy\": \"adaptive\",\n    \"include_embeddings\": true,\n    \"max_hops\": 2\n  }'\n</code></pre>"},{"location":"api-v2-guide/#path-finding","title":"Path Finding","text":"<pre><code># Find paths between entities\ncurl -X POST http://localhost:8000/api/v2/kg/paths \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"start_entity\": \"firewall_01\",\n    \"end_entity\": \"database_server\",\n    \"max_length\": 5,\n    \"relationship_types\": [\"CONNECTS_TO\", \"ROUTES_THROUGH\"]\n  }'\n</code></pre>"},{"location":"api-v2-guide/#enterprise-features","title":"Enterprise Features","text":""},{"location":"api-v2-guide/#deduplication","title":"Deduplication","text":"<pre><code># Check for duplicates\ncurl -X POST http://localhost:8000/api/v2/deduplication/check \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"document_path\": \"/data/document.pdf\",\n    \"dedup_mode\": \"hybrid\",\n    \"simhash_bits\": 128,\n    \"hamming_threshold\": 5\n  }'\n\n# Find similar documents\ncurl -X POST http://localhost:8000/api/v2/deduplication/find-similar \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"document_id\": \"doc_123456\",\n    \"similarity_threshold\": 0.85,\n    \"include_cdc_analysis\": true,\n    \"limit\": 20\n  }'\n</code></pre>"},{"location":"api-v2-guide/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Get performance metrics\ncurl http://localhost:8000/api/v2/performance/metrics \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Run benchmark\ncurl -X POST http://localhost:8000/api/v2/performance/benchmark \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"test_type\": \"vector_search\",\n    \"dataset_size\": 10000,\n    \"iterations\": 5\n  }'\n</code></pre>"},{"location":"api-v2-guide/#module-management","title":"Module Management","text":"<pre><code># Get module status\ncurl http://localhost:8000/api/v2/modules/status \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Configure modules\ncurl -X POST http://localhost:8000/api/v2/modules/configure \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"enable_kg\": true,\n    \"enable_dedup\": true,\n    \"enable_c_extensions\": true,\n    \"vector_backend\": \"milvus\"\n  }'\n</code></pre>"},{"location":"api-v2-guide/#configuration-templates","title":"Configuration Templates","text":"<pre><code># Get available templates\ncurl http://localhost:8000/api/v2/config/templates \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Apply template\ncurl -X POST http://localhost:8000/api/v2/config/apply-template \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"template\": \"enterprise\",\n    \"customize\": {\n      \"max_workers\": 16,\n      \"cache_size\": \"10GB\"\n    }\n  }'\n</code></pre>"},{"location":"api-v2-guide/#graphql-api","title":"GraphQL API","text":""},{"location":"api-v2-guide/#graphql-endpoint","title":"GraphQL Endpoint","text":"<p>The GraphQL endpoint is available at: <pre><code>http://localhost:8000/api/v2/graphql\n</code></pre></p>"},{"location":"api-v2-guide/#query-examples","title":"Query Examples","text":"<pre><code># Search documents\nquery SearchDocuments {\n  searchDocuments(\n    query: \"network security\",\n    filters: {\n      documentType: [\"pdf\"],\n      dateRange: {\n        start: \"2024-01-01\",\n        end: \"2024-12-31\"\n      }\n    },\n    limit: 10\n  ) {\n    id\n    filename\n    content\n    metadata {\n      pages\n      size\n      processingTime\n    }\n    entities {\n      type\n      value\n      confidence\n    }\n  }\n}\n\n# Get document with versions\nquery GetDocument {\n  document(id: \"doc_123456\") {\n    id\n    filename\n    currentVersion\n    versions {\n      version\n      createdAt\n      comment\n      size\n    }\n    chunks {\n      id\n      content\n      embedding\n      metadata\n    }\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#mutations","title":"Mutations","text":"<pre><code># Process document\nmutation ProcessDocument {\n  processDocument(\n    file: \"document.pdf\",\n    options: {\n      enableOCR: true,\n      enableKG: true,\n      enableVector: true\n    }\n  ) {\n    documentId\n    status\n    estimatedTime\n  }\n}\n\n# Update document metadata\nmutation UpdateMetadata {\n  updateDocumentMetadata(\n    id: \"doc_123456\",\n    metadata: {\n      tags: [\"security\", \"network\"],\n      category: \"architecture\",\n      confidential: true\n    }\n  ) {\n    success\n    document {\n      id\n      metadata\n    }\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#subscriptions","title":"Subscriptions","text":"<pre><code># Subscribe to processing updates\nsubscription ProcessingUpdates {\n  documentProcessing(documentId: \"doc_123456\") {\n    status\n    progress\n    currentStep\n    errors\n    warnings\n  }\n}\n\n# Subscribe to search updates\nsubscription SearchUpdates {\n  searchResults(sessionId: \"search_789\") {\n    newResults {\n      id\n      content\n      score\n    }\n    totalFound\n    processingTime\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#websocket-real-time","title":"WebSocket Real-time","text":""},{"location":"api-v2-guide/#connecting-to-websocket","title":"Connecting to WebSocket","text":"<pre><code>// JavaScript WebSocket client\nconst ws = new WebSocket('ws://localhost:8000/api/v2/ws');\n\nws.onopen = () =&gt; {\n  console.log('Connected to WebSocket');\n\n  // Authenticate\n  ws.send(JSON.stringify({\n    type: 'auth',\n    token: 'your-jwt-token'\n  }));\n};\n\nws.onmessage = (event) =&gt; {\n  const message = JSON.parse(event.data);\n\n  switch(message.type) {\n    case 'processing_update':\n      console.log(`Processing: ${message.progress}%`);\n      break;\n    case 'search_result':\n      console.log(`Found: ${message.result}`);\n      break;\n    case 'error':\n      console.error(`Error: ${message.error}`);\n      break;\n  }\n};\n</code></pre>"},{"location":"api-v2-guide/#websocket-events","title":"WebSocket Events","text":"<p>Available WebSocket event types:</p> <ul> <li><code>processing_started</code>: Document processing started</li> <li><code>processing_progress</code>: Processing progress update</li> <li><code>processing_completed</code>: Processing completed</li> <li><code>processing_error</code>: Processing error occurred</li> <li><code>search_started</code>: Search initiated</li> <li><code>search_result</code>: New search result</li> <li><code>search_completed</code>: Search completed</li> <li><code>kg_update</code>: Knowledge graph updated</li> <li><code>vector_indexed</code>: Vectors indexed in Milvus</li> </ul>"},{"location":"api-v2-guide/#subscribing-to-events","title":"Subscribing to Events","text":"<pre><code>// Subscribe to specific document processing\nws.send(JSON.stringify({\n  type: 'subscribe',\n  channel: 'document',\n  documentId: 'doc_123456'\n}));\n\n// Subscribe to search results\nws.send(JSON.stringify({\n  type: 'subscribe',\n  channel: 'search',\n  searchId: 'search_789'\n}));\n\n// Unsubscribe\nws.send(JSON.stringify({\n  type: 'unsubscribe',\n  channel: 'document',\n  documentId: 'doc_123456'\n}));\n</code></pre>"},{"location":"api-v2-guide/#error-handling","title":"Error Handling","text":""},{"location":"api-v2-guide/#error-response-format","title":"Error Response Format","text":"<p>All API errors follow a consistent format:</p> <pre><code>{\n  \"error\": {\n    \"code\": \"ERR_2001\",\n    \"message\": \"Document not found\",\n    \"details\": {\n      \"document_id\": \"doc_123456\",\n      \"suggestion\": \"Check if the document ID is correct\"\n    },\n    \"timestamp\": \"2024-09-22T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>"},{"location":"api-v2-guide/#error-codes","title":"Error Codes","text":"Code Range Category Description ERR_1xxx Authentication Auth/permission errors ERR_2xxx Document Document processing errors ERR_3xxx Vector/Milvus Vector database errors ERR_4xxx Knowledge Graph KG operation errors ERR_5xxx Search Search/query errors ERR_6xxx System System/configuration errors"},{"location":"api-v2-guide/#common-error-codes","title":"Common Error Codes","text":"<ul> <li><code>ERR_1001</code>: Invalid authentication token</li> <li><code>ERR_1002</code>: Token expired</li> <li><code>ERR_1003</code>: Insufficient permissions</li> <li><code>ERR_2001</code>: Document not found</li> <li><code>ERR_2002</code>: Document processing failed</li> <li><code>ERR_2003</code>: Invalid document format</li> <li><code>ERR_3001</code>: Milvus connection failed</li> <li><code>ERR_3002</code>: Collection not found</li> <li><code>ERR_3003</code>: Vector dimension mismatch</li> <li><code>ERR_4001</code>: FalkorDB connection failed</li> <li><code>ERR_4002</code>: Invalid Cypher query</li> <li><code>ERR_5001</code>: Search query invalid</li> <li><code>ERR_5002</code>: No results found</li> <li><code>ERR_6001</code>: Service unavailable</li> <li><code>ERR_6002</code>: Rate limit exceeded</li> </ul>"},{"location":"api-v2-guide/#handling-errors-in-code","title":"Handling Errors in Code","text":"<pre><code>import requests\n\ndef safe_api_call(url, headers=None, json=None):\n    try:\n        response = requests.post(url, headers=headers, json=json)\n        response.raise_for_status()\n        return response.json()\n    except requests.exceptions.HTTPError as e:\n        if response.status_code == 401:\n            # Refresh token and retry\n            refresh_token()\n            return safe_api_call(url, headers, json)\n        elif response.status_code == 429:\n            # Rate limited, wait and retry\n            time.sleep(60)\n            return safe_api_call(url, headers, json)\n        else:\n            error_data = response.json().get('error', {})\n            print(f\"Error {error_data.get('code')}: {error_data.get('message')}\")\n            raise\n    except requests.exceptions.RequestException as e:\n        print(f\"Network error: {e}\")\n        raise\n</code></pre>"},{"location":"api-v2-guide/#rate-limiting","title":"Rate Limiting","text":"<p>The API implements multiple rate limiting strategies:</p>"},{"location":"api-v2-guide/#rate-limit-headers","title":"Rate Limit Headers","text":"<p>All responses include rate limit information:</p> <pre><code>X-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1695384000\nX-RateLimit-Strategy: sliding_window\n</code></pre>"},{"location":"api-v2-guide/#rate-limit-strategies","title":"Rate Limit Strategies","text":"<ol> <li>Fixed Window: Fixed time windows (e.g., 100 requests per minute)</li> <li>Sliding Window: Rolling time window</li> <li>Token Bucket: Burst capacity with refill rate</li> <li>Leaky Bucket: Smooth rate limiting</li> </ol>"},{"location":"api-v2-guide/#handling-rate-limits","title":"Handling Rate Limits","text":"<pre><code>def handle_rate_limit(response):\n    if response.status_code == 429:\n        reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n        wait_time = max(0, reset_time - time.time())\n        print(f\"Rate limited. Waiting {wait_time} seconds...\")\n        time.sleep(wait_time)\n        return True\n    return False\n</code></pre>"},{"location":"api-v2-guide/#best-practices","title":"Best Practices","text":""},{"location":"api-v2-guide/#1-use-batch-operations","title":"1. Use Batch Operations","text":"<p>Instead of individual requests, batch operations when possible:</p> <pre><code># Good: Batch insert\nvectors = [generate_embedding(doc) for doc in documents]\nresponse = api.insert_batch(vectors)\n\n# Avoid: Individual inserts\nfor doc in documents:\n    vector = generate_embedding(doc)\n    api.insert_single(vector)  # Multiple API calls\n</code></pre>"},{"location":"api-v2-guide/#2-implement-exponential-backoff","title":"2. Implement Exponential Backoff","text":"<pre><code>def exponential_backoff(func, max_retries=5):\n    for attempt in range(max_retries):\n        try:\n            return func()\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            wait_time = 2 ** attempt\n            time.sleep(wait_time)\n</code></pre>"},{"location":"api-v2-guide/#3-use-websocket-for-real-time-updates","title":"3. Use WebSocket for Real-time Updates","text":"<p>For long-running operations, use WebSocket instead of polling:</p> <pre><code># Good: WebSocket subscription\nws.subscribe('document', document_id)\n\n# Avoid: Polling\nwhile True:\n    status = api.get_status(document_id)\n    if status == 'completed':\n        break\n    time.sleep(5)  # Polling every 5 seconds\n</code></pre>"},{"location":"api-v2-guide/#4-cache-authentication-tokens","title":"4. Cache Authentication Tokens","text":"<pre><code>class APIClient:\n    def __init__(self):\n        self._token = None\n        self._token_expiry = 0\n\n    def get_token(self):\n        if time.time() &gt;= self._token_expiry:\n            self._refresh_token()\n        return self._token\n\n    def _refresh_token(self):\n        response = self.login()\n        self._token = response['access_token']\n        self._token_expiry = time.time() + response['expires_in'] - 60\n</code></pre>"},{"location":"api-v2-guide/#5-use-appropriate-search-strategy","title":"5. Use Appropriate Search Strategy","text":"<p>Choose the right search strategy based on your use case:</p> <ul> <li>Vector Search: For semantic similarity</li> <li>Keyword Search: For exact matches</li> <li>Hybrid Search: For best of both worlds</li> <li>Knowledge Graph: For relationship queries</li> </ul>"},{"location":"api-v2-guide/#examples-and-use-cases","title":"Examples and Use Cases","text":""},{"location":"api-v2-guide/#example-1-complete-document-processing-pipeline","title":"Example 1: Complete Document Processing Pipeline","text":"<pre><code>import asyncio\nimport aiohttp\n\nasync def process_document_pipeline(file_path):\n    async with aiohttp.ClientSession() as session:\n        # 1. Upload document\n        with open(file_path, 'rb') as f:\n            data = aiohttp.FormData()\n            data.add_field('file', f, filename='document.pdf')\n            data.add_field('enable_ocr', 'true')\n            data.add_field('enable_kg', 'true')\n            data.add_field('enable_vector', 'true')\n\n            async with session.post(\n                'http://localhost:8000/api/v2/documents/upload',\n                headers={'Authorization': f'Bearer {token}'},\n                data=data\n            ) as resp:\n                result = await resp.json()\n                document_id = result['document_id']\n\n        # 2. Monitor processing via WebSocket\n        async with session.ws_connect('ws://localhost:8000/api/v2/ws') as ws:\n            await ws.send_json({'type': 'auth', 'token': token})\n            await ws.send_json({\n                'type': 'subscribe',\n                'channel': 'document',\n                'documentId': document_id\n            })\n\n            async for msg in ws:\n                if msg.type == aiohttp.WSMsgType.TEXT:\n                    data = msg.json()\n                    if data['type'] == 'processing_completed':\n                        break\n                    print(f\"Progress: {data.get('progress', 0)}%\")\n\n        # 3. Search the processed document\n        async with session.post(\n            'http://localhost:8000/api/v2/search/advanced',\n            headers={'Authorization': f'Bearer {token}'},\n            json={\n                'query': 'network architecture',\n                'filters': {'document_id': document_id},\n                'search_options': {\n                    'enable_semantic': True,\n                    'enable_kg': True\n                }\n            }\n        ) as resp:\n            search_results = await resp.json()\n\n        return search_results\n\n# Run the pipeline\nresults = asyncio.run(process_document_pipeline('document.pdf'))\n</code></pre>"},{"location":"api-v2-guide/#example-2-knowledge-graph-analysis","title":"Example 2: Knowledge Graph Analysis","text":"<pre><code>def analyze_network_topology(api_client):\n    # 1. Initialize KG if needed\n    api_client.kg_initialize(graph_name='network_topology')\n\n    # 2. Find all critical paths\n    critical_paths = api_client.kg_cypher(\n        \"\"\"\n        MATCH p = (s:Server)-[*]-&gt;(d:Database)\n        WHERE s.critical = true AND d.sensitive = true\n        RETURN p\n        ORDER BY length(p)\n        LIMIT 10\n        \"\"\"\n    )\n\n    # 3. Identify security vulnerabilities\n    vulnerabilities = api_client.kg_cypher(\n        \"\"\"\n        MATCH (n:NetworkDevice)\n        WHERE NOT (n)-[:PROTECTED_BY]-&gt;(:Firewall)\n        RETURN n.name, n.type, n.ip_address\n        \"\"\"\n    )\n\n    # 4. Find single points of failure\n    spof = api_client.kg_cypher(\n        \"\"\"\n        MATCH (n:NetworkDevice)\n        WHERE size((n)-[:CONNECTS_TO]-()) &gt; 5\n        AND NOT exists(n.redundancy)\n        RETURN n\n        \"\"\"\n    )\n\n    return {\n        'critical_paths': critical_paths,\n        'vulnerabilities': vulnerabilities,\n        'single_points_of_failure': spof\n    }\n</code></pre>"},{"location":"api-v2-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-v2-guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"api-v2-guide/#1-milvus-connection-failed","title":"1. Milvus Connection Failed","text":"<pre><code># Check Milvus status\ncurl http://localhost:8000/api/v2/health/dependencies\n\n# Solution: Ensure Milvus is running\ndocker run -d --name milvus \\\n  -p 19530:19530 \\\n  -p 9091:9091 \\\n  milvusdb/milvus:latest\n</code></pre>"},{"location":"api-v2-guide/#2-authentication-issues","title":"2. Authentication Issues","text":"<pre><code># Test authentication\ncurl -X POST http://localhost:8000/api/v2/auth/verify \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Solution: Refresh token if expired\ncurl -X POST http://localhost:8000/api/v2/auth/refresh \\\n  -d \"refresh_token=$REFRESH_TOKEN\"\n</code></pre>"},{"location":"api-v2-guide/#3-slow-search-performance","title":"3. Slow Search Performance","text":"<pre><code># Optimize search with proper indexing\napi_client.create_index(\n    collection='documents',\n    field='embedding',\n    index_type='IVF_SQ8',  # Use for large datasets\n    params={'nlist': 2048}\n)\n\n# Use filters to reduce search space\nresults = api_client.search(\n    query='security',\n    filters='date &gt;= \"2024-01-01\" AND type == \"network_diagram\"',\n    top_k=10\n)\n</code></pre>"},{"location":"api-v2-guide/#performance-optimization","title":"Performance Optimization","text":""},{"location":"api-v2-guide/#1-caching-configuration","title":"1. Caching Configuration","text":"<p>Configure multi-tier caching for better performance:</p> <pre><code># config.yml\ncache:\n  memory:\n    enabled: true\n    size: 1GB\n    ttl: 3600\n  redis:\n    enabled: true\n    host: localhost\n    port: 6379\n    ttl: 86400\n  strategy: hybrid  # memory -&gt; redis -&gt; source\n</code></pre>"},{"location":"api-v2-guide/#2-connection-pooling","title":"2. Connection Pooling","text":"<pre><code># Use connection pooling for better performance\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry\n\nsession = requests.Session()\nretry = Retry(total=3, backoff_factor=0.3)\nadapter = HTTPAdapter(max_retries=retry, pool_connections=10, pool_maxsize=10)\nsession.mount('http://', adapter)\nsession.mount('https://', adapter)\n</code></pre>"},{"location":"api-v2-guide/#3-batch-processing-settings","title":"3. Batch Processing Settings","text":"<pre><code># Optimal batch settings for large datasets\ncurl -X POST http://localhost:8000/api/v2/documents/batch \\\n  -d '{\n    \"parallel_workers\": 16,\n    \"batch_size\": 100,\n    \"checkpoint_interval\": 500,\n    \"memory_limit\": \"8GB\"\n  }'\n</code></pre>"},{"location":"api-v2-guide/#security-best-practices","title":"Security Best Practices","text":""},{"location":"api-v2-guide/#1-api-key-rotation","title":"1. API Key Rotation","text":"<p>Regularly rotate API keys and tokens:</p> <pre><code>def rotate_api_key():\n    # Generate new API key\n    new_key = api_client.generate_api_key()\n\n    # Update applications\n    update_application_configs(new_key)\n\n    # Revoke old key after grace period\n    schedule_revocation(old_key, delay_hours=24)\n</code></pre>"},{"location":"api-v2-guide/#2-request-signing","title":"2. Request Signing","text":"<p>Sign sensitive requests:</p> <pre><code>import hmac\nimport hashlib\n\ndef sign_request(payload, secret):\n    message = json.dumps(payload, sort_keys=True)\n    signature = hmac.new(\n        secret.encode(),\n        message.encode(),\n        hashlib.sha256\n    ).hexdigest()\n    return signature\n</code></pre>"},{"location":"api-v2-guide/#3-audit-logging","title":"3. Audit Logging","text":"<p>Enable comprehensive audit logging:</p> <pre><code># Configure audit logging\ncurl -X POST http://localhost:8000/api/v2/admin/audit/configure \\\n  -d '{\n    \"enabled\": true,\n    \"log_level\": \"detailed\",\n    \"include_request_body\": true,\n    \"include_response_body\": false,\n    \"retention_days\": 90\n  }'\n</code></pre>"},{"location":"api-v2-guide/#next-steps","title":"Next Steps","text":"<ol> <li>Explore MCP Integration: See the MCP Integration Guide</li> <li>Learn about Milvus: Read the Milvus Vector Database Guide</li> <li>Deploy to Production: Follow the Production Deployment Guide</li> <li>Configure Authentication: See the Authentication &amp; Security Guide</li> </ol>"},{"location":"api-v2-guide/#api-reference","title":"API Reference","text":"<p>For complete API reference documentation, visit: - Swagger UI: http://localhost:8000/docs - ReDoc: http://localhost:8000/redoc - OpenAPI Schema: http://localhost:8000/openapi.json</p>"},{"location":"api/","title":"API Integration Guide","text":""},{"location":"api/#rest-api-server","title":"REST API Server","text":"<p>NetIntel-OCR provides a REST API for programmatic document processing and integration with external systems.</p>"},{"location":"api/#starting-the-api-server","title":"Starting the API Server","text":"<pre><code># Start API server on port 8000\nnetintel-ocr server api\n\n# Custom port and host\nnetintel-ocr server api --port 8080 --host 0.0.0.0\n\n# With authentication\nnetintel-ocr server api --api-key YOUR_SECRET_KEY\n</code></pre>"},{"location":"api/#docker-api-mode","title":"Docker API Mode","text":"<pre><code>docker run -p 8000:8000 \\\n  -e API_KEY=your-secret-key \\\n  netintel-ocr:latest --api\n</code></pre>"},{"location":"api/#api-endpoints","title":"API Endpoints","text":""},{"location":"api/#health-check","title":"Health Check","text":"<pre><code>GET /health\n\nResponse:\n{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.16.15\",\n  \"models_available\": [\"qwen2.5vl:7b\", \"Nanonets-OCR-s:latest\"],\n  \"milvus_connected\": true\n}\n</code></pre>"},{"location":"api/#process-document","title":"Process Document","text":"<pre><code>POST /process\nContent-Type: multipart/form-data\n\nParameters:\n- file: PDF file (required)\n- model: OCR model (optional)\n- network_model: Network diagram model (optional)\n- start_page: Starting page (optional)\n- end_page: Ending page (optional)\n- confidence_threshold: Detection threshold (optional)\n\nResponse:\n{\n  \"job_id\": \"uuid-12345\",\n  \"status\": \"processing\",\n  \"estimated_time\": 45\n}\n</code></pre>"},{"location":"api/#get-job-status","title":"Get Job Status","text":"<pre><code>GET /status/{job_id}\n\nResponse:\n{\n  \"job_id\": \"uuid-12345\",\n  \"status\": \"completed\",\n  \"progress\": 100,\n  \"pages_processed\": 10,\n  \"diagrams_found\": 3\n}\n</code></pre>"},{"location":"api/#get-results","title":"Get Results","text":"<pre><code>GET /results/{job_id}\n\nResponse:\n{\n  \"job_id\": \"uuid-12345\",\n  \"pages\": [\n    {\n      \"page_number\": 1,\n      \"type\": \"text\",\n      \"content\": \"...\"\n    },\n    {\n      \"page_number\": 2,\n      \"type\": \"network_diagram\",\n      \"mermaid\": \"graph TB...\",\n      \"components\": [...],\n      \"context\": {...}\n    }\n  ],\n  \"summary\": {...}\n}\n</code></pre>"},{"location":"api/#search-documents","title":"Search Documents","text":"<pre><code>POST /search\nContent-Type: application/json\n\n{\n  \"query\": \"firewall configuration\",\n  \"collection\": \"network_docs\",\n  \"limit\": 10,\n  \"filters\": {\n    \"document_type\": \"network\"\n  }\n}\n\nResponse:\n{\n  \"results\": [\n    {\n      \"document\": \"firewall-guide.pdf\",\n      \"page\": 5,\n      \"score\": 0.92,\n      \"content\": \"...\",\n      \"metadata\": {...}\n    }\n  ]\n}\n</code></pre>"},{"location":"api/#python-client","title":"Python Client","text":""},{"location":"api/#installation","title":"Installation","text":"<pre><code># Install client library\npip install netintel-ocr-client\n\n# Or install full package with client\npip install netintel-ocr[client]\n</code></pre> <p>Package Details</p> <p>Main package: https://pypi.org/project/netintel-ocr/</p> <p>Client library: https://pypi.org/project/netintel-ocr-client/</p>"},{"location":"api/#basic-usage","title":"Basic Usage","text":"<pre><code>from netintel_client import NetIntelClient\n\n# Initialize client\nclient = NetIntelClient(\n    host=\"http://localhost:8000\",\n    api_key=\"your-secret-key\"\n)\n\n# Process document\njob = client.process_document(\n    file_path=\"network-design.pdf\",\n    model=\"qwen2.5vl:7b\",\n    start_page=1,\n    end_page=10\n)\n\n# Wait for completion\nresult = client.wait_for_job(job.job_id)\n\n# Get results\npages = result.pages\ndiagrams = [p for p in pages if p.type == \"network_diagram\"]\n</code></pre>"},{"location":"api/#async-processing","title":"Async Processing","text":"<pre><code>import asyncio\nfrom netintel_client import AsyncNetIntelClient\n\nasync def process_documents():\n    client = AsyncNetIntelClient(\"http://localhost:8000\")\n\n    # Process multiple documents\n    jobs = []\n    for pdf in pdf_files:\n        job = await client.process_document(pdf)\n        jobs.append(job)\n\n    # Wait for all\n    results = await asyncio.gather(\n        *[client.wait_for_job(j.job_id) for j in jobs]\n    )\n\n    return results\n</code></pre>"},{"location":"api/#javascripttypescript-client","title":"JavaScript/TypeScript Client","text":""},{"location":"api/#installation_1","title":"Installation","text":"<pre><code>npm install netintel-ocr-client\n</code></pre>"},{"location":"api/#usage","title":"Usage","text":"<pre><code>const { NetIntelClient } = require('netintel-ocr-client');\n\nconst client = new NetIntelClient({\n  host: 'http://localhost:8000',\n  apiKey: 'your-secret-key'\n});\n\n// Process document\nconst job = await client.processDocument({\n  file: fileBuffer,\n  model: 'qwen2.5vl:7b'\n});\n\n// Get results\nconst result = await client.waitForJob(job.jobId);\nconsole.log(`Found ${result.diagramsFound} diagrams`);\n</code></pre>"},{"location":"api/#webhook-integration","title":"Webhook Integration","text":""},{"location":"api/#configure-webhooks","title":"Configure Webhooks","text":"<pre><code>POST /webhooks\nContent-Type: application/json\n\n{\n  \"url\": \"https://your-server.com/webhook\",\n  \"events\": [\"job.completed\", \"job.failed\"],\n  \"secret\": \"webhook-secret\"\n}\n</code></pre>"},{"location":"api/#webhook-payload","title":"Webhook Payload","text":"<pre><code>{\n  \"event\": \"job.completed\",\n  \"job_id\": \"uuid-12345\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"data\": {\n    \"pages_processed\": 10,\n    \"diagrams_found\": 3,\n    \"processing_time\": 45.2\n  }\n}\n</code></pre>"},{"location":"api/#rate-limiting","title":"Rate Limiting","text":"<p>Default limits: - 100 requests per minute per API key - 10 concurrent jobs per API key - 100MB max file size</p> <p>Configure custom limits:</p> <pre><code>netintel-ocr server api \\\n  --rate-limit 200 \\\n  --concurrent-jobs 20 \\\n  --max-file-size 500\n</code></pre>"},{"location":"api/#authentication","title":"Authentication","text":""},{"location":"api/#api-key-authentication","title":"API Key Authentication","text":"<pre><code># Set API key\nexport NETINTEL_API_KEY=your-secret-key\n\n# Or in request header\ncurl -H \"X-API-Key: your-secret-key\" \\\n  http://localhost:8000/process\n</code></pre>"},{"location":"api/#jwt-authentication","title":"JWT Authentication","text":"<pre><code># Get token\nPOST /auth/token\n{\n  \"username\": \"user\",\n  \"password\": \"pass\"\n}\n\n# Use token\ncurl -H \"Authorization: Bearer jwt-token\" \\\n  http://localhost:8000/process\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"INVALID_MODEL\",\n    \"message\": \"Model 'unknown-model' not found\",\n    \"details\": {\n      \"available_models\": [\"qwen2.5vl:7b\", \"llava:13b\"]\n    }\n  },\n  \"request_id\": \"req-12345\"\n}\n</code></pre>"},{"location":"api/#common-error-codes","title":"Common Error Codes","text":"Code Description Solution <code>INVALID_FILE</code> PDF file corrupt or invalid Verify PDF file <code>MODEL_NOT_FOUND</code> Requested model unavailable Check available models <code>RATE_LIMITED</code> Too many requests Retry after delay <code>PROCESSING_FAILED</code> Internal processing error Check logs <code>TIMEOUT</code> Processing timeout Reduce page range"},{"location":"api/#monitoring","title":"Monitoring","text":""},{"location":"api/#metrics-endpoint","title":"Metrics Endpoint","text":"<pre><code>GET /metrics\n\nResponse (Prometheus format):\nnetintel_requests_total{method=\"POST\",endpoint=\"/process\"} 1234\nnetintel_processing_duration_seconds{quantile=\"0.99\"} 45.2\nnetintel_active_jobs 5\n</code></pre>"},{"location":"api/#logging","title":"Logging","text":"<pre><code># Enable debug logging\nclient = NetIntelClient(\n    host=\"http://localhost:8000\",\n    log_level=\"DEBUG\"\n)\n</code></pre>"},{"location":"api/#next-steps","title":"Next Steps","text":"<ul> <li>MCP Server Guide - Model Context Protocol integration</li> <li>Batch Processing - Process multiple documents</li> <li>Deployment Guide - Production setup</li> </ul>"},{"location":"batch/","title":"Batch Processing Guide","text":"<p>New in v0.1.17: Hierarchical CLI</p> <p>NetIntel-OCR v0.1.17 introduces a hierarchical CLI structure. Batch processing is now under the <code>process batch</code> command group for better organization.</p>"},{"location":"batch/#overview","title":"Overview","text":"<p>NetIntel-OCR provides efficient batch processing capabilities for handling multiple documents with parallel processing, progress tracking, and centralized storage.</p>"},{"location":"batch/#basic-batch-processing","title":"Basic Batch Processing","text":""},{"location":"batch/#process-multiple-files","title":"Process Multiple Files","text":"<pre><code># Process all PDFs in directory\nnetintel-ocr process batch /path/to/pdfs/\n\n# Process with file pattern\nnetintel-ocr process batch /path/to/pdfs/ --pattern \"*.pdf\"\n\n# With specific model\nnetintel-ocr process batch /path/to/pdfs/ --model qwen2.5vl:7b\n\n# Recursive processing\nnetintel-ocr process batch /path/to/documents/ --recursive\n</code></pre>"},{"location":"batch/#parallel-processing","title":"Parallel Processing","text":"<pre><code># Process 4 documents simultaneously\nnetintel-ocr process batch /path/to/pdfs/ --parallel 4\n\n# Auto-detect optimal parallelism\nnetintel-ocr process batch /path/to/pdfs/ --auto-parallel\n\n# GPU parallel processing\nnetintel-ocr process batch /path/to/pdfs/ --gpu --parallel 2\n\n# Process from file list\necho \"doc1.pdf\\ndoc2.pdf\\ndoc3.pdf\" &gt; file_list.txt\nnetintel-ocr process batch file_list.txt\n</code></pre>"},{"location":"batch/#advanced-batch-features","title":"Advanced Batch Features","text":""},{"location":"batch/#batch-ingestion","title":"Batch Ingestion","text":"<pre><code># Ingest to vector store\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --collection network_docs \\\n  --parallel 4\n\n# With deduplication\nnetintel-ocr process batch /path/to/documents/ \\\n  --deduplicate \\\n  --collection unified_docs\n\n# Watch directory for new files\nnetintel-ocr process watch /input/folder \\\n  --pattern \"*.pdf\" \\\n  --collection live_docs\n</code></pre>"},{"location":"batch/#progress-tracking","title":"Progress Tracking","text":"<pre><code># Enable progress bar\nnetintel-ocr process batch /path/to/pdfs/ --progress\n\n# Save progress for resume\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --checkpoint batch-checkpoint.json \\\n  --resume-on-failure\n\n# Resume from checkpoint\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --resume-from batch-checkpoint.json\n</code></pre>"},{"location":"batch/#output-organization","title":"Output Organization","text":"<pre><code># Organize by document type\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --output-structure type \\\n  --output-dir processed/\n\n# Result:\n# processed/\n#   \u251c\u2500\u2500 network_diagrams/\n#   \u251c\u2500\u2500 flow_diagrams/\n#   \u2514\u2500\u2500 text_only/\n\n# Alternative output formats\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --output-dir results/ \\\n  --format json\n</code></pre>"},{"location":"batch/#batch-configuration","title":"Batch Configuration","text":""},{"location":"batch/#yaml-configuration","title":"YAML Configuration","text":"<pre><code># batch-config.yaml\nbatch:\n  max_parallel: 4\n  chunk_size: 10\n  resume_on_failure: true\n  checkpoint_file: batch-state.json\n\n  output:\n    structure: document  # or 'type', 'date'\n    dir: ./processed\n\n  models:\n    text: Nanonets-OCR-s:latest\n    network: qwen2.5vl:7b\n    flow: qwen2.5vl:7b\n\n  filters:\n    min_pages: 5\n    max_pages: 500\n    file_types: [pdf, png, jpg]\n\n  error_handling:\n    max_retries: 3\n    retry_delay: 5\n    skip_on_error: false\n</code></pre>"},{"location":"batch/#use-configuration","title":"Use Configuration","text":"<pre><code># Apply batch configuration\nnetintel-ocr process batch /path/to/pdfs/ --config batch-config.yaml\n\n# Or use config commands\nnetintel-ocr config set processing.max_parallel 4\nnetintel-ocr config set processing.chunk_size 10\nnetintel-ocr process batch /path/to/pdfs/\n</code></pre>"},{"location":"batch/#centralized-database","title":"Centralized Database","text":""},{"location":"batch/#merge-to-central-store","title":"Merge to Central Store","text":"<pre><code># Create centralized database\nnetintel-ocr db merge \\\n  --source-dir ./processed \\\n  --central-db ./central/unified.db\n\n# With metadata\nnetintel-ocr db merge \\\n  --add-metadata \"project=network-refresh\" \\\n  --add-metadata \"date=2024-01-15\" \\\n  ./processed/* ./central/unified.db\n</code></pre>"},{"location":"batch/#query-centralized-database","title":"Query Centralized Database","text":"<pre><code># Search across all documents\nnetintel-ocr db query \"firewall configuration\" \\\n  --db ./central/unified.db\n\n# Filter by metadata\nnetintel-ocr db query \"DMZ architecture\" \\\n  --db ./central/unified.db \\\n  --filter \"project=network-refresh\"\n\n# Export query results\nnetintel-ocr db query \"network topology\" \\\n  --format json &gt; results.json\n</code></pre>"},{"location":"batch/#cloud-storage-integration","title":"Cloud Storage Integration","text":""},{"location":"batch/#s3minio-support","title":"S3/MinIO Support","text":"<pre><code># Configure S3\nexport AWS_ACCESS_KEY_ID=your-key\nexport AWS_SECRET_ACCESS_KEY=your-secret\nexport S3_BUCKET=netintel-output\n\n# Process and upload to S3\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --output-s3 s3://netintel-output/processed/\n\n# Process from S3\nnetintel-ocr process batch s3://netintel-input/ \\\n  --pattern \"*.pdf\" \\\n  --output-s3 s3://netintel-output/\n</code></pre>"},{"location":"batch/#azure-blob-storage","title":"Azure Blob Storage","text":"<pre><code># Configure Azure\nexport AZURE_STORAGE_CONNECTION_STRING=your-connection-string\n\n# Process with Azure storage\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --storage-backend azure \\\n  --container processed-docs\n</code></pre>"},{"location":"batch/#performance-optimization","title":"Performance Optimization","text":""},{"location":"batch/#memory-management","title":"Memory Management","text":"<pre><code># Limit memory per process\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --max-memory 4GB \\\n  --parallel 2\n\n# Enable swap for large documents\nnetintel-ocr process batch /path/to/large-docs/ \\\n  --enable-swap \\\n  --swap-dir /tmp/netintel-swap\n</code></pre>"},{"location":"batch/#cpugpu-optimization","title":"CPU/GPU Optimization","text":"<pre><code># CPU-only batch processing\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --cpu-only \\\n  --parallel $(nproc)\n\n# Mixed CPU/GPU processing\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --gpu-for-models \"llava,qwen2.5vl\" \\\n  --cpu-for-models \"Nanonets-OCR-s\"\n</code></pre>"},{"location":"batch/#caching-strategy","title":"Caching Strategy","text":"<pre><code># Enable aggressive caching\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --cache-models \\\n  --cache-embeddings \\\n  --cache-dir /tmp/netintel-cache\n\n# Share cache across runs\nexport NETINTEL_CACHE_DIR=/shared/cache\nnetintel-ocr process batch /path/to/pdfs/ --use-cache\n</code></pre>"},{"location":"batch/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"batch/#real-time-monitoring","title":"Real-time Monitoring","text":"<pre><code># Enable metrics server\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --metrics-port 9090 \\\n  --progress-webhook http://monitor/progress\n\n# View metrics\ncurl http://localhost:9090/metrics\n\n# Use server monitoring\nnetintel-ocr server health\n</code></pre>"},{"location":"batch/#detailed-logging","title":"Detailed Logging","text":"<pre><code># Per-document logs\nnetintel-ocr --debug process batch /path/to/pdfs/ \\\n  --log-per-document \\\n  --log-dir ./logs\n\n# Structured logging\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --log-format json \\\n  --log-file batch.jsonl\n</code></pre>"},{"location":"batch/#error-handling","title":"Error Handling","text":""},{"location":"batch/#retry-logic","title":"Retry Logic","text":"<pre><code># Automatic retry with backoff\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --max-retries 3 \\\n  --retry-backoff exponential \\\n  --retry-delay 5\n</code></pre>"},{"location":"batch/#failed-document-handling","title":"Failed Document Handling","text":"<pre><code># Skip failed documents\nnetintel-ocr process batch /path/to/pdfs/ \\\n  --skip-on-error \\\n  --failed-list failed.txt\n\n# Reprocess failed documents\nnetintel-ocr process batch failed.txt \\\n  --max-retries 5\n</code></pre>"},{"location":"batch/#batch-scripts","title":"Batch Scripts","text":""},{"location":"batch/#shell-script-example","title":"Shell Script Example","text":"<pre><code>#!/bin/bash\n# batch-process.sh\n\nDOCS_DIR=\"/path/to/documents\"\nOUTPUT_DIR=\"/path/to/output\"\nFAILED_LIST=\"failed_docs.txt\"\n\n# Clear previous failures\n&gt; $FAILED_LIST\n\n# Process in chunks\nfind $DOCS_DIR -name \"*.pdf\" | while read -r file; do\n  netintel-ocr process pdf \"$file\" \\\n    --model qwen2.5vl:7b \\\n    --output-dir $OUTPUT_DIR || echo \"$file\" &gt;&gt; $FAILED_LIST\ndone\n\n# Retry failed documents\nif [ -s $FAILED_LIST ]; then\n  echo \"Retrying failed documents...\"\n  netintel-ocr process batch $FAILED_LIST \\\n    --model minicpm-v:latest\nfi\n</code></pre>"},{"location":"batch/#python-script-example","title":"Python Script Example","text":"<pre><code># batch_processor.py\nimport os\nfrom pathlib import Path\nfrom netintel_ocr import BatchProcessor\n\nprocessor = BatchProcessor(\n    max_parallel=4,\n    model=\"qwen2.5vl:7b\",\n    output_dir=\"./processed\"\n)\n\n# Process all PDFs\npdf_files = Path(\"/documents\").glob(\"**/*.pdf\")\nresults = processor.process_batch(pdf_files)\n\n# Handle results\nfor result in results:\n    if result.success:\n        print(f\"\u2713 {result.file}: {result.diagrams_found} diagrams\")\n    else:\n        print(f\"\u2717 {result.file}: {result.error}\")\n\n# Generate summary\nprocessor.generate_summary(\"batch_summary.json\")\n</code></pre>"},{"location":"batch/#best-practices","title":"Best Practices","text":"<ol> <li>Chunk Large Batches: Process in groups of 50-100 documents</li> <li>Use Checkpoints: Enable resume for long-running batches</li> <li>Monitor Memory: Set limits to prevent OOM errors</li> <li>Deduplicate First: Remove duplicates before processing</li> <li>Test Small Sample: Validate settings on subset first</li> </ol>"},{"location":"batch/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting - Common batch issues</li> <li>Vector Search - Search processed batches</li> <li>API Integration - Batch processing via API</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#version-0117-latest-release-hierarchical-cli-knowledge-graph","title":"Version 0.1.17 - Latest Release - Hierarchical CLI &amp; Knowledge Graph","text":"<p>Released: 2025-09-12</p>"},{"location":"changelog/#major-feature-hierarchical-cli-structure","title":"\ud83c\udfaf Major Feature - Hierarchical CLI Structure","text":"<ul> <li>NEW Command Structure: Complete redesign with 8 command groups for better organization</li> <li>Command Groups:</li> <li><code>process</code> - Document processing (pdf, batch, watch)</li> <li><code>server</code> - Server operations (api, mcp, worker, all, dev, health)</li> <li><code>db</code> - Database management (query, merge, stats, cleanup, import, migrate)</li> <li><code>kg</code> - Knowledge Graph (18+ commands for graph operations)</li> <li><code>model</code> - Model management (list, set-default, preload, ollama)</li> <li><code>project</code> - Project initialization (templates: small, medium, large, enterprise)</li> <li><code>config</code> - Configuration management (profiles, templates, environment variables)</li> <li><code>system</code> - System utilities (check, diagnose, version, health, metrics)</li> <li>Breaking Change: Old syntax <code>netintel-ocr document.pdf</code> \u2192 New syntax <code>netintel-ocr process pdf document.pdf</code></li> </ul>"},{"location":"changelog/#knowledge-graph-system-major-enhancement","title":"\ud83e\udde0 Knowledge Graph System (Major Enhancement)","text":""},{"location":"changelog/#core-kg-features","title":"Core KG Features","text":"<ul> <li>FalkorDB Integration: Redis-based graph database for storing entities and relationships</li> <li>Automatic Entity Extraction: Identifies network components, flow elements, and their relationships</li> <li>PyKEEN Embeddings: 8 state-of-the-art models for knowledge graph embeddings (200-dim):</li> <li>TransE (fast, simple relationships)</li> <li>RotatE (complex relationships, default)</li> <li>ComplEx (symmetric relationships)</li> <li>DistMult, ConvE, TuckER, HolE, RESCAL</li> <li>Default Enabled: KG features active by default in v0.1.17, use <code>--no-kg</code> to disable</li> </ul>"},{"location":"changelog/#hybrid-retrieval-system","title":"Hybrid Retrieval System","text":"<ul> <li>4 Retrieval Strategies:</li> <li>Vector-first: Start with Milvus, expand with graph</li> <li>Graph-first: Start with FalkorDB, enhance with vectors</li> <li>Parallel: Execute both simultaneously with RRF</li> <li>Adaptive: Auto-select based on query classification</li> <li>Query Intent Classification: 6 query types for optimal routing:</li> <li>Entity-centric, Relational, Topological</li> <li>Semantic, Analytical, Exploratory</li> <li>Reciprocal Rank Fusion (RRF): Advanced result merging for parallel search</li> <li>Performance Metrics:</li> <li>92% query accuracy (vs 72% vector-only)</li> <li>&lt;150ms response time for hybrid queries</li> <li>25% storage reduction with unified storage</li> </ul>"},{"location":"changelog/#enhanced-minirag-integration","title":"Enhanced MiniRAG Integration","text":"<ul> <li>3 Query Modes:</li> <li><code>minirag_only</code>: Traditional RAG with vector search</li> <li><code>kg_embedding_only</code>: Pure KG embedding similarity</li> <li><code>hybrid</code>: Combined graph + vector context</li> <li>Context Enrichment: Graph traversal adds related entities to context</li> <li>Answer Generation: LLM with graph-aware context for better accuracy</li> </ul>"},{"location":"changelog/#kg-cli-commands-18-new-commands","title":"KG CLI Commands (18+ new commands)","text":"<ul> <li>Initialization: <code>kg init</code>, <code>kg check-requirements</code></li> <li>Processing: <code>kg process</code>, <code>kg train-embeddings</code></li> <li>Querying: <code>kg query</code>, <code>kg rag-query</code>, <code>kg hybrid-search</code></li> <li>Analysis: <code>kg path-find</code>, <code>kg find-similar</code>, <code>kg cluster</code></li> <li>Visualization: <code>kg visualize</code>, <code>kg embedding-stats</code></li> <li>Management: <code>kg export</code>, <code>kg batch-query</code>, <code>kg stats</code></li> </ul>"},{"location":"changelog/#new-features","title":"\u2728 New Features","text":"<ul> <li>Configuration Templates: 6 pre-built templates (minimal, development, staging, production, enterprise, cloud)</li> <li>Profile Management: Multiple configuration profiles with easy switching</li> <li>Environment Variables: Complete configuration override capability</li> <li>18+ KG Commands: Including <code>kg init</code>, <code>kg train-embeddings</code>, <code>kg hybrid-search</code>, <code>kg path-find</code></li> <li>Visualization Tools: 2D/3D embedding visualization and clustering</li> <li>Batch KG Processing: Automatic KG extraction during batch operations</li> </ul>"},{"location":"changelog/#technical-improvements","title":"\ud83d\udee0\ufe0f Technical Improvements","text":"<ul> <li>50+ New Commands: Organized into intuitive hierarchical structure</li> <li>Click Framework: Modern CLI framework for better command organization</li> <li>Template System: Pre-configured templates for different deployment scenarios</li> <li>Configuration Validation: Comprehensive validation with helpful error messages</li> <li>Better Error Handling: Improved error messages and recovery</li> </ul>"},{"location":"changelog/#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Complete CLI reference with all new commands</li> <li>Migration guide from v0.1.16 to v0.1.17</li> <li>Configuration template documentation</li> <li>Knowledge Graph implementation guides</li> <li>Hybrid retrieval architecture documentation</li> <li>PyKEEN model selection guide</li> </ul>"},{"location":"changelog/#kg-implementation-details","title":"\ud83d\udd04 KG Implementation Details","text":""},{"location":"changelog/#what-gets-extracted","title":"What Gets Extracted","text":"<ul> <li>Network Components: Routers, switches, firewalls, servers, load balancers</li> <li>Flow Elements: Process steps, decision points, data stores</li> <li>Relationships: CONNECTS_TO, DEPENDS_ON, ROUTES_THROUGH, CONTAINS</li> <li>Properties: IP addresses, VLANs, protocols, ports, bandwidth</li> <li>Context: Security zones, business services, applications</li> </ul>"},{"location":"changelog/#storage-architecture","title":"Storage Architecture","text":"<ul> <li>FalkorDB: Graph structure + 200D KG embeddings as node properties</li> <li>Milvus: 4096D text embeddings for semantic search</li> <li>Unified Interface: Single query API for both graph and vector search</li> </ul>"},{"location":"changelog/#example-usage","title":"Example Usage","text":"<pre><code># Process with KG (default in v0.1.17)\nnetintel-ocr process pdf network-architecture.pdf\n\n# Query the knowledge graph\nnetintel-ocr kg query \"MATCH (n:NetworkDevice) RETURN n\"\n\n# Natural language query with MiniRAG\nnetintel-ocr kg rag-query \"What are the security vulnerabilities?\"\n\n# Find paths between entities\nnetintel-ocr kg path-find \"Router-A\" \"Database-Server\"\n\n# Visualize embeddings\nnetintel-ocr kg visualize --method tsne --output network-graph.html\n</code></pre>"},{"location":"changelog/#version-011615","title":"Version 0.1.16.15","text":"<p>Released: 2025-09-01</p>"},{"location":"changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fixed DEFAULT token parser error by replacing 'default' with 'DefaultZone'</li> <li>Enhanced connection handling to replace 'default' in arrow connections</li> <li>Improved keyword conflict resolution for Mermaid reserved words</li> </ul>"},{"location":"changelog/#version-011614","title":"Version 0.1.16.14","text":"<p>Released: 2025-09-01</p>"},{"location":"changelog/#bug-fixes_1","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fixed flow diagram parse errors with node-subgraph concatenation patterns</li> <li>Enhanced Mermaid fixer to handle 'default' keyword issues in subgraphs</li> <li>Improved preprocessing to separate concatenated node and subgraph definitions</li> </ul>"},{"location":"changelog/#version-011613","title":"Version 0.1.16.13","text":"<p>Released: 2025-09-01</p>"},{"location":"changelog/#features","title":"\u2728 Features","text":"<ul> <li>Applied Mermaid validation fixes to flow diagrams</li> <li>Added context extraction to flow diagrams using surrounding text</li> <li>Enhanced flow processor with RobustMermaidValidator for auto-correction</li> </ul>"},{"location":"changelog/#version-011612","title":"Version 0.1.16.12","text":"<p>Released: 2025-09-01</p>"},{"location":"changelog/#features_1","title":"\u2728 Features","text":"<ul> <li>Added context extraction for diagrams using surrounding text paragraphs</li> <li>Enhanced validation to auto-correct LLM-generated Mermaid syntax issues</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Fixed Mermaid diagram parsing errors with malformed subgraph/zone syntax</li> </ul>"},{"location":"changelog/#version-0116-major-release","title":"Version 0.1.16 - Major Release","text":"<p>Released: 2025-08-31</p>"},{"location":"changelog/#major-features","title":"\ud83c\udfaf Major Features","text":"<ul> <li>Unified Diagram Detection: Automatic detection for network/flow/hybrid diagrams</li> <li>Comprehensive Flow Processing: Full Mermaid generation for flow diagrams</li> <li>Context-Aware Analysis: Uses surrounding text (2 paragraphs before/after)</li> <li>Prompt Management System: Full customization without code changes</li> <li>Default Model Update: NetIntelOCR-7B-0925 as default vision model</li> </ul>"},{"location":"changelog/#new-capabilities","title":"\u2728 New Capabilities","text":"<ul> <li>Flow diagram element extraction and Mermaid generation</li> <li>Context extraction using document surrounding text</li> <li>Complete prompt import/export system</li> <li>Enhanced syntax validation and auto-correction</li> </ul>"},{"location":"changelog/#version-0115","title":"Version 0.1.15","text":"<p>Released: 2025-08-30</p>"},{"location":"changelog/#performance-improvements","title":"\ud83d\ude80 Performance Improvements","text":"<ul> <li>Milvus Integration: 20-60x faster search, 70% less memory usage</li> <li>Qwen3-8B Embeddings: 4096-dimensional vectors via Ollama</li> <li>Binary Vectors: Enhanced deduplication with SimHash</li> <li>Simplified Deployment: One-command initialization with scales</li> </ul>"},{"location":"changelog/#infrastructure","title":"\ud83d\udd27 Infrastructure","text":"<ul> <li>IVF_SQ8 indexing for CPU-optimized search</li> <li>Distributed architecture support</li> <li>Enhanced C++ deduplication core with AVX2 SIMD</li> </ul>"},{"location":"changelog/#version-0113","title":"Version 0.1.13","text":"<p>Released: 2025-08-25</p>"},{"location":"changelog/#new-features_1","title":"\u2728 New Features","text":"<ul> <li>REST API Server: Full API mode with <code>--api</code> flag</li> <li>MCP Server: Model Context Protocol support with <code>--mcp</code></li> <li>All-in-One Mode: Combined services with <code>--all-in-one</code></li> <li>Deployment Scales: Small/medium/large/enterprise configurations</li> <li>Kubernetes Support: Helm charts and manifests generation</li> </ul>"},{"location":"changelog/#version-0112","title":"Version 0.1.12","text":"<p>Released: 2025-08-20</p>"},{"location":"changelog/#major-features_1","title":"\ud83c\udfaf Major Features","text":"<ul> <li>Centralized Database: Unified LanceDB management</li> <li>Advanced Query Engine: Multi-field filtering and reranking</li> <li>Parallel Batch Processing: Progress tracking and resumability</li> <li>Cloud Storage: S3/MinIO integration</li> <li>Enhanced Embeddings: Multiple providers with intelligent caching</li> </ul>"},{"location":"changelog/#version-0110","title":"Version 0.1.10","text":"<p>Released: 2025-08-15</p>"},{"location":"changelog/#features_2","title":"\u2728 Features","text":"<ul> <li>Hybrid Detection: Automatic network/flow diagram classification</li> <li>Improved Accuracy: Enhanced component extraction algorithms</li> <li>Better Error Handling: Graceful fallbacks for processing failures</li> </ul>"},{"location":"changelog/#version-017","title":"Version 0.1.7","text":"<p>Released: 2025-08-10</p>"},{"location":"changelog/#major-features_2","title":"\ud83c\udfaf Major Features","text":"<ul> <li>Vector Database: Automatic LanceDB file generation</li> <li>RAG Optimization: Minimal metadata for optimal search</li> <li>Chunk Management: Intelligent document chunking</li> </ul>"},{"location":"changelog/#version-014","title":"Version 0.1.4","text":"<p>Released: 2025-08-01</p>"},{"location":"changelog/#new-features_2","title":"\u2728 New Features","text":"<ul> <li>Multi-Model Support: Different models for different tasks</li> <li>Model Optimization: Task-specific model selection</li> <li>Performance Modes: Fast/balanced/accurate processing</li> </ul>"},{"location":"changelog/#version-010","title":"Version 0.1.0","text":"<p>Released: 2025-07-01</p>"},{"location":"changelog/#initial-release","title":"\ud83c\udf89 Initial Release","text":"<ul> <li>Network diagram detection and extraction</li> <li>Mermaid.js generation</li> <li>PDF processing with OCR</li> <li>Basic CLI interface</li> <li>Ollama integration</li> </ul>"},{"location":"changelog/#upcoming-features","title":"Upcoming Features","text":""},{"location":"changelog/#version-020-planned","title":"Version 0.2.0 (Planned)","text":"<ul> <li>Web UI interface</li> <li>Real-time collaboration</li> <li>Custom model training</li> <li>Enterprise SSO integration</li> <li>Advanced analytics dashboard</li> </ul>"},{"location":"changelog/#version-030-planned","title":"Version 0.3.0 (Planned)","text":"<ul> <li>AutoML for model selection</li> <li>Federated learning support</li> <li>Multi-language support</li> <li>Graph database integration</li> <li>Compliance reporting</li> </ul>"},{"location":"changelog/#migration-guides","title":"Migration Guides","text":""},{"location":"changelog/#from-0115-to-0116","title":"From 0.1.15 to 0.1.16","text":"<ul> <li>Update default model to NetIntelOCR-7B-0925</li> <li>Export and update prompts using new management system</li> <li>Test flow diagram processing with new validator</li> </ul>"},{"location":"changelog/#from-0112-to-0115","title":"From 0.1.12 to 0.1.15","text":"<ul> <li>Migrate from LanceDB to Milvus</li> <li>Update embedding dimensions to 4096</li> <li>Regenerate vector indices</li> </ul>"},{"location":"changelog/#from-017-to-0112","title":"From 0.1.7 to 0.1.12","text":"<ul> <li>Update batch processing scripts</li> <li>Configure cloud storage backends</li> <li>Migrate to centralized database</li> </ul>"},{"location":"changelog/#deprecation-notices","title":"Deprecation Notices","text":""},{"location":"changelog/#deprecated-in-0116","title":"Deprecated in 0.1.16","text":"<ul> <li>Old flow diagram processor (use enhanced version)</li> <li>Manual prompt editing in code (use prompt management)</li> </ul>"},{"location":"changelog/#deprecated-in-0115","title":"Deprecated in 0.1.15","text":"<ul> <li>LanceDB backend (use Milvus)</li> <li>768-dimension embeddings (use 4096)</li> </ul>"},{"location":"changelog/#will-be-removed-in-020","title":"Will be removed in 0.2.0","text":"<ul> <li>Legacy CLI arguments</li> <li>Old configuration format</li> <li>Direct Ollama API calls</li> </ul>"},{"location":"changelog/#support","title":"Support","text":"<p>For issues and questions: - GitHub: https://github.com/VisionMLNet/NetIntelOCR/issues - Documentation: https://visionml.net/docs - PyPI: https://pypi.org/project/netintel-ocr/ - Discord: https://discord.gg/netintel-ocr</p>"},{"location":"cli-reference/","title":"CLI Reference Guide","text":""},{"location":"cli-reference/#overview","title":"Overview","text":"<p>Complete reference for NetIntel-OCR v0.1.18.1 CLI commands with full multi-model support and 30+ processing options.</p>"},{"location":"cli-reference/#command-structure","title":"Command Structure","text":"<pre><code>netintel-ocr [global-options] &lt;capability&gt; &lt;command&gt; [options]\n</code></pre>"},{"location":"cli-reference/#global-options","title":"Global Options","text":"<pre><code>--config PATH        # Use specific configuration file\n--profile NAME       # Use configuration profile\n--debug, -d         # Enable debug output\n--verbose, -v       # Enable verbose output\n--quiet, -q         # Suppress output\n--log-level LEVEL   # Set log level (DEBUG|INFO|WARNING|ERROR)\n--log-file PATH     # Log to file\n--log-format FORMAT # Log format (text|json)\n--no-color         # Disable colored output\n--dry-run          # Simulate without executing\n--help, -h         # Show help\n--version          # Show version\n</code></pre>"},{"location":"cli-reference/#1-process-capability","title":"1. Process Capability","text":"<p>Document processing and ingestion operations.</p>"},{"location":"cli-reference/#process-file","title":"process file","text":"<p>Process a single PDF document with complete multi-model support (v0.1.18.1).</p> <pre><code>netintel-ocr process file &lt;file_path&gt; [options]\n\nMulti-Model Options (NEW in v0.1.18.1):\n  --model, -m MODEL              # Primary OCR/text extraction model\n  --network-model MODEL          # Network diagram processing model\n  --flow-model MODEL             # Flow diagram processing model\n\nProcessing Modes:\n  --text-only, -t                # Extract text only, skip diagrams\n  --network-only                 # Extract network diagrams only\n\nPage Selection:\n  --pages RANGE                  # Page range (e.g., 1-10 or 1,3,5)\n  --start, -s INT                # Start page number\n  --end, -e INT                  # End page number\n\nDiagram Processing:\n  --confidence, -c FLOAT         # Detection confidence (0.0-1.0)\n  --no-icons                     # Disable Mermaid icons\n  --diagram-only                 # Extract only diagrams\n  --fast-extraction              # Optimized fast extraction\n  --multi-diagram                # Force multi-diagram mode\n  --no-auto-detect               # Disable auto-detection\n\nTable Extraction:\n  --extract-tables               # Extract tables (enabled by default)\n  --no-tables                    # Disable table extraction\n  --table-confidence FLOAT       # Table detection threshold\n  --table-method METHOD          # Table method (llm|hybrid)\n  --save-table-json              # Save tables as JSON\n\nProcessing Control:\n  --resume                       # Resume from checkpoint\n  --timeout SECONDS              # Operation timeout\n  --keep-images, -k              # Keep intermediate files\n  --width, -w INT                # Image processing width\n\nOutput Control:\n  --output, -o PATH              # Output file path\n  --debug, -d                    # Enable debug output\n  --verbose, -v                  # Verbose output\n  --quiet, -q                    # Minimal output\n\nVector Generation (Milvus default):\n  --no-vector                    # Disable vector generation\n  --vector-format FORMAT         # Vector DB format (milvus|lancedb)\n  --chunk-size INT               # Chunk size (default: 1000)\n  --chunk-overlap INT            # Chunk overlap (default: 100)\n  --chunk-strategy STRATEGY      # Chunking strategy (semantic|fixed|sentence)\n\nKnowledge Graph:\n  --with-kg                      # Enable KG extraction\n  --kg-model MODEL               # KG embedding model\n\nExamples:\n  # Basic processing\n  netintel-ocr process file document.pdf\n\n  # Multi-model processing (NEW!)\n  netintel-ocr process file doc.pdf \\\n    --model nanonets-ocr-s \\\n    --network-model qwen2.5vl \\\n    --flow-model custom-flow\n\n  # Advanced options\n  netintel-ocr process file doc.pdf \\\n    --pages 1-50 \\\n    --confidence 0.8 \\\n    --fast-extraction \\\n    --table-method hybrid \\\n    --with-kg \\\n    --vector-format milvus\n</code></pre>"},{"location":"cli-reference/#process-batch","title":"process batch","text":"<p>Process multiple documents.</p> <pre><code>netintel-ocr process batch &lt;directory|pattern&gt; [options]\n\nOptions:\n  --files LIST               # File list (one per line)\n  --pattern GLOB             # File pattern (e.g., *.pdf)\n  --recursive, -r            # Process subdirectories\n  --parallel INT             # Parallel workers\n  --batch-size INT           # Documents per batch\n  --output-dir DIR           # Output directory\n  --output-structure TYPE    # Output structure (flat|tree|type)\n  --checkpoint PATH          # Checkpoint file\n  --resume                   # Resume from checkpoint\n  --skip-errors              # Continue on errors\n  --dedup                    # Deduplicate documents\n  --ingest                   # Ingest to vector store\n  --collection NAME          # Target collection\n\nExamples:\n  netintel-ocr process batch /path/to/pdfs/\n  netintel-ocr process batch --pattern \"*.pdf\" --parallel 4\n  netintel-ocr process batch --files list.txt --ingest\n</code></pre>"},{"location":"cli-reference/#process-watch","title":"process watch","text":"<p>Watch directory for new documents.</p> <pre><code>netintel-ocr process watch &lt;directory&gt; [options]\n\nOptions:\n  --pattern GLOB         # File pattern to watch\n  --interval SECONDS     # Check interval\n  --process-existing     # Process existing files\n  --move-processed DIR   # Move processed files\n  --move-failed DIR      # Move failed files\n\nExamples:\n  netintel-ocr process watch /input --pattern \"*.pdf\"\n  netintel-ocr process watch /scan --interval 30\n</code></pre>"},{"location":"cli-reference/#process-dedup","title":"process dedup","text":"<p>Find and remove duplicate documents.</p> <pre><code>netintel-ocr process dedup &lt;directory&gt; [options]\nnetintel-ocr process find-duplicates &lt;directory&gt; [options]\nnetintel-ocr process dedup-stats [options]\n\nOptions:\n  --threshold FLOAT      # Similarity threshold\n  --mode MODE           # Dedup mode (hash|content|hybrid)\n  --action ACTION       # Action (report|remove|move)\n  --move-to DIR         # Move duplicates to directory\n\nExamples:\n  netintel-ocr process find-duplicates /docs\n  netintel-ocr process dedup /docs --threshold 0.95\n  netintel-ocr process dedup-stats\n</code></pre>"},{"location":"cli-reference/#2-server-capability","title":"2. Server Capability","text":"<p>API and server management.</p>"},{"location":"cli-reference/#server-api","title":"server api","text":"<p>Start REST API server.</p> <pre><code>netintel-ocr server api [options]\n\nOptions:\n  --host HOST           # Bind host (default: 0.0.0.0)\n  --port PORT           # Bind port (default: 8000)\n  --workers INT         # Worker processes\n  --timeout SECONDS     # Request timeout\n  --max-requests INT    # Max requests per worker\n  --auth-key KEY        # API authentication key\n  --cors-origins LIST   # CORS allowed origins\n  --tls-cert PATH       # TLS certificate\n  --tls-key PATH        # TLS key\n\nExamples:\n  netintel-ocr server api\n  netintel-ocr server api --port 8080 --workers 4\n  netintel-ocr server api --auth-key secret --tls-cert cert.pem\n</code></pre>"},{"location":"cli-reference/#server-mcp","title":"server mcp","text":"<p>Start Model Context Protocol server.</p> <pre><code>netintel-ocr server mcp [options]\n\nOptions:\n  --host HOST          # Bind host\n  --port PORT          # Bind port (default: 8001)\n  --stdio              # Use stdio mode\n  --transport TYPE     # Transport (stdio|http|websocket)\n\nExamples:\n  netintel-ocr server mcp\n  netintel-ocr server mcp --port 8001\n  netintel-ocr server mcp --stdio\n</code></pre>"},{"location":"cli-reference/#server-all","title":"server all","text":"<p>Start all services.</p> <pre><code>netintel-ocr server all [options]\n\nOptions:\n  --api-port PORT      # API port\n  --mcp-port PORT      # MCP port\n  --workers INT        # Worker processes\n\nExamples:\n  netintel-ocr server all\n  netintel-ocr server all --api-port 8000 --mcp-port 8001\n</code></pre>"},{"location":"cli-reference/#server-worker","title":"server worker","text":"<p>Start background worker.</p> <pre><code>netintel-ocr server worker [options]\n\nOptions:\n  --count INT          # Number of workers\n  --queue NAME         # Queue name\n  --embedded           # Run in API process\n\nExamples:\n  netintel-ocr server worker --count 4\n  netintel-ocr server worker --embedded\n</code></pre>"},{"location":"cli-reference/#server-statushealth","title":"server status/health","text":"<p>Check server status.</p> <pre><code>netintel-ocr server status\nnetintel-ocr server health\nnetintel-ocr server metrics\n\nExamples:\n  netintel-ocr server status\n  netintel-ocr server health --detailed\n  netintel-ocr server metrics --format json\n</code></pre>"},{"location":"cli-reference/#3-database-capability","title":"3. Database Capability","text":"<p>Database and vector store operations.</p>"},{"location":"cli-reference/#db-query","title":"db query","text":"<p>Query documents.</p> <pre><code>netintel-ocr db query &lt;query&gt; [options]\n\nOptions:\n  --collection NAME      # Collection to query\n  --limit INT           # Result limit\n  --threshold FLOAT     # Similarity threshold\n  --filters JSON        # Query filters\n  --fields LIST         # Fields to return\n  --vector              # Vector search mode\n  --hybrid              # Hybrid search mode\n\nExamples:\n  netintel-ocr db query \"firewall configuration\"\n  netintel-ocr db query \"network topology\" --limit 10\n  netintel-ocr db query \"security\" --collection docs --vector\n</code></pre>"},{"location":"cli-reference/#db-search","title":"db search","text":"<p>Advanced search operations.</p> <pre><code>netintel-ocr db search &lt;query&gt; [options]\n\nOptions:\n  --date-range RANGE    # Date range\n  --document-type TYPE  # Document type filter\n  --author NAME         # Author filter\n  --tags LIST          # Tag filters\n\nExamples:\n  netintel-ocr db search \"compliance\" --date-range 2024-01-01:2024-12-31\n  netintel-ocr db search \"firewall\" --document-type network\n</code></pre>"},{"location":"cli-reference/#db-stats","title":"db stats","text":"<p>Database statistics.</p> <pre><code>netintel-ocr db stats [options]\nnetintel-ocr db info\n\nOptions:\n  --collection NAME     # Specific collection\n  --detailed           # Detailed statistics\n\nExamples:\n  netintel-ocr db stats\n  netintel-ocr db stats --collection network_docs --detailed\n  netintel-ocr db info\n</code></pre>"},{"location":"cli-reference/#db-manage","title":"db manage","text":"<p>Database management.</p> <pre><code>netintel-ocr db optimize [options]\nnetintel-ocr db compact [collection]\nnetintel-ocr db rebuild-index [collection]\nnetintel-ocr db verify-index [collection]\nnetintel-ocr db export &lt;output_file&gt;\nnetintel-ocr db import &lt;input_file&gt;\nnetintel-ocr db backup [output_dir]\nnetintel-ocr db restore &lt;backup_dir&gt;\nnetintel-ocr db merge [sources...]\nnetintel-ocr db drop-collection &lt;name&gt;\n\nExamples:\n  netintel-ocr db optimize\n  netintel-ocr db compact network_docs\n  netintel-ocr db export backup.db\n  netintel-ocr db rebuild-index --optimize\n</code></pre>"},{"location":"cli-reference/#4-knowledge-graph-capability","title":"4. Knowledge Graph Capability","text":"<p>Knowledge Graph operations (passthrough to KG CLI).</p>"},{"location":"cli-reference/#kg-init","title":"kg init","text":"<p>Initialize Knowledge Graph.</p> <pre><code>netintel-ocr kg init [options]\n\nOptions:\n  --reset              # Reset existing KG\n  --import PATH        # Import from file\n\nExamples:\n  netintel-ocr kg init\n  netintel-ocr kg init --reset\n</code></pre>"},{"location":"cli-reference/#kg-query","title":"kg query","text":"<p>Query Knowledge Graph.</p> <pre><code>netintel-ocr kg query &lt;cypher_query&gt; [options]\n\nOptions:\n  --limit INT          # Result limit\n  --format FORMAT      # Output format (json|table|csv)\n\nExamples:\n  netintel-ocr kg query \"MATCH (n) RETURN n LIMIT 10\"\n  netintel-ocr kg query \"MATCH (n:Server) RETURN n.name\"\n</code></pre>"},{"location":"cli-reference/#kg-rag-query","title":"kg rag-query","text":"<p>RAG-enhanced query.</p> <pre><code>netintel-ocr kg rag-query &lt;natural_language_query&gt; [options]\n\nOptions:\n  --strategy TYPE       # Query strategy\n  --llm-model MODEL    # LLM model\n  --embedding-model MODEL # Embedding model\n  --limit INT          # Result limit\n\nExamples:\n  netintel-ocr kg rag-query \"Show all firewall rules\"\n  netintel-ocr kg rag-query \"Find security vulnerabilities\" --llm-model llama2\n</code></pre>"},{"location":"cli-reference/#kg-manage","title":"kg manage","text":"<p>KG management operations.</p> <pre><code>netintel-ocr kg stats\nnetintel-ocr kg export &lt;output_file&gt;\nnetintel-ocr kg import &lt;input_file&gt;\nnetintel-ocr kg clear\nnetintel-ocr kg optimize\n\nExamples:\n  netintel-ocr kg stats\n  netintel-ocr kg export knowledge-graph.json\n  netintel-ocr kg optimize\n</code></pre>"},{"location":"cli-reference/#5-configuration-capability","title":"5. Configuration Capability","text":"<p>Configuration management.</p>"},{"location":"cli-reference/#config-init","title":"config init","text":"<p>Initialize configuration.</p> <pre><code>netintel-ocr config init [options]\n\nOptions:\n  --template NAME      # Configuration template\n  --output PATH        # Output path\n  --force             # Overwrite existing\n\nExamples:\n  netintel-ocr config init\n  netintel-ocr config init --template production\n  netintel-ocr config init --output /etc/netintel/config.json\n</code></pre>"},{"location":"cli-reference/#config-getset","title":"config get/set","text":"<p>Get and set configuration values.</p> <pre><code>netintel-ocr config get &lt;key&gt;\nnetintel-ocr config set &lt;key&gt; &lt;value&gt;\nnetintel-ocr config unset &lt;key&gt;\n\nExamples:\n  netintel-ocr config get server.api.port\n  netintel-ocr config set server.api.port 8080\n  netintel-ocr config set models.default qwen2.5vl:7b\n  netintel-ocr config unset server.api.auth.key\n</code></pre>"},{"location":"cli-reference/#config-profile","title":"config profile","text":"<p>Manage configuration profiles.</p> <pre><code>netintel-ocr config profile list\nnetintel-ocr config profile create &lt;name&gt;\nnetintel-ocr config profile use &lt;name&gt;\nnetintel-ocr config profile delete &lt;name&gt;\nnetintel-ocr config profile copy &lt;source&gt; &lt;dest&gt;\nnetintel-ocr config profile export &lt;name&gt;\nnetintel-ocr config profile import &lt;name&gt; &lt;file&gt;\nnetintel-ocr config profile diff &lt;profile1&gt; &lt;profile2&gt;\n\nExamples:\n  netintel-ocr config profile create production\n  netintel-ocr config profile use production\n  netintel-ocr config profile export production &gt; prod.json\n</code></pre>"},{"location":"cli-reference/#config-env","title":"config env","text":"<p>Environment variable management.</p> <pre><code>netintel-ocr config env export [options]\nnetintel-ocr config env load &lt;file&gt;\nnetintel-ocr config env show\n\nExamples:\n  netintel-ocr config env export &gt; .env\n  netintel-ocr config env load production.env\n  netintel-ocr config env show\n</code></pre>"},{"location":"cli-reference/#config-manage","title":"config manage","text":"<p>Configuration management.</p> <pre><code>netintel-ocr config show [section]\nnetintel-ocr config validate\nnetintel-ocr config fix\nnetintel-ocr config backup [file]\nnetintel-ocr config restore &lt;file&gt;\nnetintel-ocr config reset\nnetintel-ocr config migrate &lt;old_config&gt;\n\nExamples:\n  netintel-ocr config show\n  netintel-ocr config validate --strict\n  netintel-ocr config backup config-backup.json\n  netintel-ocr config migrate old-config.ini\n</code></pre>"},{"location":"cli-reference/#6-project-capability","title":"6. Project Capability","text":"<p>Project initialization and management.</p>"},{"location":"cli-reference/#project-init","title":"project init","text":"<p>Initialize project structure.</p> <pre><code>netintel-ocr project init [options]\n\nOptions:\n  --template NAME       # Project template\n  --output DIR         # Output directory\n  --force             # Overwrite existing\n\nTemplates:\n  - small: Development/test environment\n  - medium: Staging environment\n  - large: Production environment\n  - enterprise: High-availability setup\n\nExamples:\n  netintel-ocr project init\n  netintel-ocr project init --template production\n  netintel-ocr project init --template enterprise --output /opt/netintel\n</code></pre>"},{"location":"cli-reference/#project-generate","title":"project generate","text":"<p>Generate deployment files.</p> <pre><code>netintel-ocr project generate docker\nnetintel-ocr project generate kubernetes\nnetintel-ocr project generate helm\nnetintel-ocr project generate systemd\n\nExamples:\n  netintel-ocr project generate docker &gt; docker-compose.yml\n  netintel-ocr project generate kubernetes --output k8s/\n  netintel-ocr project generate helm --name netintel-ocr\n</code></pre>"},{"location":"cli-reference/#7-model-capability","title":"7. Model Capability","text":"<p>Model management operations.</p>"},{"location":"cli-reference/#model-list","title":"model list","text":"<p>List available models.</p> <pre><code>netintel-ocr model list [options]\n\nOptions:\n  --sort-by FIELD      # Sort by (name|size|speed|accuracy)\n  --filter TYPE        # Filter by type\n\nExamples:\n  netintel-ocr model list\n  netintel-ocr model list --sort-by speed\n  netintel-ocr model list --filter vision\n</code></pre>"},{"location":"cli-reference/#model-ollama","title":"model ollama","text":"<p>OLLAMA model management.</p> <pre><code>netintel-ocr model ollama list\nnetintel-ocr model ollama pull &lt;model&gt;\nnetintel-ocr model ollama remove &lt;model&gt;\nnetintel-ocr model ollama set-host &lt;host&gt;\nnetintel-ocr model ollama verify\n\nExamples:\n  netintel-ocr model ollama list\n  netintel-ocr model ollama pull qwen2.5vl:7b\n  netintel-ocr model ollama set-host http://ollama:11434\n</code></pre>"},{"location":"cli-reference/#model-config","title":"model config","text":"<p>Configure models.</p> <pre><code>netintel-ocr model set-default &lt;type&gt; &lt;model&gt;\nnetintel-ocr model config &lt;model&gt; [options]\nnetintel-ocr model preload &lt;model&gt;\nnetintel-ocr model unload &lt;model&gt;\nnetintel-ocr model keep-loaded\n\nExamples:\n  netintel-ocr model set-default network qwen2.5vl:7b\n  netintel-ocr model config qwen2.5vl:7b --max-context 2048\n  netintel-ocr model preload qwen2.5vl:7b\n</code></pre>"},{"location":"cli-reference/#model-benchmark","title":"model benchmark","text":"<p>Benchmark models.</p> <pre><code>netintel-ocr model benchmark [model]\nnetintel-ocr model compare &lt;models...&gt;\nnetintel-ocr model recommend [options]\n\nExamples:\n  netintel-ocr model benchmark qwen2.5vl:7b\n  netintel-ocr model compare qwen2.5vl:7b llava:13b\n  netintel-ocr model recommend --priority speed\n</code></pre>"},{"location":"cli-reference/#8-system-capability","title":"8. System Capability","text":"<p>System utilities and diagnostics.</p>"},{"location":"cli-reference/#system-check","title":"system check","text":"<p>System checks and requirements.</p> <pre><code>netintel-ocr system check [options]\nnetintel-ocr system version [options]\nnetintel-ocr system info\n\nOptions:\n  --verbose           # Detailed output\n  --json             # JSON output\n\nExamples:\n  netintel-ocr system check\n  netintel-ocr system version --json\n  netintel-ocr system info\n</code></pre>"},{"location":"cli-reference/#system-health","title":"system health","text":"<p>Health monitoring.</p> <pre><code>netintel-ocr system health [options]\n\nOptions:\n  --detailed          # Detailed health info\n  --component NAME    # Check specific component\n  --json             # JSON output\n\nExamples:\n  netintel-ocr system health\n  netintel-ocr system health --detailed\n  netintel-ocr system health --component api\n</code></pre>"},{"location":"cli-reference/#system-metrics","title":"system metrics","text":"<p>System metrics and performance.</p> <pre><code>netintel-ocr system metrics [options]\nnetintel-ocr system performance\nnetintel-ocr system resources\n\nOptions:\n  --watch            # Continuous monitoring\n  --interval SEC     # Update interval\n  --category TYPE    # Metric category\n\nExamples:\n  netintel-ocr system metrics\n  netintel-ocr system metrics --watch --interval 1\n  netintel-ocr system performance\n</code></pre>"},{"location":"cli-reference/#system-diagnose","title":"system diagnose","text":"<p>Diagnostic tools.</p> <pre><code>netintel-ocr system diagnose [options]\nnetintel-ocr system test-connection &lt;service&gt;\nnetintel-ocr system benchmark [options]\nnetintel-ocr system profile [options]\n\nOptions:\n  --output FILE      # Save diagnostic report\n  --performance      # Include performance data\n  --detailed        # Detailed diagnostics\n\nExamples:\n  netintel-ocr system diagnose --output report.txt\n  netintel-ocr system test-connection ollama\n  netintel-ocr system benchmark\n  netintel-ocr system profile --duration 60\n</code></pre>"},{"location":"cli-reference/#system-cache","title":"system cache","text":"<p>Cache management.</p> <pre><code>netintel-ocr system cache stats\nnetintel-ocr system cache clear [type]\nnetintel-ocr system cache warmup\nnetintel-ocr system clear-cache\n\nExamples:\n  netintel-ocr system cache stats\n  netintel-ocr system cache clear models\n  netintel-ocr system clear-cache\n</code></pre>"},{"location":"cli-reference/#system-gpu","title":"system gpu","text":"<p>GPU management.</p> <pre><code>netintel-ocr system gpu status\nnetintel-ocr system gpu monitor\nnetintel-ocr system gpu optimize\n\nExamples:\n  netintel-ocr system gpu status\n  netintel-ocr system gpu monitor --interval 1\n  netintel-ocr system gpu optimize --auto\n</code></pre>"},{"location":"cli-reference/#shell-completion","title":"Shell Completion","text":"<p>Enable tab completion for your shell.</p>"},{"location":"cli-reference/#bash","title":"Bash","text":"<pre><code># Generate completion script\nnetintel-ocr completion bash &gt; /etc/bash_completion.d/netintel-ocr\n\n# Or add to .bashrc\neval \"$(netintel-ocr completion bash)\"\n</code></pre>"},{"location":"cli-reference/#zsh","title":"Zsh","text":"<pre><code># Generate completion script\nnetintel-ocr completion zsh &gt; ~/.zsh/completions/_netintel-ocr\n\n# Or add to .zshrc\neval \"$(netintel-ocr completion zsh)\"\n</code></pre>"},{"location":"cli-reference/#fish","title":"Fish","text":"<pre><code># Generate completion script\nnetintel-ocr completion fish &gt; ~/.config/fish/completions/netintel-ocr.fish\n</code></pre>"},{"location":"cli-reference/#environment-variables","title":"Environment Variables","text":"<pre><code># Configuration\nNETINTEL_CONFIG         # Configuration file path\nNETINTEL_PROFILE        # Active profile name\n\n# Server settings\nNETINTEL_SERVER_API_PORT      # API server port\nNETINTEL_SERVER_API_HOST      # API server host\nNETINTEL_SERVER_MCP_PORT      # MCP server port\n\n# Model settings\nNETINTEL_MODELS_DEFAULT       # Default model\nNETINTEL_MODELS_OLLAMA_HOST   # OLLAMA host\n\n# Database settings\nNETINTEL_DB_MILVUS_HOST      # Milvus host\nNETINTEL_DB_MILVUS_PORT      # Milvus port\nNETINTEL_DB_COLLECTION        # Default collection\n\n# Performance\nNETINTEL_PERFORMANCE_GPU_ENABLED    # Enable GPU\nNETINTEL_PERFORMANCE_MAX_PARALLEL   # Max parallel workers\n\n# Logging\nNETINTEL_LOGGING_LEVEL       # Log level\nNETINTEL_LOGGING_FILE        # Log file path\nNETINTEL_DEBUG               # Enable debug mode\n</code></pre>"},{"location":"cli-reference/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code>: Success</li> <li><code>1</code>: General error</li> <li><code>2</code>: Configuration error</li> <li><code>3</code>: Connection error</li> <li><code>4</code>: Processing error</li> <li><code>5</code>: Authentication error</li> <li><code>6</code>: Invalid input</li> <li><code>7</code>: Resource error</li> <li><code>130</code>: Interrupted (Ctrl+C)</li> </ul>"},{"location":"cli-reference/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Getting started</li> <li>Configuration Guide - Configuration details</li> <li>API Reference - REST API documentation</li> <li>Troubleshooting Guide - Common issues</li> </ul>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>New in v0.1.17.1: Modular Configuration</p> <p>NetIntel-OCR v0.1.17.1 introduces modular installation which affects configuration. You can now configure only the modules you have installed, and the system will gracefully handle missing modules.</p>"},{"location":"configuration/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.17+ introduces comprehensive configuration management through the <code>config</code> capability, enabling environment-specific settings, profiles, and automated configuration handling. Version 0.1.17.1 enhances this with modular configuration that adapts to installed features.</p>"},{"location":"configuration/#configuration-architecture","title":"Configuration Architecture","text":"<pre><code>graph TB\n    A[Default Config] --&gt; B[Profile Configs]\n    B --&gt; C[Environment Overrides]\n    C --&gt; D[CLI Arguments]\n    D --&gt; E[Runtime Config]</code></pre>"},{"location":"configuration/#configuration-file-structure","title":"Configuration File Structure","text":""},{"location":"configuration/#main-configuration-configjson","title":"Main Configuration (<code>config.json</code>)","text":"<pre><code>{\n  \"version\": \"0.1.17.1\",\n  \"profile\": \"production\",\n\n  \"modules\": {\n    \"kg\": {\n      \"enabled\": true,\n      \"falkordb\": {\n        \"host\": \"localhost\",\n        \"port\": 6379\n      },\n      \"embeddings\": {\n        \"models\": [\"TransE\", \"RotatE\", \"ComplEx\"]\n      }\n    },\n    \"vector\": {\n      \"enabled\": false\n    },\n    \"api\": {\n      \"enabled\": true\n    },\n    \"mcp\": {\n      \"enabled\": false\n    }\n  },\n\n  \"server\": {\n    \"api\": {\n      \"host\": \"0.0.0.0\",\n      \"port\": 8000,\n      \"workers\": 4,\n      \"timeout\": 300,\n      \"max_request_size\": \"100MB\",\n      \"auth\": {\n        \"enabled\": false,\n        \"key\": null\n      }\n    },\n    \"mcp\": {\n      \"host\": \"0.0.0.0\",\n      \"port\": 8001,\n      \"enabled\": true\n    }\n  },\n\n  \"models\": {\n    \"default\": \"qwen2.5vl:7b\",\n    \"text\": \"Nanonets-OCR-s:latest\",\n    \"network\": \"NetIntelOCR-7B-0925\",\n    \"flow\": \"qwen2.5vl:7b\",\n    \"ollama\": {\n      \"host\": \"http://localhost:11434\",\n      \"timeout\": 600\n    }\n  },\n\n  \"db\": {\n    \"type\": \"milvus\",\n    \"milvus\": {\n      \"host\": \"localhost\",\n      \"port\": 19530,\n      \"collection\": \"network_docs\",\n      \"index_type\": \"IVF_SQ8\",\n      \"metric_type\": \"L2\"\n    },\n    \"lancedb\": {\n      \"path\": \"./lance_db\",\n      \"table\": \"documents\"\n    }\n  },\n\n  \"processing\": {\n    \"max_parallel\": 4,\n    \"chunk_size\": 10,\n    \"confidence_threshold\": 0.5,\n    \"context_lines\": 2,\n    \"timeout_per_page\": 30,\n    \"cache\": {\n      \"enabled\": true,\n      \"dir\": \"~/.cache/netintel-ocr\",\n      \"ttl\": 3600\n    }\n  },\n\n  \"logging\": {\n    \"level\": \"INFO\",\n    \"format\": \"json\",\n    \"file\": null,\n    \"rotation\": {\n      \"enabled\": false,\n      \"max_size\": \"100MB\",\n      \"max_files\": 10\n    }\n  },\n\n  \"performance\": {\n    \"gpu\": {\n      \"enabled\": false,\n      \"device\": 0\n    },\n    \"memory\": {\n      \"max_usage\": \"8GB\",\n      \"swap_enabled\": false\n    },\n    \"cpu\": {\n      \"max_cores\": null\n    }\n  }\n}\n</code></pre>"},{"location":"configuration/#module-aware-configuration-v01171","title":"Module-Aware Configuration (v0.1.17.1)","text":""},{"location":"configuration/#automatic-module-detection","title":"Automatic Module Detection","text":"<p>NetIntel-OCR v0.1.17.1 automatically detects installed modules and adjusts configuration:</p> <pre><code># Check installed modules and their configuration status\nnetintel-ocr --version --detailed\n\n# Initialize config based on installed modules\nnetintel-ocr config init --auto-detect\n\n# The system will:\n# 1. Detect which modules are installed\n# 2. Enable configuration for installed modules\n# 3. Disable configuration for missing modules\n# 4. Show warnings for missing optional modules\n</code></pre>"},{"location":"configuration/#module-specific-configuration","title":"Module-Specific Configuration","text":"<pre><code># Configure Knowledge Graph (if installed)\nnetintel-ocr config set modules.kg.enabled true\nnetintel-ocr config set modules.kg.falkordb.host localhost\n\n# Configure Vector Store (if installed)\nnetintel-ocr config set modules.vector.enabled true\nnetintel-ocr config set modules.vector.milvus.host localhost\n\n# Check module availability before configuring\nnetintel-ocr config check-module kg\n# Output: \u2713 Knowledge Graph module installed\nnetintel-ocr config check-module vector\n# Output: \u2717 Vector module not installed. Install with: pip install netintel-ocr[vector]\n</code></pre>"},{"location":"configuration/#configuration-commands","title":"Configuration Commands","text":""},{"location":"configuration/#initialize-configuration","title":"Initialize Configuration","text":"<pre><code># Create default configuration (v0.1.17.1 auto-detects modules)\nnetintel-ocr config init\n\n# Initialize with template\nnetintel-ocr config init --template production\n\n# Initialize at custom path\nnetintel-ocr config init --output /etc/netintel/config.json\n\n# Available templates (v0.1.17.1 templates adapt to installed modules)\nnetintel-ocr config init --list-templates\n# - minimal: Base OCR only (500MB install)\n# - development: Dev with available modules\n# - staging: Staging with KG if available\n# - production: Production with all installed modules\n# - enterprise: Full features (requires [all] install)\n# - cloud: Cloud-optimized (requires [cloud] install)\n</code></pre>"},{"location":"configuration/#view-configuration","title":"View Configuration","text":"<pre><code># Show current configuration\nnetintel-ocr config show\n\n# Show specific section\nnetintel-ocr config show server\nnetintel-ocr config show models\n\n# Show effective configuration (with overrides)\nnetintel-ocr config show --effective\n\n# Output as JSON\nnetintel-ocr config show --json &gt; current-config.json\n</code></pre>"},{"location":"configuration/#set-configuration-values","title":"Set Configuration Values","text":"<pre><code># Set individual values\nnetintel-ocr config set server.api.port 8080\nnetintel-ocr config set models.default llava:13b\nnetintel-ocr config set db.milvus.host milvus.internal\n\n# Set nested values\nnetintel-ocr config set server.api.auth.enabled true\nnetintel-ocr config set server.api.auth.key \"secret-key-123\"\n\n# Set arrays\nnetintel-ocr config set server.api.cors.origins '[\"http://localhost:3000\",\"https://app.example.com\"]'\n\n# Remove a setting (use default)\nnetintel-ocr config unset server.api.auth.key\n</code></pre>"},{"location":"configuration/#get-configuration-values","title":"Get Configuration Values","text":"<pre><code># Get specific value\nnetintel-ocr config get server.api.port\n# Output: 8000\n\n# Get section\nnetintel-ocr config get models\n# Output: JSON object with all model settings\n\n# Get with default\nnetintel-ocr config get cache.ttl --default 3600\n</code></pre>"},{"location":"configuration/#configuration-profiles","title":"Configuration Profiles","text":""},{"location":"configuration/#profile-management","title":"Profile Management","text":"<pre><code># List available profiles\nnetintel-ocr config profile list\n\n# Create new profile\nnetintel-ocr config profile create staging\nnetintel-ocr config profile create production --from development\n\n# Switch profile\nnetintel-ocr config profile use production\n\n# Show current profile\nnetintel-ocr config profile current\n\n# Delete profile\nnetintel-ocr config profile delete old-staging\n</code></pre>"},{"location":"configuration/#profile-specific-settings","title":"Profile-Specific Settings","text":"<pre><code># Set value for specific profile\nnetintel-ocr config set server.api.port 8000 --profile production\nnetintel-ocr config set server.api.port 3000 --profile development\n\n# Copy profile\nnetintel-ocr config profile copy production production-backup\n\n# Compare profiles\nnetintel-ocr config profile diff development production\n\n# Export profile\nnetintel-ocr config profile export production &gt; prod-config.json\n\n# Import profile\nnetintel-ocr config profile import staging &lt; staging-config.json\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"configuration/#configuration-via-environment","title":"Configuration via Environment","text":"<p>All configuration values can be overridden using environment variables:</p> <pre><code># Pattern: NETINTEL_&lt;SECTION&gt;_&lt;KEY&gt;\nexport NETINTEL_SERVER_API_PORT=8080\nexport NETINTEL_MODELS_DEFAULT=llava:13b\nexport NETINTEL_DB_MILVUS_HOST=milvus.internal\nexport NETINTEL_LOGGING_LEVEL=DEBUG\n\n# Module-specific variables (v0.1.17.1)\nexport NETINTEL_MODULES_KG_ENABLED=true\nexport NETINTEL_MODULES_KG_FALKORDB_HOST=localhost\nexport NETINTEL_MODULES_VECTOR_ENABLED=false\nexport NETINTEL_MODULES_API_ENABLED=true\n\n# Special variables\nexport NETINTEL_CONFIG=/path/to/config.json\nexport NETINTEL_PROFILE=production\nexport NETINTEL_DEBUG=true\n</code></pre>"},{"location":"configuration/#environment-management","title":"Environment Management","text":"<pre><code># Export current config as environment variables\nnetintel-ocr config env export &gt; .env\n\n# Export specific profile\nnetintel-ocr config env export --profile production &gt; prod.env\n\n# Load environment file\nnetintel-ocr config env load .env\n\n# Show environment variables\nnetintel-ocr config env show\n\n# Generate Docker env file\nnetintel-ocr config env docker &gt; docker.env\n\n# Generate Kubernetes ConfigMap\nnetintel-ocr config env k8s &gt; configmap.yaml\n</code></pre>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<pre><code># Validate current configuration\nnetintel-ocr config validate\n\n# Validate specific file\nnetintel-ocr config validate --file custom-config.json\n\n# Strict validation (check all dependencies)\nnetintel-ocr config validate --strict\n\n# Fix common issues\nnetintel-ocr config fix\n\n# Check configuration health\nnetintel-ocr config health\n</code></pre>"},{"location":"configuration/#configuration-migration","title":"Configuration Migration","text":"<pre><code># Migrate from old format\nnetintel-ocr config migrate old-config.ini\n\n# Upgrade configuration version\nnetintel-ocr config upgrade\n\n# Convert between formats\nnetintel-ocr config convert config.yaml --format json\n\n# Merge configurations\nnetintel-ocr config merge base.json overrides.json --output final.json\n</code></pre>"},{"location":"configuration/#configuration-backup","title":"Configuration Backup","text":"<pre><code># Backup current configuration\nnetintel-ocr config backup\n\n# Backup with timestamp\nnetintel-ocr config backup config-$(date +%Y%m%d-%H%M%S).json\n\n# List backups\nnetintel-ocr config backup list\n\n# Restore from backup\nnetintel-ocr config restore config-20240115-120000.json\n\n# Auto-backup before changes\nnetintel-ocr config set --backup server.api.port 8080\n</code></pre>"},{"location":"configuration/#configuration-templates","title":"Configuration Templates","text":""},{"location":"configuration/#using-templates","title":"Using Templates","text":"<pre><code># List available templates\nnetintel-ocr config template list\n\n# Show template details\nnetintel-ocr config template show production\n\n# Create config from template\nnetintel-ocr config template apply production\n\n# Create custom template\nnetintel-ocr config template create my-template --from-current\n\n# Share template\nnetintel-ocr config template export my-template &gt; template.json\n</code></pre>"},{"location":"configuration/#template-examples-v01171","title":"Template Examples (v0.1.17.1)","text":"<p>Templates now adapt based on installed modules:</p>"},{"location":"configuration/#minimal-template-base-install","title":"Minimal Template (Base Install)","text":"<pre><code>{\n  \"profile\": \"minimal\",\n  \"modules\": {\n    \"kg\": {\"enabled\": false},\n    \"vector\": {\"enabled\": false},\n    \"api\": {\"enabled\": false},\n    \"mcp\": {\"enabled\": false}\n  },\n  \"server\": {\n    \"api\": {\"port\": 3000, \"host\": \"localhost\"}\n  },\n  \"logging\": {\"level\": \"INFO\"}\n}\n</code></pre>"},{"location":"configuration/#development-template-auto-detects-modules","title":"Development Template (Auto-detects Modules)","text":"<pre><code>{\n  \"profile\": \"development\",\n  \"modules\": {\n    \"kg\": {\"enabled\": \"auto\"},\n    \"vector\": {\"enabled\": \"auto\"},\n    \"api\": {\"enabled\": \"auto\"},\n    \"mcp\": {\"enabled\": false}\n  },\n  \"server\": {\n    \"api\": {\"port\": 3000, \"host\": \"localhost\"}\n  },\n  \"logging\": {\"level\": \"DEBUG\"},\n  \"performance\": {\"gpu\": {\"enabled\": false}}\n}\n</code></pre>"},{"location":"configuration/#production-template-requires-modules","title":"Production Template (Requires Modules)","text":"<pre><code>{\n  \"profile\": \"production\",\n  \"modules\": {\n    \"kg\": {\"enabled\": true, \"required\": true},\n    \"vector\": {\"enabled\": true, \"required\": false},\n    \"api\": {\"enabled\": true, \"required\": true},\n    \"mcp\": {\"enabled\": false}\n  },\n  \"server\": {\n    \"api\": {\n      \"port\": 8000,\n      \"host\": \"0.0.0.0\",\n      \"workers\": 8,\n      \"auth\": {\"enabled\": true}\n    }\n  },\n  \"logging\": {\"level\": \"WARNING\"},\n  \"performance\": {\"gpu\": {\"enabled\": true}}\n}\n</code></pre>"},{"location":"configuration/#configuration-scenarios","title":"Configuration Scenarios","text":""},{"location":"configuration/#multi-environment-setup","title":"Multi-Environment Setup","text":"<pre><code># Development\nnetintel-ocr config profile use development\nnetintel-ocr config set server.api.port 3000\nnetintel-ocr config set logging.level DEBUG\n\n# Staging\nnetintel-ocr config profile use staging\nnetintel-ocr config set server.api.port 8000\nnetintel-ocr config set db.milvus.host staging-milvus\n\n# Production\nnetintel-ocr config profile use production\nnetintel-ocr config set server.api.auth.enabled true\nnetintel-ocr config set logging.level WARNING\n</code></pre>"},{"location":"configuration/#docker-configuration","title":"Docker Configuration","text":"<pre><code># Generate Docker-optimized config\nnetintel-ocr config init --template docker\n\n# Set Docker-specific settings\nnetintel-ocr config set server.api.host 0.0.0.0\nnetintel-ocr config set db.milvus.host milvus\nnetintel-ocr config set models.ollama.host http://ollama:11434\n\n# Export for Docker\nnetintel-ocr config env docker &gt; docker.env\n</code></pre>"},{"location":"configuration/#kubernetes-configuration","title":"Kubernetes Configuration","text":"<pre><code># Generate K8s ConfigMap\nnetintel-ocr config k8s configmap &gt; configmap.yaml\n\n# Generate K8s Secret\nnetintel-ocr config k8s secret --keys \"server.api.auth.key\" &gt; secret.yaml\n\n# Generate Helm values\nnetintel-ocr config k8s helm &gt; values.yaml\n</code></pre>"},{"location":"configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"configuration/#1-use-profiles-for-environments","title":"1. Use Profiles for Environments","text":"<pre><code># Separate profiles for each environment\nnetintel-ocr config profile create development\nnetintel-ocr config profile create staging\nnetintel-ocr config profile create production\n\n# Switch based on environment\nENVIRONMENT=production\nnetintel-ocr config profile use $ENVIRONMENT\n</code></pre>"},{"location":"configuration/#2-secure-sensitive-data","title":"2. Secure Sensitive Data","text":"<pre><code># Don't store secrets in config files\nnetintel-ocr config set server.api.auth.key \"$API_KEY\" --no-save\n\n# Use environment variables for secrets\nexport NETINTEL_SERVER_API_AUTH_KEY=\"secret-key\"\n\n# Or use secret management\nnetintel-ocr config secret set api-key\nnetintel-ocr config secret get api-key\n</code></pre>"},{"location":"configuration/#3-version-control-configuration","title":"3. Version Control Configuration","text":"<pre><code># Track configuration changes\ngit add config.json\ngit commit -m \"Update production configuration\"\n\n# Exclude sensitive profiles\necho \"config-production.json\" &gt;&gt; .gitignore\n\n# Track templates only\ngit add templates/*.json\n</code></pre>"},{"location":"configuration/#4-validate-before-deployment","title":"4. Validate Before Deployment","text":"<pre><code># Always validate configuration\nnetintel-ocr config validate --strict\n\n# Test configuration\nnetintel-ocr --dry-run server all\n\n# Check effective configuration\nnetintel-ocr config show --effective\n</code></pre>"},{"location":"configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"configuration/#common-issues","title":"Common Issues","text":"<pre><code># Configuration not found\nnetintel-ocr config init\n\n# Invalid configuration\nnetintel-ocr config validate\nnetintel-ocr config fix\n\n# Profile not found\nnetintel-ocr config profile list\nnetintel-ocr config profile create missing-profile\n\n# Module not installed (v0.1.17.1)\nnetintel-ocr --version  # Check which modules are installed\n# Install missing module\npip install \"netintel-ocr[kg]\"\npip install \"netintel-ocr[vector]\"\n\n# Permission denied\nsudo chown $USER:$USER ~/.netintel-ocr/config.json\nchmod 600 ~/.netintel-ocr/config.json\n</code></pre>"},{"location":"configuration/#debug-configuration","title":"Debug Configuration","text":"<pre><code># Show configuration resolution\nnetintel-ocr config debug\n\n# Show configuration sources\nnetintel-ocr config sources\n\n# Test configuration loading\nnetintel-ocr config test\n\n# Show default values\nnetintel-ocr config defaults\n</code></pre>"},{"location":"configuration/#configuration-api","title":"Configuration API","text":""},{"location":"configuration/#programmatic-access","title":"Programmatic Access","text":"<pre><code>from netintel_ocr.config import ConfigManager\n\n# Load configuration\nconfig = ConfigManager()\nconfig.load()\n\n# Get values\napi_port = config.get(\"server.api.port\")\nmodels = config.get(\"models\")\n\n# Set values\nconfig.set(\"server.api.port\", 8080)\nconfig.set(\"models.default\", \"llava:13b\")\n\n# Check module availability (v0.1.17.1)\nif config.is_module_installed(\"kg\"):\n    config.set(\"modules.kg.enabled\", True)\n    # Configure KG settings\n    config.set(\"modules.kg.falkordb.host\", \"localhost\")\nelse:\n    print(\"KG module not installed. Install with: pip install netintel-ocr[kg]\")\n\n# Save configuration\nconfig.save()\n\n# Switch profiles\nconfig.use_profile(\"production\")\n</code></pre>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment Guide - Deploy with configuration</li> <li>API Configuration - API server settings</li> <li>Model Configuration - Model management</li> <li>Performance Tuning - Optimization settings</li> </ul>"},{"location":"customization/","title":"Customization Guide","text":""},{"location":"customization/#prompt-management","title":"Prompt Management","text":""},{"location":"customization/#export-current-prompts","title":"Export Current Prompts","text":"<pre><code># Export all prompts to YAML\nnetintel-ocr config export-prompts prompts.yaml\n\n# Export specific category\nnetintel-ocr config export-prompts network-prompts.yaml --category network\n</code></pre>"},{"location":"customization/#import-custom-prompts","title":"Import Custom Prompts","text":"<pre><code># Import modified prompts\nnetintel-ocr config import-prompts custom-prompts.yaml\n\n# Validate prompts\nnetintel-ocr config validate-prompts custom-prompts.yaml\n</code></pre>"},{"location":"customization/#prompt-structure","title":"Prompt Structure","text":"<pre><code>network_detection:\n  description: \"Detect network diagrams in images\"\n  prompt: |\n    Analyze this image for network architecture elements:\n    - Routers, switches, firewalls\n    - Network zones and segments\n    - Connection types and protocols\n\n    Return confidence score 0-1.\n\ncomponent_extraction:\n  description: \"Extract network components\"\n  prompt: |\n    Identify all network components:\n    {\n      \"components\": [...],\n      \"connections\": [...],\n      \"zones\": [...]\n    }\n</code></pre>"},{"location":"customization/#key-tuning-parameters","title":"Key Tuning Parameters","text":""},{"location":"customization/#1-detection-confidence-threshold","title":"1. Detection Confidence Threshold","text":"<pre><code># Default: 0.7\nnetintel-ocr process file document.pdf --confidence-threshold 0.9\n\n# Lower for more detection (may include false positives)\nnetintel-ocr process file document.pdf --confidence-threshold 0.5\n</code></pre>"},{"location":"customization/#2-model-temperature","title":"2. Model Temperature","text":"<pre><code># In prompts.yaml\nnetwork_extraction:\n  temperature: 0.3  # Lower = more deterministic\n  max_tokens: 4096\n  top_p: 0.9\n</code></pre>"},{"location":"customization/#3-context-window-size","title":"3. Context Window Size","text":"<pre><code># Surrounding text for context extraction\nnetintel-ocr --context-before 1000 --context-after 1000 document.pdf\n\n# Disable context for speed\nnetintel-ocr process file document.pdf --no-context\n</code></pre>"},{"location":"customization/#4-extraction-strategies","title":"4. Extraction Strategies","text":"<pre><code># Fast extraction (less accurate)\nnetintel-ocr process file document.pdf --fast-extraction\n\n# Comprehensive extraction (slower)\nnetintel-ocr process file document.pdf --comprehensive\n\n# Multi-pass extraction\nnetintel-ocr --multi-pass 3 document.pdf\n</code></pre>"},{"location":"customization/#5-output-verbosity","title":"5. Output Verbosity","text":"<pre><code># Minimal output\nnetintel-ocr process file document.pdf --output minimal\n\n# Include all metadata\nnetintel-ocr process file document.pdf --output detailed\n\n# Custom fields\nnetintel-ocr db query --fields \"components,security,recommendations\" document.pdf\n</code></pre>"},{"location":"customization/#6-mermaid-syntax-preferences","title":"6. Mermaid Syntax Preferences","text":"<pre><code># In config.yaml\nmermaid:\n  direction: TB  # Top-Bottom (or LR, RL, BT)\n  theme: default\n  node_shape: rectangle  # Or circle, diamond, hexagon\n  include_labels: true\n  simplify_connections: false\n</code></pre>"},{"location":"customization/#model-selection-tips","title":"Model Selection Tips","text":""},{"location":"customization/#vision-models-comparison","title":"Vision Models Comparison","text":"Model Speed Accuracy Memory Best For qwen2.5vl:7b Fast High 8GB General use llava:13b Medium Very High 16GB Complex diagrams minicpm-v Very Fast Medium 4GB Quick processing cogvlm Slow Highest 32GB Critical accuracy"},{"location":"customization/#selecting-models-by-document-type","title":"Selecting Models by Document Type","text":"<pre><code># Technical specifications\nnetintel-ocr --model Nanonets-OCR-s:latest \\\n             --network-model cogvlm:latest \\\n             technical-spec.pdf\n\n# Marketing materials (simpler diagrams)\nnetintel-ocr --model minicpm-v:latest \\\n             --network-model minicpm-v:latest \\\n             marketing-doc.pdf\n\n# Security documentation\nnetintel-ocr --model qwen2.5vl:7b \\\n             --security-focus \\\n             security-guide.pdf\n</code></pre>"},{"location":"customization/#custom-processing-pipelines","title":"Custom Processing Pipelines","text":""},{"location":"customization/#define-custom-pipeline","title":"Define Custom Pipeline","text":"<pre><code># custom_pipeline.py\nfrom netintel_ocr import Pipeline\n\npipeline = Pipeline()\npipeline.add_step(\"ocr\", model=\"Nanonets-OCR-s:latest\")\npipeline.add_step(\"detect\", confidence=0.8)\npipeline.add_step(\"extract\", strategy=\"comprehensive\")\npipeline.add_step(\"validate\", fix_errors=True)\npipeline.add_step(\"context\", window=2000)\n</code></pre>"},{"location":"customization/#use-custom-pipeline","title":"Use Custom Pipeline","text":"<pre><code>netintel-ocr config set pipeline custom_pipeline.py document.pdf\n</code></pre>"},{"location":"customization/#advanced-prompt-engineering","title":"Advanced Prompt Engineering","text":""},{"location":"customization/#component-extraction-enhancement","title":"Component Extraction Enhancement","text":"<pre><code>component_extraction:\n  prompt: |\n    Extract network components with these specific details:\n    1. Component type (router/switch/firewall/server/endpoint)\n    2. Component name/label\n    3. IP addresses or network ranges\n    4. Security zone assignment\n    5. Criticality level (high/medium/low)\n\n    For each connection include:\n    - Source and destination components\n    - Protocol/port information\n    - Direction (unidirectional/bidirectional)\n    - Bandwidth or capacity if shown\n</code></pre>"},{"location":"customization/#security-analysis-focus","title":"Security Analysis Focus","text":"<pre><code>security_analysis:\n  prompt: |\n    Analyze security aspects:\n    - Identify trust boundaries and security zones\n    - Detect exposed services and entry points\n    - Map data flows crossing zone boundaries\n    - Identify potential attack vectors\n    - Suggest security improvements\n\n    Priority: Accuracy over speed\n</code></pre>"},{"location":"customization/#performance-optimization","title":"Performance Optimization","text":""},{"location":"customization/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple files efficiently\nnetintel-ocr process batch \\\n             --max-parallel 4 \\\n             --cache-models \\\n             *.pdf\n</code></pre>"},{"location":"customization/#gpu-acceleration","title":"GPU Acceleration","text":"<pre><code># Enable GPU\nexport CUDA_VISIBLE_DEVICES=0\nnetintel-ocr process file document.pdf --gpu\n\n# Multi-GPU\nexport CUDA_VISIBLE_DEVICES=0,1\nnetintel-ocr --gpu --parallel-pages 2 document.pdf\n</code></pre>"},{"location":"customization/#caching","title":"Caching","text":"<pre><code># Enable result caching\nnetintel-ocr config set cache.dir /tmp/netintel-cache document.pdf\n\n# Clear cache\nnetintel-ocr system clear-cache\n</code></pre>"},{"location":"customization/#validation-rules","title":"Validation Rules","text":""},{"location":"customization/#custom-validation","title":"Custom Validation","text":"<pre><code>validation_rules:\n  network:\n    - rule: \"All components must have unique IDs\"\n    - rule: \"Connections must reference existing components\"\n    - rule: \"Security zones must be properly labeled\"\n\n  mermaid:\n    - rule: \"No orphaned nodes\"\n    - rule: \"Valid Mermaid syntax\"\n    - rule: \"Consistent node naming\"\n</code></pre>"},{"location":"customization/#apply-validation","title":"Apply Validation","text":"<pre><code>netintel-ocr config set validation.rules custom-rules.yaml document.pdf\n</code></pre>"},{"location":"customization/#additional-resources","title":"Additional Resources","text":"<ul> <li>Full Documentation: https://visionml.net/docs</li> <li>PyPI Package: https://pypi.org/project/netintel-ocr/</li> <li>Example Prompts: https://github.com/VisionMLNet/NetIntelOCR/tree/main/prompts</li> </ul>"},{"location":"customization/#next-steps","title":"Next Steps","text":"<ul> <li>Vector Search Guide - Configure semantic search</li> <li>Deployment Guide - Production setup</li> <li>Quick Start Guide - Basic usage</li> </ul>"},{"location":"deployment/","title":"Deployment Guide","text":"<p>Platform Requirements</p> <p>Linux Only - NetIntel-OCR is tested and supported only on Linux systems.</p> <ul> <li>Supported OS: Ubuntu 20.04/22.04, RHEL 8/9, Debian 11/12</li> <li>Python: 3.11.x or 3.12.x ONLY</li> <li>Architecture: x86_64 (ARM support planned)</li> </ul> <p>Windows and macOS deployments are not currently supported.</p>"},{"location":"deployment/#deployment-workflow-overview","title":"Deployment Workflow Overview","text":"<p>NetIntel-OCR v0.1.17 provides a comprehensive deployment workflow using the new CLI capabilities:</p> <pre><code>graph LR\n    A[System Check] --&gt; B[Project Init]\n    B --&gt; C[Config Setup]\n    C --&gt; D[Model Setup]\n    D --&gt; E[Server Deploy]\n    E --&gt; F[Health Check]</code></pre>"},{"location":"deployment/#step-1-system-verification","title":"Step 1: System Verification","text":""},{"location":"deployment/#check-system-requirements","title":"Check System Requirements","text":"<pre><code># Verify system compatibility\nnetintel-ocr system check\n\n# Get detailed diagnostics\nnetintel-ocr system diagnose\n\n# Check version and dependencies\nnetintel-ocr system version --json\n</code></pre>"},{"location":"deployment/#system-requirements","title":"System Requirements","text":"<pre><code># Check Python version (MUST be 3.11.x or 3.12.x)\npython --version\n\n# Verify Linux platform\nuname -s  # Must output \"Linux\"\n\n# Check available resources\nnetintel-ocr system metrics\n</code></pre> <p>Production Environment</p> <ul> <li>OS: Linux x86_64 (Ubuntu 20.04+ or RHEL 8+ recommended)</li> <li>Python: 3.11.x or 3.12.x (verified installation)</li> <li>Memory: 16GB minimum, 32GB recommended</li> <li>CPU: 8+ cores recommended</li> <li>Storage: SSD with 100GB+ available</li> </ul>"},{"location":"deployment/#step-2-project-initialization","title":"Step 2: Project Initialization","text":""},{"location":"deployment/#initialize-deployment-configuration","title":"Initialize Deployment Configuration","text":"<pre><code># Initialize with deployment template\nnetintel-ocr project init --template production\n\n# Small deployment (dev/test)\nnetintel-ocr project init --template small\n\n# Medium deployment (staging)\nnetintel-ocr project init --template medium\n\n# Large deployment (production)\nnetintel-ocr project init --template large\n\n# Enterprise deployment (high availability)\nnetintel-ocr project init --template enterprise\n</code></pre>"},{"location":"deployment/#generated-files","title":"Generated Files","text":"<pre><code>project/\n\u251c\u2500\u2500 config.json           # Main configuration\n\u251c\u2500\u2500 docker-compose.yml    # Docker deployment\n\u251c\u2500\u2500 k8s/                  # Kubernetes manifests\n\u2502   \u251c\u2500\u2500 configmap.yaml\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 hpa.yaml\n\u2502   \u2514\u2500\u2500 pvc.yaml\n\u251c\u2500\u2500 helm/                 # Helm charts\n\u2502   \u251c\u2500\u2500 Chart.yaml\n\u2502   \u2514\u2500\u2500 values.yaml\n\u2514\u2500\u2500 .env                  # Environment variables\n</code></pre>"},{"location":"deployment/#step-3-configuration-management","title":"Step 3: Configuration Management","text":""},{"location":"deployment/#initialize-configuration","title":"Initialize Configuration","text":"<pre><code># Create default configuration\nnetintel-ocr config init\n\n# Initialize with specific template\nnetintel-ocr config init --template production\n\n# Initialize with custom path\nnetintel-ocr config init --output /etc/netintel/config.json\n</code></pre>"},{"location":"deployment/#configure-settings","title":"Configure Settings","text":"<pre><code># Set API server configuration\nnetintel-ocr config set server.api.port 8000\nnetintel-ocr config set server.api.host 0.0.0.0\nnetintel-ocr config set server.api.workers 4\n\n# Set MCP server configuration\nnetintel-ocr config set server.mcp.port 8001\nnetintel-ocr config set server.mcp.enabled true\n\n# Set database configuration\nnetintel-ocr config set db.milvus.host milvus.internal\nnetintel-ocr config set db.milvus.port 19530\nnetintel-ocr config set db.collection network_docs\n\n# Set model configuration\nnetintel-ocr config set models.default qwen2.5vl:7b\nnetintel-ocr config set models.network NetIntelOCR-7B-0925\nnetintel-ocr config set models.flow qwen2.5vl:7b\n\n# Set performance options\nnetintel-ocr config set performance.max_parallel 4\nnetintel-ocr config set performance.cache_enabled true\nnetintel-ocr config set performance.gpu_enabled true\n</code></pre>"},{"location":"deployment/#configuration-profiles","title":"Configuration Profiles","text":"<pre><code># Create deployment profiles\nnetintel-ocr config profile create development\nnetintel-ocr config profile create staging\nnetintel-ocr config profile create production\n\n# Switch between profiles\nnetintel-ocr config profile use production\n\n# List profiles\nnetintel-ocr config profile list\n\n# Export profile\nnetintel-ocr config profile export production &gt; prod-config.json\n</code></pre>"},{"location":"deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># Export configuration as environment variables\nnetintel-ocr config env export &gt; .env\n\n# Load from environment\nnetintel-ocr config env load\n\n# Show current configuration\nnetintel-ocr config show\n\n# Validate configuration\nnetintel-ocr config validate\n</code></pre>"},{"location":"deployment/#step-4-model-management","title":"Step 4: Model Management","text":""},{"location":"deployment/#configure-ollama","title":"Configure OLLAMA","text":"<pre><code># Set OLLAMA host\nnetintel-ocr model ollama set-host http://ollama.internal:11434\n\n# List available models\nnetintel-ocr model ollama list\n\n# Pull required models\nnetintel-ocr model ollama pull qwen2.5vl:7b\nnetintel-ocr model ollama pull NetIntelOCR-7B-0925\nnetintel-ocr model ollama pull minicpm-v:latest\n\n# Verify models\nnetintel-ocr model ollama verify\n</code></pre>"},{"location":"deployment/#model-configuration","title":"Model Configuration","text":"<pre><code># List all configured models\nnetintel-ocr model list\n\n# Configure model defaults\nnetintel-ocr model set-default text Nanonets-OCR-s:latest\nnetintel-ocr model set-default network qwen2.5vl:7b\nnetintel-ocr model set-default flow qwen2.5vl:7b\n\n# Preload models for performance\nnetintel-ocr model preload qwen2.5vl:7b\nnetintel-ocr model preload --all\n\n# Keep models loaded in memory\nnetintel-ocr model keep-loaded\n</code></pre>"},{"location":"deployment/#step-5-docker-deployment","title":"Step 5: Docker Deployment","text":""},{"location":"deployment/#single-container-deployment","title":"Single Container Deployment","text":"<pre><code># Dockerfile\nFROM python:3.11-slim-bullseye\n# OR: FROM python:3.12-slim-bookworm\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc g++ python3-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install NetIntel-OCR\nRUN pip install netintel-ocr\n\n# Copy configuration\nCOPY config.json /app/config.json\n\n# Set configuration path\nENV NETINTEL_CONFIG=/app/config.json\n\n# Default command starts all services\nCMD [\"netintel-ocr\", \"server\", \"all\"]\n</code></pre>"},{"location":"deployment/#docker-compose-deployment","title":"Docker Compose Deployment","text":"<pre><code># docker-compose.yml (generated by project init)\nversion: '3.8'\n\nservices:\n  netintel-ocr:\n    image: netintel-ocr:latest\n    container_name: netintel-ocr\n    command: netintel-ocr server all\n    environment:\n      - NETINTEL_CONFIG=/app/config/config.json\n      - OLLAMA_HOST=http://ollama:11434\n    ports:\n      - \"8000:8000\"  # API\n      - \"8001:8001\"  # MCP\n    volumes:\n      - ./config:/app/config\n      - ./input:/app/input\n      - ./output:/app/output\n      - ./cache:/app/cache\n    depends_on:\n      - ollama\n      - milvus\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"netintel-ocr\", \"system\", \"health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  ollama:\n    image: ollama/ollama:latest\n    container_name: ollama\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama_data:/root/.ollama\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n\n  milvus:\n    image: milvusdb/milvus:latest\n    container_name: milvus\n    ports:\n      - \"19530:19530\"\n      - \"9091:9091\"\n    volumes:\n      - milvus_data:/var/lib/milvus\n    environment:\n      - ETCD_ENDPOINTS=etcd:2379\n      - MINIO_ADDRESS=minio:9000\n\nvolumes:\n  ollama_data:\n  milvus_data:\n</code></pre>"},{"location":"deployment/#build-and-deploy","title":"Build and Deploy","text":"<pre><code># Build Docker image\ndocker build -t netintel-ocr:latest .\n\n# Start services using docker-compose\ndocker-compose up -d\n\n# Check service health\ndocker exec netintel-ocr netintel-ocr system health\n\n# View logs\ndocker-compose logs -f netintel-ocr\n\n# Scale services\ndocker-compose up -d --scale netintel-ocr=3\n</code></pre>"},{"location":"deployment/#step-6-kubernetes-deployment","title":"Step 6: Kubernetes Deployment","text":""},{"location":"deployment/#deploy-using-generated-manifests","title":"Deploy Using Generated Manifests","text":"<pre><code># Apply all Kubernetes resources\nkubectl apply -f k8s/\n\n# Check deployment status\nkubectl get pods -l app=netintel-ocr\n\n# View logs\nkubectl logs -f deployment/netintel-ocr\n\n# Check service endpoints\nkubectl get svc netintel-ocr-service\n</code></pre>"},{"location":"deployment/#helm-deployment","title":"Helm Deployment","text":"<pre><code># Install using Helm\nhelm install netintel-ocr ./helm \\\n  --set image.tag=latest \\\n  --set replicas=3 \\\n  --set resources.requests.memory=4Gi \\\n  --set resources.requests.cpu=2\n\n# Upgrade deployment\nhelm upgrade netintel-ocr ./helm \\\n  --set replicas=5\n\n# Check status\nhelm status netintel-ocr\n</code></pre>"},{"location":"deployment/#configmap-for-kubernetes","title":"ConfigMap for Kubernetes","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: netintel-ocr-config\ndata:\n  config.json: |\n    {\n      \"server\": {\n        \"api\": {\"port\": 8000, \"host\": \"0.0.0.0\"},\n        \"mcp\": {\"port\": 8001, \"enabled\": true}\n      },\n      \"db\": {\n        \"milvus\": {\n          \"host\": \"milvus-service\",\n          \"port\": 19530\n        }\n      },\n      \"models\": {\n        \"default\": \"qwen2.5vl:7b\",\n        \"network\": \"NetIntelOCR-7B-0925\"\n      }\n    }\n</code></pre>"},{"location":"deployment/#step-7-server-operations","title":"Step 7: Server Operations","text":""},{"location":"deployment/#start-individual-services","title":"Start Individual Services","text":"<pre><code># Start API server only\nnetintel-ocr server api --port 8000 --workers 4\n\n# Start MCP server only\nnetintel-ocr server mcp --port 8001\n\n# Start all services (API + MCP)\nnetintel-ocr server all\n\n# Start with custom configuration\nnetintel-ocr --config production.json server all\n</code></pre>"},{"location":"deployment/#server-management","title":"Server Management","text":"<pre><code># Check server status\nnetintel-ocr server status\n\n# Reload configuration (graceful)\nnetintel-ocr server reload\n\n# Stop server (graceful shutdown)\nnetintel-ocr server stop\n\n# View server metrics\nnetintel-ocr server metrics\n</code></pre>"},{"location":"deployment/#step-8-health-monitoring","title":"Step 8: Health Monitoring","text":""},{"location":"deployment/#system-health-checks","title":"System Health Checks","text":"<pre><code># Check overall system health\nnetintel-ocr system health\n\n# Detailed health report\nnetintel-ocr system health --detailed\n\n# Check specific components\nnetintel-ocr system health --component api\nnetintel-ocr system health --component mcp\nnetintel-ocr system health --component db\nnetintel-ocr system health --component models\n</code></pre>"},{"location":"deployment/#monitoring-endpoints","title":"Monitoring Endpoints","text":"<pre><code># Prometheus metrics\ncurl http://localhost:8000/metrics\n\n# Health check\ncurl http://localhost:8000/health\n\n# Readiness check\ncurl http://localhost:8000/ready\n\n# Liveness check\ncurl http://localhost:8000/alive\n</code></pre>"},{"location":"deployment/#logging-configuration","title":"Logging Configuration","text":"<pre><code># Set log level\nnetintel-ocr config set logging.level INFO\nnetintel-ocr config set logging.format json\n\n# Enable debug mode\nnetintel-ocr --debug server all\n\n# Log to file\nnetintel-ocr --log-file /var/log/netintel.log server all\n\n# Structured logging\nnetintel-ocr --log-format json server all\n</code></pre>"},{"location":"deployment/#production-best-practices","title":"Production Best Practices","text":""},{"location":"deployment/#1-configuration-management","title":"1. Configuration Management","text":"<pre><code># Use environment-specific profiles\nnetintel-ocr config profile use production\n\n# Enable configuration validation\nnetintel-ocr config validate --strict\n\n# Backup configuration\nnetintel-ocr config backup /backup/config-$(date +%Y%m%d).json\n</code></pre>"},{"location":"deployment/#2-security-settings","title":"2. Security Settings","text":"<pre><code># Enable API authentication\nnetintel-ocr config set server.api.auth.enabled true\nnetintel-ocr config set server.api.auth.key \"$(openssl rand -hex 32)\"\n\n# Configure TLS\nnetintel-ocr config set server.api.tls.enabled true\nnetintel-ocr config set server.api.tls.cert /etc/ssl/cert.pem\nnetintel-ocr config set server.api.tls.key /etc/ssl/key.pem\n\n# Set CORS policy\nnetintel-ocr config set server.api.cors.origins \"https://app.example.com\"\n</code></pre>"},{"location":"deployment/#3-performance-optimization","title":"3. Performance Optimization","text":"<pre><code># Configure caching\nnetintel-ocr config set cache.enabled true\nnetintel-ocr config set cache.dir /var/cache/netintel\nnetintel-ocr config set cache.size 10GB\n\n# Set resource limits\nnetintel-ocr config set resources.max_memory 8GB\nnetintel-ocr config set resources.max_cpu 4\n\n# Enable GPU acceleration\nnetintel-ocr config set gpu.enabled true\nnetintel-ocr config set gpu.device 0\n</code></pre>"},{"location":"deployment/#4-high-availability","title":"4. High Availability","text":"<pre><code># Configure clustering\nnetintel-ocr config set cluster.enabled true\nnetintel-ocr config set cluster.nodes \"node1:8000,node2:8000,node3:8000\"\n\n# Set up load balancing\nnetintel-ocr config set loadbalancer.algorithm round_robin\nnetintel-ocr config set loadbalancer.health_check_interval 10\n\n# Configure failover\nnetintel-ocr config set failover.enabled true\nnetintel-ocr config set failover.timeout 30\n</code></pre>"},{"location":"deployment/#troubleshooting-deployment","title":"Troubleshooting Deployment","text":""},{"location":"deployment/#common-issues","title":"Common Issues","text":"<pre><code># Check system requirements\nnetintel-ocr system check --verbose\n\n# Verify configuration\nnetintel-ocr config validate --debug\n\n# Test connectivity\nnetintel-ocr system test-connection ollama\nnetintel-ocr system test-connection milvus\n\n# Generate diagnostic report\nnetintel-ocr system diagnose --output diagnostic-report.txt\n</code></pre>"},{"location":"deployment/#debug-mode","title":"Debug Mode","text":"<pre><code># Run with full debug output\nnetintel-ocr --debug --verbose server all\n\n# Debug specific component\nnetintel-ocr --debug server api --component network_processor\n\n# Save debug logs\nnetintel-ocr --debug --log-file debug.log server all\n</code></pre>"},{"location":"deployment/#migration-from-previous-versions","title":"Migration from Previous Versions","text":""},{"location":"deployment/#from-v0116-to-v0117","title":"From v0.1.16 to v0.1.17","text":"<pre><code># Export old configuration\nnetintel-ocr-old --export-config &gt; old-config.json\n\n# Migrate configuration\nnetintel-ocr config migrate old-config.json\n\n# Verify migration\nnetintel-ocr config validate\n\n# Test with new configuration\nnetintel-ocr --dry-run server all\n</code></pre>"},{"location":"deployment/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - Advanced configuration options</li> <li>API Integration - REST API endpoints and usage</li> <li>MCP Server Guide - Model Context Protocol setup</li> <li>Monitoring Guide - Production monitoring setup</li> <li>Troubleshooting Guide - Common issues and solutions</li> </ul>"},{"location":"enterprise-features-guide/","title":"Enterprise Features Guide v0.1.18.0","text":""},{"location":"enterprise-features-guide/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.18.0 includes enterprise-grade features for deduplication, performance monitoring, batch processing, and module management. This guide covers all enterprise capabilities designed for production deployments at scale.</p>"},{"location":"enterprise-features-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Deduplication System</li> <li>Performance Monitoring</li> <li>Batch Processing</li> <li>Module Management</li> <li>Configuration Templates</li> <li>Distributed Processing</li> <li>High Availability</li> <li>Compliance and Audit</li> </ol>"},{"location":"enterprise-features-guide/#deduplication-system","title":"Deduplication System","text":""},{"location":"enterprise-features-guide/#overview_1","title":"Overview","text":"<p>The deduplication system uses multiple methods to identify and eliminate duplicate documents: - MD5: Exact duplicate detection - SimHash: Near-duplicate detection with hamming distance - CDC (Content-Defined Chunking): Block-level deduplication</p>"},{"location":"enterprise-features-guide/#configuration","title":"Configuration","text":"<pre><code># dedup-config.yml\ndeduplication:\n  enabled: true\n  methods:\n    md5:\n      enabled: true\n      store_hashes: true\n\n    simhash:\n      enabled: true\n      bits: 128  # 64 or 128\n      hamming_threshold: 5  # 0-10 for similarity\n\n    cdc:\n      enabled: true\n      min_chunk_size: 4096\n      max_chunk_size: 16384\n      avg_chunk_size: 8192\n      algorithm: \"xxhash\"  # xxhash, md5, sha256\n\n  storage:\n    backend: \"redis\"  # redis, sqlite, postgresql\n    connection:\n      host: localhost\n      port: 6379\n      db: 0\n</code></pre>"},{"location":"enterprise-features-guide/#using-deduplication-api","title":"Using Deduplication API","text":"<pre><code>import requests\nimport hashlib\n\n# Initialize dedup system\nresponse = requests.post(\n    \"http://localhost:8000/api/v2/deduplication/initialize\",\n    headers={\"Authorization\": f\"Bearer {token}\"},\n    json={\n        \"clear_existing\": False,\n        \"config\": {\n            \"simhash_bits\": 128,\n            \"cdc_enabled\": True\n        }\n    }\n)\n\n# Check for duplicates before processing\ndef check_duplicate(file_path):\n    # Calculate MD5\n    with open(file_path, 'rb') as f:\n        md5_hash = hashlib.md5(f.read()).hexdigest()\n\n    response = requests.post(\n        \"http://localhost:8000/api/v2/deduplication/check\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        json={\n            \"document_path\": file_path,\n            \"md5_hash\": md5_hash,\n            \"dedup_mode\": \"full\",  # exact, fuzzy, hybrid, full\n            \"simhash_bits\": 128,\n            \"hamming_threshold\": 5\n        }\n    )\n\n    result = response.json()\n\n    if result[\"is_duplicate\"]:\n        print(f\"Duplicate found: {result['similar_documents']}\")\n        return True\n\n    return False\n\n# Find similar documents\ndef find_similar(document_id, threshold=0.85):\n    response = requests.post(\n        \"http://localhost:8000/api/v2/deduplication/find-similar\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        json={\n            \"document_id\": document_id,\n            \"similarity_threshold\": threshold,\n            \"include_cdc_analysis\": True,\n            \"limit\": 20\n        }\n    )\n\n    return response.json()[\"similar_documents\"]\n</code></pre>"},{"location":"enterprise-features-guide/#advanced-deduplication-with-cdc","title":"Advanced Deduplication with CDC","text":"<pre><code>class CDCDeduplicator:\n    \"\"\"Content-Defined Chunking for block-level deduplication\"\"\"\n\n    def __init__(self, min_size=4096, max_size=16384, avg_size=8192):\n        self.min_size = min_size\n        self.max_size = max_size\n        self.avg_size = avg_size\n        self.mask = avg_size - 1\n        self.chunk_store = {}  # Hash -&gt; content mapping\n\n    def chunk_document(self, content):\n        \"\"\"Split document into content-defined chunks\"\"\"\n        chunks = []\n        offset = 0\n        window_size = 48\n\n        while offset &lt; len(content):\n            # Find chunk boundary using rolling hash\n            chunk_end = min(offset + self.max_size, len(content))\n            chunk_start = offset\n\n            # Look for chunk boundary\n            if offset + self.min_size &lt; len(content):\n                for i in range(offset + self.min_size, chunk_end):\n                    # Rolling hash window\n                    window = content[i-window_size:i]\n                    hash_val = self._rolling_hash(window)\n\n                    if (hash_val &amp; self.mask) == 0:\n                        chunk_end = i\n                        break\n\n            # Extract chunk\n            chunk = content[chunk_start:chunk_end]\n            chunk_hash = hashlib.xxhash64(chunk).hexdigest()\n\n            chunks.append({\n                \"hash\": chunk_hash,\n                \"offset\": chunk_start,\n                \"size\": len(chunk),\n                \"is_duplicate\": chunk_hash in self.chunk_store\n            })\n\n            # Store unique chunks\n            if chunk_hash not in self.chunk_store:\n                self.chunk_store[chunk_hash] = chunk\n\n            offset = chunk_end\n\n        return chunks\n\n    def _rolling_hash(self, data):\n        \"\"\"Calculate rolling hash using xxhash\"\"\"\n        import xxhash\n        return xxhash.xxh64(data).intdigest()\n\n    def calculate_dedup_ratio(self, chunks):\n        \"\"\"Calculate deduplication ratio\"\"\"\n        total_size = sum(c[\"size\"] for c in chunks)\n        unique_size = sum(c[\"size\"] for c in chunks if not c[\"is_duplicate\"])\n\n        dedup_ratio = 1 - (unique_size / total_size) if total_size &gt; 0 else 0\n\n        return {\n            \"total_chunks\": len(chunks),\n            \"unique_chunks\": sum(1 for c in chunks if not c[\"is_duplicate\"]),\n            \"total_size\": total_size,\n            \"unique_size\": unique_size,\n            \"dedup_ratio\": dedup_ratio,\n            \"space_saved\": total_size - unique_size\n        }\n</code></pre>"},{"location":"enterprise-features-guide/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"enterprise-features-guide/#real-time-metrics-collection","title":"Real-time Metrics Collection","text":"<pre><code>class PerformanceMonitor:\n    \"\"\"Enterprise performance monitoring system\"\"\"\n\n    def __init__(self, api_base=\"http://localhost:8000\"):\n        self.api_base = api_base\n        self.metrics_history = []\n\n    def get_current_metrics(self):\n        \"\"\"Get current system metrics\"\"\"\n\n        response = requests.get(\n            f\"{self.api_base}/api/v2/performance/metrics\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        metrics = response.json()\n\n        # Add timestamp\n        metrics[\"timestamp\"] = datetime.now().isoformat()\n        self.metrics_history.append(metrics)\n\n        return metrics\n\n    def run_benchmark(self, test_type=\"comprehensive\"):\n        \"\"\"Run performance benchmark\"\"\"\n\n        benchmarks = {\n            \"simhash\": {\n                \"dataset_size\": 10000,\n                \"iterations\": 5\n            },\n            \"cdc\": {\n                \"dataset_size\": 5000,\n                \"iterations\": 3\n            },\n            \"vector_search\": {\n                \"dataset_size\": 100000,\n                \"iterations\": 10\n            },\n            \"kg_extraction\": {\n                \"dataset_size\": 1000,\n                \"iterations\": 3\n            }\n        }\n\n        results = {}\n\n        for bench_type, params in benchmarks.items():\n            response = requests.post(\n                f\"{self.api_base}/api/v2/performance/benchmark\",\n                headers={\"Authorization\": f\"Bearer {token}\"},\n                json={\n                    \"test_type\": bench_type,\n                    **params\n                }\n            )\n\n            results[bench_type] = response.json()\n\n        return results\n\n    def analyze_performance(self):\n        \"\"\"Analyze performance trends\"\"\"\n\n        if len(self.metrics_history) &lt; 2:\n            return None\n\n        # Calculate trends\n        cpu_trend = self._calculate_trend([m[\"cpu_usage\"][\"current\"] for m in self.metrics_history])\n        memory_trend = self._calculate_trend([m[\"memory\"][\"used_gb\"] for m in self.metrics_history])\n\n        # Identify bottlenecks\n        latest = self.metrics_history[-1]\n\n        bottlenecks = []\n        if latest[\"cpu_usage\"][\"current\"] &gt; 80:\n            bottlenecks.append(\"High CPU usage\")\n        if latest[\"memory\"][\"used_gb\"] / (latest[\"memory\"][\"used_gb\"] + latest[\"memory\"][\"available_gb\"]) &gt; 0.9:\n            bottlenecks.append(\"High memory usage\")\n        if latest[\"processing_stats\"][\"documents_per_hour\"] &lt; 50:\n            bottlenecks.append(\"Low throughput\")\n\n        return {\n            \"trends\": {\n                \"cpu\": cpu_trend,\n                \"memory\": memory_trend\n            },\n            \"bottlenecks\": bottlenecks,\n            \"recommendations\": self._generate_recommendations(bottlenecks)\n        }\n\n    def _calculate_trend(self, values):\n        \"\"\"Calculate trend direction\"\"\"\n        if len(values) &lt; 2:\n            return \"stable\"\n\n        recent = values[-5:]\n        avg_recent = sum(recent) / len(recent)\n        avg_all = sum(values) / len(values)\n\n        if avg_recent &gt; avg_all * 1.1:\n            return \"increasing\"\n        elif avg_recent &lt; avg_all * 0.9:\n            return \"decreasing\"\n        else:\n            return \"stable\"\n\n    def _generate_recommendations(self, bottlenecks):\n        \"\"\"Generate performance recommendations\"\"\"\n\n        recommendations = []\n\n        if \"High CPU usage\" in bottlenecks:\n            recommendations.append(\"Consider scaling horizontally or optimizing algorithms\")\n        if \"High memory usage\" in bottlenecks:\n            recommendations.append(\"Enable swap or increase RAM allocation\")\n        if \"Low throughput\" in bottlenecks:\n            recommendations.append(\"Increase worker count or optimize pipeline\")\n\n        return recommendations\n</code></pre>"},{"location":"enterprise-features-guide/#custom-metrics","title":"Custom Metrics","text":"<pre><code># Define custom metrics\ncustom_metrics = {\n    \"document_processing\": {\n        \"pages_per_second\": 0,\n        \"ocr_accuracy\": 0,\n        \"extraction_errors\": 0\n    },\n    \"search_performance\": {\n        \"avg_latency_ms\": 0,\n        \"queries_per_second\": 0,\n        \"cache_hit_rate\": 0\n    },\n    \"storage_efficiency\": {\n        \"dedup_ratio\": 0,\n        \"compression_ratio\": 0,\n        \"storage_saved_gb\": 0\n    }\n}\n\n# Report custom metrics\nresponse = requests.post(\n    \"http://localhost:8000/api/v2/performance/metrics/custom\",\n    headers={\"Authorization\": f\"Bearer {token}\"},\n    json=custom_metrics\n)\n</code></pre>"},{"location":"enterprise-features-guide/#batch-processing","title":"Batch Processing","text":""},{"location":"enterprise-features-guide/#batch-job-configuration","title":"Batch Job Configuration","text":"<pre><code># batch-config.yml\nbatch_processing:\n  max_workers: 16\n  worker_type: \"process\"  # thread, process, distributed\n  batch_size: 100\n  checkpoint_interval: 500\n  memory_limit: \"8GB\"\n\n  queue:\n    type: \"redis\"  # redis, rabbitmq, sqs\n    max_size: 10000\n    ttl: 86400\n\n  error_handling:\n    max_retries: 3\n    retry_delay: 60\n    dead_letter_queue: true\n\n  output:\n    format: \"jsonl\"\n    compression: \"gzip\"\n    partitioning: \"date\"  # date, size, count\n</code></pre>"},{"location":"enterprise-features-guide/#batch-processing-implementation","title":"Batch Processing Implementation","text":"<pre><code>class EnterpriseBatchProcessor:\n    \"\"\"Enterprise batch processing system\"\"\"\n\n    def __init__(self, config_path=\"batch-config.yml\"):\n        self.config = self._load_config(config_path)\n        self.job_queue = []\n        self.results = {}\n\n    def submit_batch_job(self, input_path, output_path, options=None):\n        \"\"\"Submit batch processing job\"\"\"\n\n        job_request = {\n            \"input_path\": input_path,\n            \"output_path\": output_path,\n            \"parallel_workers\": self.config[\"max_workers\"],\n            \"batch_size\": self.config[\"batch_size\"],\n            \"checkpoint_interval\": self.config[\"checkpoint_interval\"],\n            \"auto_merge\": True,\n            \"skip_existing\": True,\n            \"processing_options\": options or {\n                \"enable_ocr\": True,\n                \"enable_kg\": True,\n                \"enable_vector\": True,\n                \"enable_dedup\": True\n            }\n        }\n\n        response = requests.post(\n            \"http://localhost:8000/api/v2/batch/submit\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=job_request\n        )\n\n        job_info = response.json()\n        self.job_queue.append(job_info[\"batch_id\"])\n\n        return job_info\n\n    def monitor_batch_jobs(self):\n        \"\"\"Monitor all batch jobs\"\"\"\n\n        monitoring_data = {}\n\n        for batch_id in self.job_queue:\n            response = requests.get(\n                f\"http://localhost:8000/api/v2/batch/{batch_id}/progress\",\n                headers={\"Authorization\": f\"Bearer {token}\"}\n            )\n\n            progress = response.json()\n\n            monitoring_data[batch_id] = {\n                \"status\": progress[\"status\"],\n                \"progress\": f\"{progress['processed']}/{progress['total_documents']}\",\n                \"throughput\": progress[\"current_throughput\"],\n                \"eta\": progress[\"eta_minutes\"],\n                \"errors\": progress.get(\"failed\", 0)\n            }\n\n            # Alert on issues\n            if progress[\"failed\"] &gt; 10:\n                self._send_alert(f\"High error rate in batch {batch_id}: {progress['failed']} failures\")\n\n        return monitoring_data\n\n    def handle_failed_documents(self, batch_id):\n        \"\"\"Handle failed documents in batch\"\"\"\n\n        response = requests.get(\n            f\"http://localhost:8000/api/v2/batch/{batch_id}/failures\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        failures = response.json()\n\n        # Retry failed documents\n        retry_batch = {\n            \"documents\": failures[\"failed_documents\"],\n            \"retry_strategy\": \"exponential_backoff\",\n            \"max_retries\": 5\n        }\n\n        response = requests.post(\n            f\"http://localhost:8000/api/v2/batch/{batch_id}/retry\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=retry_batch\n        )\n\n        return response.json()\n\n    def optimize_batch_performance(self, batch_id):\n        \"\"\"Optimize batch processing based on performance\"\"\"\n\n        # Get current performance metrics\n        response = requests.get(\n            f\"http://localhost:8000/api/v2/batch/{batch_id}/metrics\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        metrics = response.json()\n\n        # Calculate optimal settings\n        optimization = {}\n\n        if metrics[\"avg_document_time\"] &gt; 60:  # Slow processing\n            optimization[\"parallel_workers\"] = min(32, self.config[\"max_workers\"] * 2)\n            optimization[\"batch_size\"] = max(10, self.config[\"batch_size\"] // 2)\n\n        if metrics[\"memory_usage\"] &gt; 0.8:  # High memory\n            optimization[\"batch_size\"] = max(10, self.config[\"batch_size\"] // 2)\n            optimization[\"enable_streaming\"] = True\n\n        if metrics[\"error_rate\"] &gt; 0.1:  # High errors\n            optimization[\"validation_level\"] = \"strict\"\n            optimization[\"retry_policy\"] = \"aggressive\"\n\n        # Apply optimizations\n        if optimization:\n            response = requests.patch(\n                f\"http://localhost:8000/api/v2/batch/{batch_id}/optimize\",\n                headers={\"Authorization\": f\"Bearer {token}\"},\n                json=optimization\n            )\n\n            return response.json()\n\n        return {\"status\": \"no_optimization_needed\"}\n</code></pre>"},{"location":"enterprise-features-guide/#distributed-batch-processing","title":"Distributed Batch Processing","text":"<pre><code>import asyncio\nfrom concurrent.futures import ProcessPoolExecutor\nimport multiprocessing as mp\n\nclass DistributedBatchProcessor:\n    \"\"\"Distributed batch processing across multiple nodes\"\"\"\n\n    def __init__(self, nodes):\n        self.nodes = nodes  # List of worker node URLs\n        self.task_queue = mp.Queue()\n        self.result_queue = mp.Queue()\n\n    async def distribute_work(self, documents, strategy=\"round_robin\"):\n        \"\"\"Distribute documents across worker nodes\"\"\"\n\n        if strategy == \"round_robin\":\n            node_assignments = self._round_robin_distribution(documents)\n        elif strategy == \"load_balanced\":\n            node_assignments = await self._load_balanced_distribution(documents)\n        elif strategy == \"locality_aware\":\n            node_assignments = self._locality_aware_distribution(documents)\n        else:\n            raise ValueError(f\"Unknown strategy: {strategy}\")\n\n        # Submit work to nodes\n        tasks = []\n        for node, docs in node_assignments.items():\n            task = self._submit_to_node(node, docs)\n            tasks.append(task)\n\n        # Wait for all nodes to complete\n        results = await asyncio.gather(*tasks)\n\n        return self._merge_results(results)\n\n    def _round_robin_distribution(self, documents):\n        \"\"\"Simple round-robin distribution\"\"\"\n\n        assignments = {node: [] for node in self.nodes}\n\n        for i, doc in enumerate(documents):\n            node = self.nodes[i % len(self.nodes)]\n            assignments[node].append(doc)\n\n        return assignments\n\n    async def _load_balanced_distribution(self, documents):\n        \"\"\"Distribute based on node load\"\"\"\n\n        # Get load from each node\n        loads = {}\n        for node in self.nodes:\n            response = await self._get_node_load(node)\n            loads[node] = response[\"load\"]\n\n        # Sort nodes by load\n        sorted_nodes = sorted(loads.items(), key=lambda x: x[1])\n\n        # Distribute proportionally\n        assignments = {node: [] for node in self.nodes}\n        for i, doc in enumerate(documents):\n            # Assign to least loaded node\n            node = sorted_nodes[0][0]\n            assignments[node].append(doc)\n\n            # Update load estimate\n            sorted_nodes[0] = (node, sorted_nodes[0][1] + 1)\n            sorted_nodes.sort(key=lambda x: x[1])\n\n        return assignments\n\n    async def _submit_to_node(self, node, documents):\n        \"\"\"Submit batch to worker node\"\"\"\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"{node}/process_batch\",\n                json={\"documents\": documents},\n                timeout=aiohttp.ClientTimeout(total=3600)\n            ) as response:\n                return await response.json()\n</code></pre>"},{"location":"enterprise-features-guide/#module-management","title":"Module Management","text":""},{"location":"enterprise-features-guide/#dynamic-module-configuration","title":"Dynamic Module Configuration","text":"<pre><code>class ModuleManager:\n    \"\"\"Enterprise module management system\"\"\"\n\n    def __init__(self):\n        self.modules = self._discover_modules()\n        self.config = self._load_module_config()\n\n    def _discover_modules(self):\n        \"\"\"Discover available modules\"\"\"\n\n        response = requests.get(\n            \"http://localhost:8000/api/v2/modules/status\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        return response.json()\n\n    def enable_module(self, module_name, config=None):\n        \"\"\"Enable a specific module\"\"\"\n\n        request_data = {\n            \"module\": module_name,\n            \"enabled\": True,\n            \"config\": config or {}\n        }\n\n        response = requests.post(\n            f\"http://localhost:8000/api/v2/modules/{module_name}/enable\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=request_data\n        )\n\n        return response.json()\n\n    def configure_modules(self, configuration):\n        \"\"\"Configure multiple modules\"\"\"\n\n        response = requests.post(\n            \"http://localhost:8000/api/v2/modules/configure\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=configuration\n        )\n\n        return response.json()\n\n    def get_module_dependencies(self, module_name):\n        \"\"\"Get module dependencies\"\"\"\n\n        response = requests.get(\n            f\"http://localhost:8000/api/v2/modules/{module_name}/dependencies\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        return response.json()\n\n    def validate_module_configuration(self):\n        \"\"\"Validate current module configuration\"\"\"\n\n        response = requests.post(\n            \"http://localhost:8000/api/v2/modules/validate\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        validation_result = response.json()\n\n        if not validation_result[\"valid\"]:\n            print(\"Configuration issues found:\")\n            for issue in validation_result[\"issues\"]:\n                print(f\"  - {issue}\")\n\n        return validation_result\n\n    def optimize_module_loading(self):\n        \"\"\"Optimize module loading order\"\"\"\n\n        # Get module dependencies\n        dependencies = {}\n        for module in self.modules[\"installed\"]:\n            deps = self.get_module_dependencies(module)\n            dependencies[module] = deps[\"dependencies\"]\n\n        # Topological sort for optimal loading order\n        loading_order = self._topological_sort(dependencies)\n\n        return {\n            \"optimal_order\": loading_order,\n            \"current_order\": list(self.modules[\"installed\"].keys()),\n            \"recommendation\": \"Apply optimal loading order for faster startup\"\n        }\n\n    def _topological_sort(self, dependencies):\n        \"\"\"Topological sort for dependency resolution\"\"\"\n\n        visited = set()\n        stack = []\n\n        def visit(module):\n            if module in visited:\n                return\n\n            visited.add(module)\n\n            for dep in dependencies.get(module, []):\n                visit(dep)\n\n            stack.append(module)\n\n        for module in dependencies:\n            visit(module)\n\n        return stack[::-1]\n</code></pre>"},{"location":"enterprise-features-guide/#configuration-templates","title":"Configuration Templates","text":""},{"location":"enterprise-features-guide/#template-management","title":"Template Management","text":"<pre><code>class ConfigurationTemplateManager:\n    \"\"\"Manage and apply configuration templates\"\"\"\n\n    def __init__(self):\n        self.templates = self._load_templates()\n\n    def _load_templates(self):\n        \"\"\"Load available templates\"\"\"\n\n        response = requests.get(\n            \"http://localhost:8000/api/v2/config/templates\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n\n        return response.json()[\"templates\"]\n\n    def apply_template(self, template_name, customizations=None):\n        \"\"\"Apply configuration template\"\"\"\n\n        request_data = {\n            \"template\": template_name,\n            \"customize\": customizations or {}\n        }\n\n        response = requests.post(\n            \"http://localhost:8000/api/v2/config/apply-template\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=request_data\n        )\n\n        return response.json()\n\n    def create_custom_template(self, name, config):\n        \"\"\"Create custom configuration template\"\"\"\n\n        template_data = {\n            \"name\": name,\n            \"description\": f\"Custom template created on {datetime.now()}\",\n            \"config\": config,\n            \"metadata\": {\n                \"created_by\": \"admin\",\n                \"version\": \"1.0.0\",\n                \"compatible_versions\": [\"0.1.18.0\"]\n            }\n        }\n\n        response = requests.post(\n            \"http://localhost:8000/api/v2/config/templates/create\",\n            headers={\"Authorization\": f\"Bearer {token}\"},\n            json=template_data\n        )\n\n        return response.json()\n\n    def get_template_recommendations(self, workload_profile):\n        \"\"\"Get template recommendations based on workload\"\"\"\n\n        profiles = {\n            \"small\": \"minimal\",\n            \"medium\": \"development\",\n            \"large\": \"production\",\n            \"enterprise\": \"enterprise\",\n            \"cloud\": \"cloud\"\n        }\n\n        recommended = profiles.get(workload_profile, \"minimal\")\n\n        # Get template details\n        template = next((t for t in self.templates if t[\"name\"] == recommended), None)\n\n        return {\n            \"recommended_template\": recommended,\n            \"reason\": f\"Best suited for {workload_profile} workloads\",\n            \"config\": template,\n            \"alternatives\": [t[\"name\"] for t in self.templates if t[\"name\"] != recommended]\n        }\n</code></pre>"},{"location":"enterprise-features-guide/#enterprise-configuration-examples","title":"Enterprise Configuration Examples","text":"<pre><code># enterprise-config.yml\nenterprise:\n  deployment:\n    mode: \"distributed\"\n    nodes: 8\n    regions: [\"us-east\", \"us-west\", \"eu-central\"]\n\n  high_availability:\n    enabled: true\n    replication_factor: 3\n    failover_timeout: 30\n    health_check_interval: 10\n\n  security:\n    encryption_at_rest: true\n    encryption_in_transit: true\n    audit_logging: true\n    compliance_mode: [\"HIPAA\", \"PCI-DSS\", \"SOC2\"]\n\n  performance:\n    cache_size: \"32GB\"\n    worker_threads: 32\n    connection_pool_size: 100\n    batch_size: 1000\n\n  monitoring:\n    metrics_collection_interval: 10\n    log_level: \"INFO\"\n    alerting:\n      enabled: true\n      channels: [\"email\", \"slack\", \"pagerduty\"]\n\n  backup:\n    enabled: true\n    schedule: \"0 2 * * *\"\n    retention_days: 30\n    destinations: [\"s3\", \"azure\", \"local\"]\n</code></pre>"},{"location":"enterprise-features-guide/#distributed-processing","title":"Distributed Processing","text":""},{"location":"enterprise-features-guide/#multi-node-architecture","title":"Multi-Node Architecture","text":"<pre><code>class DistributedOrchestrator:\n    \"\"\"Orchestrate processing across multiple nodes\"\"\"\n\n    def __init__(self, config):\n        self.nodes = config[\"nodes\"]\n        self.coordinator_url = config[\"coordinator\"]\n        self.health_checker = HealthChecker(self.nodes)\n\n    async def process_distributed(self, job):\n        \"\"\"Process job across distributed nodes\"\"\"\n\n        # 1. Split job into tasks\n        tasks = self._split_job(job)\n\n        # 2. Check node health\n        healthy_nodes = await self.health_checker.get_healthy_nodes()\n\n        # 3. Distribute tasks\n        assignments = self._assign_tasks(tasks, healthy_nodes)\n\n        # 4. Execute tasks\n        results = await self._execute_distributed(assignments)\n\n        # 5. Handle failures\n        failed_tasks = [t for t in results if t[\"status\"] == \"failed\"]\n        if failed_tasks:\n            results = await self._handle_failures(failed_tasks)\n\n        # 6. Aggregate results\n        return self._aggregate_results(results)\n\n    def _split_job(self, job):\n        \"\"\"Split job into distributable tasks\"\"\"\n\n        tasks = []\n        chunk_size = job[\"total_documents\"] // len(self.nodes)\n\n        for i in range(len(self.nodes)):\n            start = i * chunk_size\n            end = start + chunk_size if i &lt; len(self.nodes) - 1 else job[\"total_documents\"]\n\n            tasks.append({\n                \"id\": f\"task_{i}\",\n                \"start\": start,\n                \"end\": end,\n                \"job_id\": job[\"id\"],\n                \"config\": job[\"config\"]\n            })\n\n        return tasks\n\n    async def _execute_distributed(self, assignments):\n        \"\"\"Execute tasks on assigned nodes\"\"\"\n\n        async def execute_on_node(node, task):\n            try:\n                async with aiohttp.ClientSession() as session:\n                    async with session.post(\n                        f\"{node}/execute\",\n                        json=task,\n                        timeout=aiohttp.ClientTimeout(total=3600)\n                    ) as response:\n                        return await response.json()\n            except Exception as e:\n                return {\n                    \"status\": \"failed\",\n                    \"error\": str(e),\n                    \"task\": task\n                }\n\n        tasks = []\n        for node, node_tasks in assignments.items():\n            for task in node_tasks:\n                tasks.append(execute_on_node(node, task))\n\n        return await asyncio.gather(*tasks)\n</code></pre>"},{"location":"enterprise-features-guide/#high-availability","title":"High Availability","text":""},{"location":"enterprise-features-guide/#failover-configuration","title":"Failover Configuration","text":"<pre><code>class HighAvailabilityManager:\n    \"\"\"Manage high availability and failover\"\"\"\n\n    def __init__(self, config):\n        self.primary = config[\"primary\"]\n        self.replicas = config[\"replicas\"]\n        self.health_check_interval = config[\"health_check_interval\"]\n        self.failover_timeout = config[\"failover_timeout\"]\n\n    async def monitor_health(self):\n        \"\"\"Monitor health of all nodes\"\"\"\n\n        while True:\n            # Check primary\n            primary_healthy = await self._check_node_health(self.primary)\n\n            if not primary_healthy:\n                # Initiate failover\n                await self._initiate_failover()\n\n            # Check replicas\n            for replica in self.replicas:\n                replica_healthy = await self._check_node_health(replica)\n                if not replica_healthy:\n                    await self._handle_replica_failure(replica)\n\n            await asyncio.sleep(self.health_check_interval)\n\n    async def _initiate_failover(self):\n        \"\"\"Initiate failover to replica\"\"\"\n\n        # Select new primary\n        for replica in self.replicas:\n            if await self._check_node_health(replica):\n                # Promote replica to primary\n                await self._promote_to_primary(replica)\n\n                # Update configuration\n                self.replicas.remove(replica)\n                self.replicas.append(self.primary)\n                self.primary = replica\n\n                # Notify clients\n                await self._notify_failover(replica)\n\n                break\n\n    async def _promote_to_primary(self, node):\n        \"\"\"Promote replica to primary\"\"\"\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"{node}/promote\",\n                json={\"role\": \"primary\"}\n            ) as response:\n                return await response.json()\n</code></pre>"},{"location":"enterprise-features-guide/#compliance-and-audit","title":"Compliance and Audit","text":""},{"location":"enterprise-features-guide/#audit-system","title":"Audit System","text":"<pre><code>class ComplianceAuditSystem:\n    \"\"\"Enterprise compliance and audit system\"\"\"\n\n    def __init__(self):\n        self.audit_log = []\n        self.compliance_rules = self._load_compliance_rules()\n\n    def log_operation(self, operation):\n        \"\"\"Log operation for audit\"\"\"\n\n        audit_entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"operation\": operation[\"type\"],\n            \"user\": operation[\"user\"],\n            \"resource\": operation[\"resource\"],\n            \"result\": operation[\"result\"],\n            \"metadata\": operation.get(\"metadata\", {})\n        }\n\n        self.audit_log.append(audit_entry)\n\n        # Check compliance\n        violations = self._check_compliance(audit_entry)\n        if violations:\n            self._handle_violations(violations)\n\n        # Persist to audit store\n        self._persist_audit_entry(audit_entry)\n\n    def generate_compliance_report(self, standard=\"SOC2\"):\n        \"\"\"Generate compliance report\"\"\"\n\n        report = {\n            \"standard\": standard,\n            \"period\": {\n                \"start\": datetime.now() - timedelta(days=30),\n                \"end\": datetime.now()\n            },\n            \"summary\": {},\n            \"details\": [],\n            \"violations\": [],\n            \"recommendations\": []\n        }\n\n        # Analyze audit log\n        for entry in self.audit_log:\n            # Check against compliance rules\n            for rule in self.compliance_rules[standard]:\n                if not self._evaluate_rule(rule, entry):\n                    report[\"violations\"].append({\n                        \"rule\": rule[\"name\"],\n                        \"entry\": entry,\n                        \"severity\": rule[\"severity\"]\n                    })\n\n        # Generate summary\n        report[\"summary\"] = {\n            \"total_operations\": len(self.audit_log),\n            \"violations\": len(report[\"violations\"]),\n            \"compliance_score\": 100 - (len(report[\"violations\"]) / len(self.audit_log) * 100)\n        }\n\n        return report\n\n    def _check_compliance(self, entry):\n        \"\"\"Check entry against compliance rules\"\"\"\n\n        violations = []\n\n        for standard, rules in self.compliance_rules.items():\n            for rule in rules:\n                if not self._evaluate_rule(rule, entry):\n                    violations.append({\n                        \"standard\": standard,\n                        \"rule\": rule,\n                        \"entry\": entry\n                    })\n\n        return violations\n\n    def _evaluate_rule(self, rule, entry):\n        \"\"\"Evaluate compliance rule\"\"\"\n\n        # Example rule evaluation\n        if rule[\"type\"] == \"data_retention\":\n            # Check if data retention policy is followed\n            return True\n\n        if rule[\"type\"] == \"access_control\":\n            # Check if proper access controls are in place\n            return entry[\"user\"] in rule[\"allowed_users\"]\n\n        if rule[\"type\"] == \"encryption\":\n            # Check if data is encrypted\n            return entry.get(\"metadata\", {}).get(\"encrypted\", False)\n\n        return True\n</code></pre>"},{"location":"enterprise-features-guide/#best-practices","title":"Best Practices","text":""},{"location":"enterprise-features-guide/#1-deduplication-strategy","title":"1. Deduplication Strategy","text":"<pre><code># Optimal deduplication pipeline\ndef optimal_dedup_pipeline(document):\n    # 1. Quick MD5 check\n    if check_md5_exists(document):\n        return \"exact_duplicate\"\n\n    # 2. SimHash for near-duplicates\n    if check_simhash_similarity(document) &gt; 0.95:\n        return \"near_duplicate\"\n\n    # 3. CDC for partial duplicates\n    chunks = cdc_chunk(document)\n    if get_dedup_ratio(chunks) &gt; 0.5:\n        return \"partial_duplicate\"\n\n    return \"unique\"\n</code></pre>"},{"location":"enterprise-features-guide/#2-batch-processing-optimization","title":"2. Batch Processing Optimization","text":"<pre><code># Optimal batch configuration\noptimal_batch = {\n    \"workers\": min(32, cpu_count() * 2),\n    \"batch_size\": 100 if memory_available() &gt; 16 else 50,\n    \"checkpoint_interval\": 500,\n    \"error_strategy\": \"dead_letter_queue\",\n    \"monitoring\": \"prometheus\"\n}\n</code></pre>"},{"location":"enterprise-features-guide/#3-module-loading","title":"3. Module Loading","text":"<pre><code># Load modules in optimal order\nmodule_order = [\n    \"base\",\n    \"performance\",  # C++ extensions first\n    \"kg\",           # Heavy modules\n    \"vector\",\n    \"api\",          # API last\n    \"mcp\"\n]\n</code></pre>"},{"location":"enterprise-features-guide/#next-steps","title":"Next Steps","text":"<ol> <li>Configure Security: See the Authentication &amp; Security Guide</li> <li>Deploy to Production: Follow the Production Deployment Guide</li> <li>Learn API v2: Read the API v2 Guide</li> </ol>"},{"location":"installation/","title":"Installation Guide","text":"<p>New in v0.1.17.1: Modular Installation</p> <p>NetIntel-OCR v0.1.17.1 introduces modular installation, reducing the base installation from ~2.5GB to ~500MB. Install only the features you need!</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":""},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Linux (Ubuntu 20.04+, RHEL 8+, or compatible)</li> <li>Python: 3.10, 3.11, or 3.12</li> <li>Memory: Minimum 8GB RAM (16GB+ recommended for Knowledge Graph)</li> <li>Storage: 2GB minimum (varies with optional modules)</li> </ul>"},{"location":"installation/#required-software","title":"Required Software","text":"<pre><code># Install Python and system dependencies\nsudo apt-get update\nsudo apt-get install -y \\\n    python3.11 \\\n    python3.11-venv \\\n    python3.11-dev \\\n    gcc g++ \\\n    libgl1-mesa-glx \\\n    libglib2.0-0\n\n# Install Ollama for LLM support\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull the default OCR model\nollama pull nanonets-ocr-s:latest\n</code></pre>"},{"location":"installation/#installation-options","title":"Installation Options","text":""},{"location":"installation/#quick-install-base-only","title":"\ud83d\ude80 Quick Install (Base Only)","text":"<p>The base installation includes core OCR functionality with network diagram detection (~500MB):</p> <pre><code># Install base package\npip install netintel-ocr\n\n# Verify installation\nnetintel-ocr --version\n</code></pre>"},{"location":"installation/#modular-installation","title":"\ud83d\udce6 Modular Installation","text":"<p>Choose the features you need with modular installation:</p>"},{"location":"installation/#knowledge-graph-support-15gb","title":"Knowledge Graph Support (+1.5GB)","text":"<pre><code># Install with Knowledge Graph support\npip install \"netintel-ocr[kg]\"\n\n# This adds:\n# - PyKEEN for knowledge graph embeddings\n# - torch for deep learning\n# - FalkorDB for graph storage\n# - scikit-learn, matplotlib, plotly for analysis\n</code></pre>"},{"location":"installation/#vector-store-support-300mb","title":"Vector Store Support (+300MB)","text":"<pre><code># Install with vector database support\npip install \"netintel-ocr[vector]\"\n\n# This adds:\n# - pymilvus for Milvus integration\n# - qdrant-client for Qdrant support\n# - chromadb for ChromaDB\n# - lancedb for LanceDB\n</code></pre>"},{"location":"installation/#api-server-support-50mb","title":"API Server Support (+50MB)","text":"<pre><code># Install with REST API server\npip install \"netintel-ocr[api]\"\n\n# This adds:\n# - FastAPI web framework\n# - uvicorn ASGI server\n# - python-multipart for file uploads\n</code></pre>"},{"location":"installation/#mcp-server-support-30mb","title":"MCP Server Support (+30MB)","text":"<pre><code># Install with Model Context Protocol server\npip install \"netintel-ocr[mcp]\"\n\n# This adds:\n# - fastmcp for MCP protocol\n# - websockets for real-time communication\n</code></pre>"},{"location":"installation/#performance-optimizations-200mb","title":"Performance Optimizations (+200MB)","text":"<pre><code># Install with C++ performance optimizations\npip install \"netintel-ocr[performance]\"\n\n# This adds:\n# - numpy with MKL optimizations\n# - numba for JIT compilation\n# - cython for C extensions\n</code></pre>"},{"location":"installation/#development-tools-100mb","title":"Development Tools (+100MB)","text":"<pre><code># Install with development and testing tools\npip install \"netintel-ocr[dev]\"\n\n# This adds:\n# - pytest for testing\n# - black for code formatting\n# - ruff for linting\n# - mypy for type checking\n</code></pre>"},{"location":"installation/#preset-configurations","title":"\ud83c\udfaf Preset Configurations","text":""},{"location":"installation/#production-installation","title":"Production Installation","text":"<pre><code># Includes: KG + Vector + API + Performance\npip install \"netintel-ocr[production]\"\n</code></pre>"},{"location":"installation/#cloud-deployment","title":"Cloud Deployment","text":"<pre><code># Includes: Vector + API + MCP\npip install \"netintel-ocr[cloud]\"\n</code></pre>"},{"location":"installation/#complete-installation","title":"Complete Installation","text":"<pre><code># Install everything\npip install \"netintel-ocr[all]\"\n</code></pre>"},{"location":"installation/#checking-installation-status","title":"Checking Installation Status","text":""},{"location":"installation/#version-information","title":"Version Information","text":"<p>The enhanced <code>--version</code> command shows comprehensive installation status:</p> <pre><code>netintel-ocr --version\n</code></pre> <p>Output example: <pre><code>NetIntel-OCR v0.1.17.1\n\u251c\u2500\u2500 Core Components:\n\u2502   \u251c\u2500\u2500 C++ Core: \u2713 v1.0.1\n\u2502   \u251c\u2500\u2500 AVX2: \u2713\n\u2502   \u251c\u2500\u2500 OpenMP: \u2713\n\u2502   \u2514\u2500\u2500 Platform: Linux x86_64\n\u251c\u2500\u2500 Installed Modules:\n\u2502   \u251c\u2500\u2500 [base] Core OCR: \u2713 (always installed)\n\u2502   \u251c\u2500\u2500 [kg] Knowledge Graph: \u2713 (pykeen 1.10.1)\n\u2502   \u251c\u2500\u2500 [vector] Vector Store: \u2713 (pymilvus 2.3.0)\n\u2502   \u251c\u2500\u2500 [api] API Server: \u2717 (not installed)\n\u2502   \u2514\u2500\u2500 [mcp] MCP Server: \u2717 (not installed)\n\u251c\u2500\u2500 Available for Install:\n\u2502   \u251c\u2500\u2500 [api] API Server: pip install netintel-ocr[api]\n\u2502   \u2502   \u2514\u2500\u2500 Adds: fastapi, uvicorn (+50MB)\n\u2502   \u2514\u2500\u2500 [mcp] MCP Server: pip install netintel-ocr[mcp]\n\u2502       \u2514\u2500\u2500 Adds: fastmcp, websockets (+30MB)\n\u2514\u2500\u2500 Active Features:\n    \u251c\u2500\u2500 FalkorDB: \u2713 (connected to localhost:6379)\n    \u251c\u2500\u2500 Milvus: \u2713 (connected to localhost:19530)\n    \u2514\u2500\u2500 Ollama: \u2713 (connected to localhost:11434)\n</code></pre></p>"},{"location":"installation/#json-output","title":"JSON Output","text":"<p>For programmatic use, get JSON output:</p> <pre><code>netintel-ocr --version --json\n</code></pre>"},{"location":"installation/#docker-installation","title":"Docker Installation","text":""},{"location":"installation/#using-pre-built-image","title":"Using Pre-built Image","text":"<pre><code># Pull the Docker image\ndocker pull netintel/netintel-ocr:0.1.17.1\n\n# Run with base features\ndocker run -v $(pwd):/data netintel/netintel-ocr:0.1.17.1 process pdf document.pdf\n</code></pre>"},{"location":"installation/#building-custom-image","title":"Building Custom Image","text":"<pre><code># Dockerfile for custom installation\nFROM python:3.11-slim\n\n# Install only what you need\nRUN pip install netintel-ocr[kg,vector]\n\n# Your configuration...\n</code></pre>"},{"location":"installation/#environment-configuration","title":"Environment Configuration","text":""},{"location":"installation/#knowledge-graph-configuration","title":"Knowledge Graph Configuration","text":"<pre><code># Set environment variables for KG support\nexport FALKORDB_HOST=localhost\nexport FALKORDB_PORT=6379\nexport MINIRAG_LLM=\"ollama/gemma3:4b-it-qat\"\nexport MINIRAG_EMBEDDING=\"ollama/qwen3-embedding:8b\"\n</code></pre>"},{"location":"installation/#milvus-configuration","title":"Milvus Configuration","text":"<pre><code># Configure Milvus vector store\nexport MILVUS_HOST=localhost\nexport MILVUS_PORT=19530\nexport MILVUS_COLLECTION=netintel_vectors\n</code></pre>"},{"location":"installation/#ollama-configuration","title":"Ollama Configuration","text":"<pre><code># Configure Ollama endpoint\nexport OLLAMA_HOST=\"http://localhost:11434\"\n</code></pre>"},{"location":"installation/#upgrading-from-v0117","title":"Upgrading from v0.1.17","text":""},{"location":"installation/#for-minimal-users","title":"For Minimal Users","text":"<p>If you only need core OCR: <pre><code>pip uninstall netintel-ocr\npip install netintel-ocr==0.1.17.1\n</code></pre></p>"},{"location":"installation/#for-full-installation-users","title":"For Full Installation Users","text":"<p>If you had everything installed in v0.1.17: <pre><code>pip uninstall netintel-ocr\npip install \"netintel-ocr[all]==0.1.17.1\"\n</code></pre></p>"},{"location":"installation/#checking-what-you-need","title":"Checking What You Need","text":"<p>Run this before upgrading to see what features you're using: <pre><code>netintel-ocr --version --detailed\n</code></pre></p>"},{"location":"installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"installation/#module-not-found-errors","title":"Module Not Found Errors","text":"<p>If you get \"module not found\" errors: <pre><code># Check what's installed\nnetintel-ocr --version\n\n# Install missing module (example for KG)\npip install \"netintel-ocr[kg]\"\n</code></pre></p>"},{"location":"installation/#connection-errors","title":"Connection Errors","text":"<p>If features show as \"not connected\": <pre><code># Start required services\ndocker-compose up -d falkordb milvus\nollama serve\n</code></pre></p>"},{"location":"installation/#performance-issues","title":"Performance Issues","text":"<p>If processing is slow: <pre><code># Install performance optimizations\npip install \"netintel-ocr[performance]\"\n\n# Enable GPU support (if available)\npip install \"netintel-ocr[kg]\"  # Includes torch with CUDA\n</code></pre></p>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Process your first document</li> <li>Configuration Guide - Configure NetIntel-OCR</li> <li>Knowledge Graph Setup - Enable KG features</li> <li>API Documentation - Use the REST API</li> </ul>"},{"location":"installation/#support","title":"Support","text":"<p>For installation issues: - Check Troubleshooting Guide - View GitHub Issues - Join Discord Community</p>"},{"location":"kg-model-configuration/","title":"Knowledge Graph Model Configuration","text":"<p>NetIntel-OCR v0.1.17 supports configurable OLLAMA models for embedding and inference in the Knowledge Graph CLI.</p>"},{"location":"kg-model-configuration/#model-configuration-methods","title":"Model Configuration Methods","text":""},{"location":"kg-model-configuration/#1-command-line-options","title":"1. Command-Line Options","text":"<p>Most KG commands that use MiniRAG or HybridRetriever now support model selection:</p> <pre><code># Specify models directly\nnetintel-ocr kg rag-query \"Find compliance issues\" \\\n  --llm-model \"ollama/gemma3:4b-it-qat\" \\\n  --embedding-model \"ollama/Qwen3-Embedding-8B\"\n\n# Other commands with model support\nnetintel-ocr kg entity-context ENTITY_ID \\\n  --llm-model \"ollama/llama3:8b\" \\\n  --embedding-model \"ollama/nomic-embed-text\"\n\nnetintel-ocr kg hybrid-search \"security vulnerabilities\" \\\n  --llm-model \"ollama/mistral:7b\" \\\n  --embedding-model \"ollama/mxbai-embed-large\"\n</code></pre>"},{"location":"kg-model-configuration/#2-environment-variables","title":"2. Environment Variables","text":"<p>Set default models using environment variables:</p> <pre><code># Set LLM model for inference\nexport MINIRAG_LLM=\"ollama/gemma3:4b-it-qat\"\n\n# Set embedding model\nexport MINIRAG_EMBEDDING=\"ollama/Qwen3-Embedding-8B\"\n\n# Set embedding dimensions (must match model)\nexport MINIRAG_EMBEDDING_DIM=\"4096\"\n\n# Configure OLLAMA server\nexport OLLAMA_HOST=\"localhost\"\nexport OLLAMA_PORT=\"11434\"\n</code></pre>"},{"location":"kg-model-configuration/#3-supported-commands","title":"3. Supported Commands","text":"<p>The following commands support <code>--llm-model</code> and <code>--embedding-model</code> options:</p> <ul> <li>rag-query: Query using Enhanced MiniRAG with KG embeddings</li> <li>entity-context: Get rich context for an entity using MiniRAG</li> <li>hybrid-search: Perform hybrid search with advanced retrieval strategies</li> <li>compare-strategies: Compare different retrieval strategies</li> <li>batch-query: Process batch queries from file</li> </ul>"},{"location":"kg-model-configuration/#available-ollama-models","title":"Available OLLAMA Models","text":""},{"location":"kg-model-configuration/#recommended-llm-models","title":"Recommended LLM Models","text":"<ul> <li><code>ollama/gemma3:4b-it-qat</code> (Default, optimized for speed)</li> <li><code>ollama/llama3:8b</code> (Better quality, slower)</li> <li><code>ollama/mistral:7b</code> (Good balance)</li> <li><code>ollama/qwen2.5:7b</code> (Multilingual support)</li> </ul>"},{"location":"kg-model-configuration/#recommended-embedding-models","title":"Recommended Embedding Models","text":"<ul> <li><code>ollama/Qwen3-Embedding-8B</code> (Default, 4096 dimensions)</li> <li><code>ollama/nomic-embed-text</code> (768 dimensions, faster)</li> <li><code>ollama/mxbai-embed-large</code> (1024 dimensions)</li> <li><code>ollama/bge-large</code> (1024 dimensions)</li> </ul>"},{"location":"kg-model-configuration/#examples","title":"Examples","text":""},{"location":"kg-model-configuration/#basic-query-with-custom-models","title":"Basic Query with Custom Models","text":"<pre><code>netintel-ocr kg rag-query \"What are the latest security patches?\" \\\n  --llm-model \"ollama/llama3:8b\" \\\n  --embedding-model \"ollama/nomic-embed-text\" \\\n  --mode hybrid\n</code></pre>"},{"location":"kg-model-configuration/#entity-context-with-environment-variables","title":"Entity Context with Environment Variables","text":"<pre><code># Set defaults\nexport MINIRAG_LLM=\"ollama/mistral:7b\"\nexport MINIRAG_EMBEDDING=\"ollama/mxbai-embed-large\"\n\n# Use defaults\nnetintel-ocr kg entity-context USER_123 --context-size 3\n</code></pre>"},{"location":"kg-model-configuration/#batch-processing-with-custom-models","title":"Batch Processing with Custom Models","text":"<pre><code>netintel-ocr kg batch-query queries.txt \\\n  --llm-model \"ollama/qwen2.5:7b\" \\\n  --embedding-model \"ollama/bge-large\" \\\n  --output results.json\n</code></pre>"},{"location":"kg-model-configuration/#strategy-comparison","title":"Strategy Comparison","text":"<pre><code>netintel-ocr kg compare-strategies \"compliance violations\" \\\n  --llm-model \"ollama/gemma3:4b-it-qat\" \\\n  --embedding-model \"ollama/Qwen3-Embedding-8B\" \\\n  --limit 10\n</code></pre>"},{"location":"kg-model-configuration/#model-selection-guidelines","title":"Model Selection Guidelines","text":""},{"location":"kg-model-configuration/#for-speed","title":"For Speed","text":"<ul> <li>LLM: <code>ollama/gemma3:4b-it-qat</code></li> <li>Embedding: <code>ollama/nomic-embed-text</code></li> </ul>"},{"location":"kg-model-configuration/#for-quality","title":"For Quality","text":"<ul> <li>LLM: <code>ollama/llama3:8b</code> or <code>ollama/mistral:7b</code></li> <li>Embedding: <code>ollama/Qwen3-Embedding-8B</code></li> </ul>"},{"location":"kg-model-configuration/#for-multilingual","title":"For Multilingual","text":"<ul> <li>LLM: <code>ollama/qwen2.5:7b</code></li> <li>Embedding: <code>ollama/multilingual-e5-large</code></li> </ul>"},{"location":"kg-model-configuration/#checking-available-models","title":"Checking Available Models","text":"<p>To see what models are available on your OLLAMA server:</p> <pre><code># List all available models\nollama list\n\n# Check if specific model is available\nollama show gemma3:4b-it-qat\n</code></pre>"},{"location":"kg-model-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"kg-model-configuration/#model-not-found","title":"Model Not Found","text":"<p>If you get a \"model not found\" error, pull the model first: <pre><code>ollama pull gemma3:4b-it-qat\nollama pull Qwen3-Embedding-8B\n</code></pre></p>"},{"location":"kg-model-configuration/#dimension-mismatch","title":"Dimension Mismatch","text":"<p>Ensure MINIRAG_EMBEDDING_DIM matches your embedding model: - Qwen3-Embedding-8B: 4096 - nomic-embed-text: 768 - mxbai-embed-large: 1024</p>"},{"location":"kg-model-configuration/#connection-issues","title":"Connection Issues","text":"<p>Check OLLAMA server: <pre><code>netintel-ocr kg check-requirements --verbose\n</code></pre></p> <p>This will show if OLLAMA is accessible and list available models.</p>"},{"location":"knowledge-graph/","title":"Knowledge Graph Processing","text":""},{"location":"knowledge-graph/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.17 introduces powerful Knowledge Graph (KG) capabilities that automatically extract and structure relationships from your network documentation. The system creates semantic graphs from network diagrams, flow charts, and technical text, enabling advanced querying and relationship analysis.</p> <p>Model Categories</p> <p>NetIntel-OCR uses two distinct categories of models:</p> <p>INGESTION MODELS (for PDF processing): - <code>qwen2.5vl:7b</code> - Network diagram analysis - <code>Nanonets-OCR-s:latest</code> - OCR text extraction</p> <p>MINIRAG MODELS (for Q&amp;A after ingestion): - <code>gemma3:4b-it-qat</code> - Answer generation - <code>qwen3-embedding:8b</code> - Semantic search</p> <p>These are separate model sets - ingestion models process documents, MiniRAG models enable Q&amp;A!</p> <p>New in v0.1.17</p> <p>Knowledge Graph processing is enabled by default in v0.1.17. No additional flags needed!</p>"},{"location":"knowledge-graph/#quick-start","title":"Quick Start","text":""},{"location":"knowledge-graph/#basic-usage","title":"Basic Usage","text":"<pre><code># Process with KG enabled (default)\nnetintel-ocr process pdf document.pdf\n\n# Explicitly disable KG if not needed\nnetintel-ocr process pdf document.pdf --no-kg\n</code></pre>"},{"location":"knowledge-graph/#what-gets-extracted","title":"What Gets Extracted","text":"<p>The Knowledge Graph system automatically identifies and extracts:</p> <ul> <li>Network Components: Routers, switches, firewalls, servers, load balancers</li> <li>Relationships: Connections, data flows, dependencies, configurations</li> <li>Attributes: IP addresses, VLANs, protocols, ports, bandwidths</li> <li>Topologies: Network paths, redundancy patterns, hierarchies</li> <li>Business Context: Services, applications, security zones</li> </ul>"},{"location":"knowledge-graph/#architecture","title":"Architecture","text":""},{"location":"knowledge-graph/#components","title":"Components","text":"<pre><code>graph LR\n    A[PDF Document] --&gt; B[OCR Engine]\n    B --&gt; C[KG Constructor]\n    C --&gt; D[FalkorDB]\n    C --&gt; E[PyKEEN Embeddings]\n    D --&gt; F[Graph Queries]\n    E --&gt; F\n    F --&gt; G[Hybrid Retrieval]</code></pre>"},{"location":"knowledge-graph/#storage-layers","title":"Storage Layers","text":"<ol> <li>FalkorDB: Graph database for storing entities and relationships</li> <li>Milvus: Vector database for text embeddings (4096D)</li> <li>KG Embeddings: 200D knowledge graph embeddings stored as properties</li> </ol>"},{"location":"knowledge-graph/#configuration","title":"Configuration","text":""},{"location":"knowledge-graph/#kg-model-selection","title":"KG Model Selection","text":"<p>Choose from 8 different embedding models based on your use case:</p> <pre><code># TransE - Fast, good for simple relationships\nnetintel-ocr process pdf document.pdf --kg-model TransE\n\n# RotatE - Best for complex relationships (default)\nnetintel-ocr process pdf document.pdf --kg-model RotatE\n\n# ComplEx - Good for symmetric relationships\nnetintel-ocr process pdf document.pdf --kg-model ComplEx\n\n# Available models: TransE, RotatE, ComplEx, DistMult, ConvE, TuckER, HolE, RESCAL\n</code></pre>"},{"location":"knowledge-graph/#training-parameters","title":"Training Parameters","text":"<pre><code># Customize training epochs (default: 100)\nnetintel-ocr process pdf document.pdf --kg-epochs 200\n\n# Adjust batch size (default: 256)\nnetintel-ocr kg train-embeddings --batch-size 512\n\n# Combined configuration\nnetintel-ocr process pdf document.pdf \\\n  --kg-model RotatE \\\n  --kg-epochs 150 \\\n  --kg-batch-size 384\n</code></pre>"},{"location":"knowledge-graph/#external-services-configuration","title":"External Services Configuration","text":"<pre><code># Configure external Ollama server\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\n\n# Verify Ollama models are available\ncurl $OLLAMA_HOST/api/tags | jq '.models[].name'\n\n# Models for different purposes:\n# INGESTION: qwen2.5vl:7b, Nanonets-OCR-s:latest\n# MINIRAG: gemma3:4b-it-qat, qwen3-embedding:8b\n\n# Custom FalkorDB host/port\nnetintel-ocr process pdf document.pdf \\\n  --falkordb-host 192.168.1.100 \\\n  --falkordb-port 6379\n\n# Using environment variables\nexport FALKORDB_HOST=falkordb.local\nexport FALKORDB_PORT=6379\nexport OLLAMA_HOST=\"http://192.168.1.100:11434\"\nnetintel-ocr process pdf document.pdf\n</code></pre>"},{"location":"knowledge-graph/#processing-modes","title":"Processing Modes","text":""},{"location":"knowledge-graph/#network-diagrams","title":"Network Diagrams","text":"<p>When processing network diagrams, the KG system:</p> <ol> <li>Identifies network components from visual elements</li> <li>Extracts connection relationships from lines/arrows</li> <li>Preserves spatial layout information</li> <li>Links related text annotations</li> </ol> <pre><code># Process network-only with KG\nnetintel-ocr process pdf document.pdf --network-only\n\n# Output includes:\n# - network_topology.json (graph structure)\n# - kg_embeddings.npy (learned embeddings)\n# - relationships.cypher (import queries)\n</code></pre>"},{"location":"knowledge-graph/#flow-diagrams","title":"Flow Diagrams","text":"<p>For flow diagrams and process charts:</p> <ol> <li>Extracts process steps as entities</li> <li>Maps flow direction as relationships</li> <li>Captures decision points and branches</li> <li>Associates metadata and conditions</li> </ol> <pre><code># Process with flow detection (uses INGESTION model)\nnetintel-ocr process pdf document.pdf --flow-model qwen2.5vl:7b  # Ingestion model, NOT MiniRAG\n</code></pre>"},{"location":"knowledge-graph/#hybrid-processing","title":"Hybrid Processing","text":"<p>Combines multiple extraction methods:</p> <pre><code># Full hybrid processing (default)\nnetintel-ocr process pdf document.pdf\n\n# This enables:\n# - Network diagram KG extraction\n# - Flow diagram relationship mapping\n# - Table structure preservation\n# - Text entity recognition\n</code></pre>"},{"location":"knowledge-graph/#knowledge-graph-cli-commands","title":"Knowledge Graph CLI Commands","text":""},{"location":"knowledge-graph/#check-system-requirements","title":"Check System Requirements","text":"<pre><code># Check if all KG requirements are installed\nnetintel-ocr kg check-requirements\n\n# Check with verbose output\nnetintel-ocr kg check-requirements --verbose\n</code></pre>"},{"location":"knowledge-graph/#initialize-kg-system","title":"Initialize KG System","text":"<pre><code># Initialize FalkorDB indices and schema\nnetintel-ocr kg init\nnetintel-ocr kg init --falkordb-host localhost --falkordb-port 6379\n\n# With authentication\nnetintel-ocr kg init --password your_password --graph-name custom_kg\n</code></pre>"},{"location":"knowledge-graph/#process-documents-with-kg","title":"Process Documents with KG","text":"<pre><code># Process a document with KG generation\nnetintel-ocr kg process document.pdf\nnetintel-ocr kg process --model RotatE --epochs 100 document.pdf\n\n# Process with specific configuration\nnetintel-ocr kg process \\\n  --kg-model ComplEx \\\n  --batch-size 512 \\\n  --force-retrain \\\n  document.pdf\n</code></pre>"},{"location":"knowledge-graph/#view-statistics","title":"View Statistics","text":"<pre><code># Display Knowledge Graph statistics\nnetintel-ocr kg stats\nnetintel-ocr kg stats --format json\nnetintel-ocr kg stats --format table\n\n# Display embedding statistics\nnetintel-ocr kg embedding-stats\nnetintel-ocr kg embedding-stats --detailed\n</code></pre>"},{"location":"knowledge-graph/#train-kg-embeddings","title":"Train KG Embeddings","text":"<pre><code># Train embeddings with PyKEEN\nnetintel-ocr kg train-embeddings\nnetintel-ocr kg train-embeddings --model RotatE --epochs 150\n\n# Force retrain existing embeddings\nnetintel-ocr kg train-embeddings --force --model ComplEx\n\n# Available models: TransE, RotatE, ComplEx, DistMult, ConvE, TuckER, HolE, RESCAL\n</code></pre>"},{"location":"knowledge-graph/#query-the-knowledge-graph","title":"Query the Knowledge Graph","text":"<pre><code># Execute Cypher queries\nnetintel-ocr kg query \"MATCH (n:NetworkDevice) RETURN n LIMIT 10\"\nnetintel-ocr kg query --format json \"MATCH (n)-[r]-&gt;(m) RETURN n,r,m LIMIT 5\"\n\n# Find paths between entities\nnetintel-ocr kg path-find \"Router-A\" \"Server-DB\"\nnetintel-ocr kg path-find --max-depth 5 --bidirectional \"DMZ\" \"Internal\"\n\n# Get entity context\nnetintel-ocr kg entity-context \"Firewall-Main\"\nnetintel-ocr kg entity-context --expand-depth 2 --include-embeddings \"Router-Core\"\n</code></pre>"},{"location":"knowledge-graph/#similarity-and-clustering","title":"Similarity and Clustering","text":"<pre><code># Find similar entities\nnetintel-ocr kg find-similar \"Router-A\"\nnetintel-ocr kg find-similar --limit 10 --threshold 0.7 \"Switch-Core\"\n\n# Compute similarity between entities\nnetintel-ocr kg similarity \"Router-A\" \"Router-B\"\nnetintel-ocr kg similarity --method cosine \"Server-1\" \"Server-2\"\n\n# Cluster entities by embeddings\nnetintel-ocr kg cluster\nnetintel-ocr kg cluster --n-clusters 5 --method kmeans\nnetintel-ocr kg cluster --min-samples 3 --eps 0.5 --method dbscan\n</code></pre>"},{"location":"knowledge-graph/#advanced-retrieval","title":"Advanced Retrieval","text":"<pre><code># Classify query intent\nnetintel-ocr kg classify-query \"What connects to the firewall?\"\nnetintel-ocr kg classify-query --verbose \"Show network topology\"\n\n# Hybrid search with multiple strategies\nnetintel-ocr kg hybrid-search \"security vulnerabilities in DMZ\"\nnetintel-ocr kg hybrid-search \\\n  --strategy adaptive \\\n  --limit 20 \\\n  --expand-hops 3 \\\n  \"database connections\"\n\n# Compare retrieval strategies\nnetintel-ocr kg compare-strategies \"network redundancy paths\"\nnetintel-ocr kg compare-strategies --detailed --format json \"firewall rules\"\n\n# RAG-enhanced query\nnetintel-ocr kg rag-query \"What are the security implications?\"\nnetintel-ocr kg rag-query \\\n  --mode hybrid \\\n  --context-depth 2 \\\n  --temperature 0.7 \\\n  \"explain the network architecture\"\n</code></pre>"},{"location":"knowledge-graph/#batch-operations","title":"Batch Operations","text":"<pre><code># Process batch queries\nnetintel-ocr kg batch-query queries.txt\nnetintel-ocr kg batch-query --output results.json --parallel 4 queries.txt\n\n# Format for queries.txt:\n# What connects to Router-A?\n# Find path from DMZ to Database\n# Show similar devices to Firewall-1\n</code></pre>"},{"location":"knowledge-graph/#visualization","title":"Visualization","text":"<pre><code># Visualize embeddings\nnetintel-ocr kg visualize\nnetintel-ocr kg visualize --method tsne --dimensions 2\nnetintel-ocr kg visualize --method pca --dimensions 3 --output embeddings.html\nnetintel-ocr kg visualize --color-by type --save-plot embeddings.png\n</code></pre>"},{"location":"knowledge-graph/#export-and-import","title":"Export and Import","text":"<pre><code># Export Knowledge Graph\nnetintel-ocr kg export --format cypher --output network.cypher\nnetintel-ocr kg export --format json --output graph.json\nnetintel-ocr kg export --format graphml --output network.graphml\n\n# Include embeddings in export\nnetintel-ocr kg export --include-embeddings --format json --output full_graph.json\n</code></pre>"},{"location":"knowledge-graph/#query-types","title":"Query Types","text":"<p>The system supports 6 query types:</p> <ol> <li>Entity-Centric: Information about specific components</li> <li>Relational: Connection and dependency queries</li> <li>Topological: Path finding and network analysis</li> <li>Semantic: Content-based similarity search</li> <li>Analytical: Aggregations and statistics</li> <li>Exploratory: Pattern discovery</li> </ol>"},{"location":"knowledge-graph/#example-python-usage","title":"Example Python Usage","text":"<pre><code># Python API usage\nfrom netintel_ocr.kg import HybridSystem, FalkorDBManager, HybridRetriever\n\n# Initialize system\nmanager = FalkorDBManager(host=\"localhost\", port=6379)\nhybrid = HybridSystem(manager)\n\n# Process document\nresults = await hybrid.process_document(\"document.pdf\")\n\n# Initialize retriever\nretriever = HybridRetriever(manager)\n\n# Perform searches\nentity_results = await retriever.hybrid_search(\n    query=\"Router-Core-1\",\n    strategy=\"graph_first\"\n)\n\npath_results = await retriever.hybrid_search(\n    query=\"path from DMZ-Switch to Internal-DB\",\n    strategy=\"adaptive\"\n)\n</code></pre>"},{"location":"knowledge-graph/#batch-processing-with-kg","title":"Batch Processing with KG","text":""},{"location":"knowledge-graph/#process-multiple-documents","title":"Process Multiple Documents","text":"<pre><code># Batch process with KG (enabled by default)\nnetintel-ocr process batch *.pdf\n\n# Batch with custom KG settings\nnetintel-ocr process batch \\\n  --kg-model ComplEx \\\n  --kg-epochs 200 \\\n  --max-parallel 4 \\\n  *.pdf\n</code></pre>"},{"location":"knowledge-graph/#building-unified-knowledge-base","title":"Building Unified Knowledge Base","text":"<pre><code># Ingest to shared knowledge graph\nnetintel-ocr process batch \\\n  --collection enterprise_kg \\\n  --kg-merge-strategy union \\\n  /docs/**/*.pdf\n</code></pre>"},{"location":"knowledge-graph/#integration-with-minirag","title":"Integration with MiniRAG","text":""},{"location":"knowledge-graph/#enhanced-retrieval","title":"Enhanced Retrieval","text":"<p>The KG system enhances MiniRAG (Retrieval Augmented Generation) with:</p> <ul> <li>Graph-aware context: Include related entities in context</li> <li>Path-based retrieval: Follow relationships for comprehensive answers</li> <li>Hybrid scoring: Combine vector similarity with graph distance</li> </ul> <p>MiniRAG Models</p> <p>MiniRAG uses its own models (<code>gemma3:4b-it-qat</code>, <code>qwen3-embedding:8b</code>) for Q&amp;A, which are separate from the ingestion models used during PDF processing.</p> <pre><code># Process document with KG enabled (default)\nnetintel-ocr process pdf document.pdf\n\n# Query with Enhanced MiniRAG\nnetintel-ocr kg rag-query \"What are the dependencies of Service-A?\"\n\n# RAG query with specific options\nnetintel-ocr kg rag-query \\\n  --mode hybrid \\\n  --context-depth 2 \\\n  --temperature 0.7 \\\n  \"explain the network topology\"\n</code></pre>"},{"location":"knowledge-graph/#retrieval-strategies","title":"Retrieval Strategies","text":"<pre><code># Use hybrid search with different strategies\n# Vector-first (fast, good for content)\nnetintel-ocr kg hybrid-search --strategy vector_first \"security policies\"\n\n# Graph-first (accurate for relationships)\nnetintel-ocr kg hybrid-search --strategy graph_first \"what connects to firewall\"\n\n# Parallel (balanced approach)\nnetintel-ocr kg hybrid-search --strategy parallel \"network redundancy\"\n\n# Adaptive (query-dependent, default)\nnetintel-ocr kg hybrid-search --strategy adaptive \"database vulnerabilities\"\n\n# Compare all strategies for a query\nnetintel-ocr kg compare-strategies \"network topology analysis\"\n</code></pre>"},{"location":"knowledge-graph/#performance-optimization","title":"Performance Optimization","text":""},{"location":"knowledge-graph/#memory-management","title":"Memory Management","text":"<pre><code># Limit graph size for large documents\nnetintel-ocr process pdf document.pdf \\\n  --kg-max-entities 10000 \\\n  --kg-max-relations 50000\n\n# Stream processing for very large graphs\nnetintel-ocr process pdf large_document.pdf \\\n  --kg-streaming \\\n  --kg-chunk-size 1000\n</code></pre>"},{"location":"knowledge-graph/#gpu-acceleration","title":"GPU Acceleration","text":"<pre><code># Enable GPU for embeddings training\nnetintel-ocr process pdf document.pdf \\\n  --kg-gpu \\\n  --kg-device cuda:0\n\n# Multi-GPU training\nnetintel-ocr process pdf document.pdf \\\n  --kg-gpu \\\n  --kg-device cuda:0,cuda:1 \\\n  --kg-distributed\n</code></pre>"},{"location":"knowledge-graph/#docker-deployment","title":"Docker Deployment","text":""},{"location":"knowledge-graph/#quick-start-with-docker-compose","title":"Quick Start with Docker Compose","text":"<pre><code># docker-compose.kg.yml\nversion: '3.8'\n\nservices:\n  falkordb:\n    image: falkordb/falkordb:latest\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - falkordb_data:/data\n\n  milvus:\n    image: milvusdb/milvus:latest\n    ports:\n      - \"19530:19530\"\n    volumes:\n      - milvus_data:/var/lib/milvus\n\n  netintel-ocr:\n    image: visionml/netintel-ocr:v0.1.17\n    environment:\n      - FALKORDB_HOST=falkordb\n      - MILVUS_HOST=milvus:19530\n      - OLLAMA_HOST=http://your-ollama-server:11434  # External Ollama\n    volumes:\n      - ./documents:/documents\n      - ./output:/output\n\nvolumes:\n  falkordb_data:\n  milvus_data:\n</code></pre> <p>Start the stack:</p> <pre><code>docker-compose -f docker-compose.kg.yml up -d\n</code></pre>"},{"location":"knowledge-graph/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"knowledge-graph/#helm-installation","title":"Helm Installation","text":"<pre><code># Add NetIntel-OCR helm repo\nhelm repo add netintel https://visionml.net/helm\nhelm repo update\n\n# Install with KG enabled and external Ollama\nhelm install netintel-ocr netintel/netintel-ocr \\\n  --set kg.enabled=true \\\n  --set falkordb.enabled=true \\\n  --set milvus.enabled=true \\\n  --set ollama.host=\"http://your-ollama-server:11434\"\n</code></pre>"},{"location":"knowledge-graph/#custom-values","title":"Custom Values","text":"<pre><code># values-kg.yaml\nkg:\n  enabled: true\n  model: RotatE\n  epochs: 150\n  batchSize: 384\n\nollama:\n  host: \"http://your-ollama-server:11434\"  # External Ollama server\n\nfalkordb:\n  enabled: true\n  persistence:\n    size: 10Gi\n\nmilvus:\n  enabled: true\n  persistence:\n    size: 50Gi\n</code></pre>"},{"location":"knowledge-graph/#monitoring-analytics","title":"Monitoring &amp; Analytics","text":""},{"location":"knowledge-graph/#kg-statistics","title":"KG Statistics","text":"<pre><code># View graph statistics\nnetintel-ocr kg stats\n\n# Detailed statistics in different formats\nnetintel-ocr kg stats --format json\nnetintel-ocr kg stats --format table\nnetintel-ocr kg stats --format summary\n\n# View embedding statistics\nnetintel-ocr kg embedding-stats\nnetintel-ocr kg embedding-stats --detailed\n\n# Example output:\n# Graph Statistics:\n#   Total nodes: 1,247\n#   Total edges: 3,892\n#   Node types: NetworkDevice(156), Service(89), Zone(12)\n#   Edge types: CONNECTS_TO(2341), DEPENDS_ON(893), CONTAINS(658)\n#   Average degree: 6.2\n#   Connected components: 3\n</code></pre>"},{"location":"knowledge-graph/#training-monitoring","title":"Training Monitoring","text":"<pre><code># Train with progress monitoring\nnetintel-ocr kg train-embeddings \\\n  --model RotatE \\\n  --epochs 150 \\\n  --verbose\n\n# View training history\nnetintel-ocr kg embedding-stats --show-history\n</code></pre>"},{"location":"knowledge-graph/#troubleshooting","title":"Troubleshooting","text":""},{"location":"knowledge-graph/#common-issues","title":"Common Issues","text":"<p>KG processing is slow: <pre><code># Reduce epochs for faster processing\nnetintel-ocr process pdf document.pdf --kg-epochs 50\n\n# Or disable if not needed\nnetintel-ocr process pdf document.pdf --no-kg\n</code></pre></p> <p>Out of memory errors: <pre><code># Reduce batch size\nnetintel-ocr kg train-embeddings --batch-size 128\n\n# Enable streaming mode\nnetintel-ocr process pdf document.pdf --kg-streaming\n</code></pre></p> <p>FalkorDB connection issues: <pre><code># Check FalkorDB status\nredis-cli -h localhost -p 6379 ping\n\n# Verify graph module\nredis-cli MODULE LIST\n</code></pre></p>"},{"location":"knowledge-graph/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug output\nnetintel-ocr --debug process pdf document.pdf --kg-verbose\n\n# Save intermediate results\nnetintel-ocr process pdf document.pdf \\\n  --kg-save-intermediate \\\n  --output-dir ./debug\n</code></pre>"},{"location":"knowledge-graph/#api-reference","title":"API Reference","text":""},{"location":"knowledge-graph/#python-api","title":"Python API","text":"<pre><code>import os\nfrom netintel_ocr.kg import KnowledgeGraphSystem\n\n# Configure external Ollama\nos.environ['OLLAMA_HOST'] = \"http://your-ollama-server:11434\"\n\n# Initialize KG system\nkg_system = KnowledgeGraphSystem(\n    falkordb_host=\"localhost\",\n    falkordb_port=6379,\n    model=\"RotatE\",\n    epochs=100,\n    ollama_host=os.environ.get('OLLAMA_HOST', 'http://localhost:11434')\n)\n\n# Process document\ngraph = kg_system.process_document(\"document.pdf\")\n\n# Query graph\nresults = kg_system.query(\n    query_type=\"entity_centric\",\n    entity=\"Router-A\"\n)\n\n# Export graph\nkg_system.export(\n    format=\"cypher\",\n    output=\"network_graph.cypher\"\n)\n</code></pre>"},{"location":"knowledge-graph/#rest-api","title":"REST API","text":"<pre><code># Process with KG\ncurl -X POST http://localhost:8000/process \\\n  -F \"file=@document.pdf\" \\\n  -F \"enable_kg=true\" \\\n  -F \"kg_model=RotatE\"\n\n# Query KG\ncurl -X GET http://localhost:8000/kg/query \\\n  -d \"entity=Router-A\" \\\n  -d \"hops=2\"\n</code></pre>"},{"location":"knowledge-graph/#best-practices","title":"Best Practices","text":"<ol> <li>Model Selection:</li> <li>Use <code>TransE</code> for simple, hierarchical networks</li> <li>Use <code>RotatE</code> (default) for complex topologies</li> <li> <p>Use <code>ComplEx</code> for bidirectional relationships</p> </li> <li> <p>Performance:</p> </li> <li>Start with 100 epochs, increase if needed</li> <li>Use GPU for documents &gt; 50 pages</li> <li> <p>Enable streaming for very large graphs</p> </li> <li> <p>Integration:</p> </li> <li>Always persist graphs to FalkorDB for reuse</li> <li>Combine with vector search for best results</li> <li>Use batch processing for document sets</li> </ol>"},{"location":"knowledge-graph/#migration-from-v0116","title":"Migration from v0.1.16","text":"<p>If upgrading from v0.1.16:</p> <ol> <li>KG is now enabled by default - no flags needed</li> <li>Dependencies are included - no separate install required</li> <li>Use <code>--no-kg</code> to disable if you want v0.1.16 behavior</li> </ol> <pre><code># v0.1.16 behavior (no KG)\nnetintel-ocr process pdf document.pdf --no-kg\n\n# v0.1.17 default (with KG)\nnetintel-ocr process pdf document.pdf\n</code></pre>"},{"location":"knowledge-graph/#additional-resources","title":"Additional Resources","text":"<ul> <li>KG Architecture Specification</li> <li>PyKEEN Documentation</li> <li>FalkorDB Documentation</li> <li>Example Notebooks</li> </ul>"},{"location":"knowledge-graph/#complete-kg-command-reference","title":"Complete KG Command Reference","text":""},{"location":"knowledge-graph/#all-available-commands","title":"All Available Commands","text":"Command Description Example <code>check-requirements</code> Check if all requirements are installed <code>netintel-ocr kg check-requirements</code> <code>init</code> Initialize FalkorDB indices and schema <code>netintel-ocr kg init</code> <code>stats</code> Display Knowledge Graph statistics <code>netintel-ocr kg stats --format json</code> <code>process</code> Process document with KG generation <code>netintel-ocr kg process document.pdf</code> <code>query</code> Execute Cypher query on the graph <code>netintel-ocr kg query \"MATCH (n) RETURN n\"</code> <code>train-embeddings</code> Train PyKEEN KG embeddings <code>netintel-ocr kg train-embeddings --model RotatE</code> <code>embedding-stats</code> Display embedding statistics <code>netintel-ocr kg embedding-stats</code> <code>similarity</code> Compute similarity between entities <code>netintel-ocr kg similarity \"A\" \"B\"</code> <code>find-similar</code> Find similar entities <code>netintel-ocr kg find-similar \"Router-A\"</code> <code>visualize</code> Visualize embeddings in 2D/3D <code>netintel-ocr kg visualize --method tsne</code> <code>cluster</code> Cluster entities by embeddings <code>netintel-ocr kg cluster --n-clusters 5</code> <code>path-find</code> Find paths between entities <code>netintel-ocr kg path-find \"A\" \"B\"</code> <code>entity-context</code> Get rich context for entity <code>netintel-ocr kg entity-context \"Server-1\"</code> <code>rag-query</code> Query using Enhanced MiniRAG <code>netintel-ocr kg rag-query \"explain topology\"</code> <code>classify-query</code> Classify query intent <code>netintel-ocr kg classify-query \"what connects?\"</code> <code>hybrid-search</code> Hybrid search with strategies <code>netintel-ocr kg hybrid-search \"security\"</code> <code>compare-strategies</code> Compare retrieval strategies <code>netintel-ocr kg compare-strategies \"query\"</code> <code>batch-query</code> Process batch queries <code>netintel-ocr kg batch-query queries.txt</code> <code>export</code> Export Knowledge Graph <code>netintel-ocr kg export --format json</code>"},{"location":"knowledge-graph/#quick-reference-card","title":"Quick Reference Card","text":"<pre><code># Essential Setup\nnetintel-ocr kg check-requirements            # Verify installation\nnetintel-ocr kg init                          # Initialize KG system\nnetintel-ocr kg stats                         # Check system status\n\n# Document Processing\nnetintel-ocr process pdf document.pdf                     # Process with KG (default)\nnetintel-ocr process pdf document.pdf --no-kg            # Process without KG\nnetintel-ocr kg process document.pdf                      # Explicit KG processing\n\n# Training &amp; Embeddings\nnetintel-ocr kg train-embeddings             # Train with defaults\nnetintel-ocr kg train-embeddings --force     # Force retrain\nnetintel-ocr kg embedding-stats              # View embedding info\n\n# Querying\nnetintel-ocr kg query \"MATCH (n) RETURN n\"   # Cypher query\nnetintel-ocr kg rag-query \"explain this\"     # Natural language query\nnetintel-ocr kg hybrid-search \"topic\"        # Hybrid search\n\n# Analysis\nnetintel-ocr kg find-similar \"entity\"        # Find similar entities\nnetintel-ocr kg path-find \"A\" \"B\"           # Find paths\nnetintel-ocr kg cluster                      # Cluster entities\n\n# Export\nnetintel-ocr kg export --format json         # Export as JSON\nnetintel-ocr kg export --format cypher       # Export as Cypher\n</code></pre>"},{"location":"knowledge-graph/#support","title":"Support","text":"<p>For KG-related issues:</p> <pre><code># View available commands and options\nnetintel-ocr kg --help\n\n# Get help for specific command\nnetintel-ocr kg init --help\nnetintel-ocr kg train-embeddings --help\n\n# Check system status\nnetintel-ocr kg stats --format json\n</code></pre>"},{"location":"knowledge-graph/#common-troubleshooting-commands","title":"Common Troubleshooting Commands","text":"<pre><code># Check all requirements first\nnetintel-ocr kg check-requirements --verbose\n\n# Verify FalkorDB connection\nnetintel-ocr kg init\n\n# Check if embeddings exist\nnetintel-ocr kg embedding-stats\n\n# Test with simple query\nnetintel-ocr kg query \"MATCH (n) RETURN count(n)\"\n\n# Verify MiniRAG models (separate from ingestion)\ncurl $OLLAMA_HOST/api/tags | grep -E \"gemma3|qwen3-embedding\"\n</code></pre> <p>Contact support with diagnostic output for faster resolution.</p>"},{"location":"mcp-integration-v0.1.18/","title":"MCP (Model Context Protocol) Integration Guide v0.1.18.0","text":""},{"location":"mcp-integration-v0.1.18/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.18.0 provides comprehensive MCP (Model Context Protocol) support, enabling seamless integration with AI assistants and LLM agents. This guide covers all 15 tools, 6 resources, and 5 prompts available in the MCP implementation.</p>"},{"location":"mcp-integration-v0.1.18/#table-of-contents","title":"Table of Contents","text":"<ol> <li>MCP Server Setup</li> <li>MCP Tools</li> <li>MCP Resources</li> <li>MCP Prompts</li> <li>Integration Examples</li> <li>Best Practices</li> </ol>"},{"location":"mcp-integration-v0.1.18/#mcp-server-setup","title":"MCP Server Setup","text":""},{"location":"mcp-integration-v0.1.18/#starting-the-mcp-server","title":"Starting the MCP Server","text":"<pre><code># Start MCP server\nnetintel-ocr server mcp --port 3000\n\n# Start with specific configuration\nnetintel-ocr server mcp --port 3000 --config mcp-config.yml\n\n# Start all servers (API + MCP)\nnetintel-ocr server all --api-port 8000 --mcp-port 3000\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#configuration","title":"Configuration","text":"<pre><code># mcp-config.yml\nmcp:\n  server:\n    port: 3000\n    host: 0.0.0.0\n    cors_enabled: true\n    allowed_origins:\n      - http://localhost:*\n      - https://claude.ai\n\n  rate_limiting:\n    enabled: true\n    requests_per_minute: 100\n    burst_size: 20\n\n  authentication:\n    enabled: true\n    api_key_header: X-MCP-API-Key\n\n  tools:\n    enabled: true\n    timeout: 30000  # 30 seconds\n\n  resources:\n    enabled: true\n    cache_ttl: 3600  # 1 hour\n\n  prompts:\n    enabled: true\n    max_context_size: 100000\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#connecting-from-claude-or-other-llms","title":"Connecting from Claude or Other LLMs","text":"<pre><code>// claude_config.json\n{\n  \"mcpServers\": {\n    \"netintel-ocr\": {\n      \"command\": \"netintel-ocr\",\n      \"args\": [\"server\", \"mcp\"],\n      \"env\": {\n        \"NETINTEL_API_KEY\": \"your-api-key\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#mcp-tools","title":"MCP Tools","text":"<p>NetIntel-OCR provides 15 specialized tools for document intelligence operations.</p>"},{"location":"mcp-integration-v0.1.18/#document-operations-tools-5","title":"Document Operations Tools (5)","text":""},{"location":"mcp-integration-v0.1.18/#1-intelligent_query","title":"1. intelligent_query","text":"<p>Performs intelligent queries with automatic mode selection.</p> <pre><code>// Tool Definition\n{\n  name: \"intelligent_query\",\n  description: \"Smart query with auto mode selection based on query intent\",\n  parameters: {\n    query: string,\n    mode?: \"auto\" | \"vector\" | \"kg\" | \"hybrid\",\n    filters?: {\n      document_type?: string[],\n      date_range?: { start: string, end: string },\n      confidence_min?: number\n    },\n    max_results?: number\n  }\n}\n\n// Example Usage\nconst result = await mcp.callTool(\"intelligent_query\", {\n  query: \"Find all firewall configurations in the network diagrams\",\n  mode: \"auto\",\n  filters: {\n    document_type: [\"network_diagram\"],\n    confidence_min: 0.8\n  },\n  max_results: 10\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-compare_documents","title":"2. compare_documents","text":"<p>Compares multiple documents to find similarities and differences.</p> <pre><code>// Tool Definition\n{\n  name: \"compare_documents\",\n  description: \"Compare multiple documents for similarities and differences\",\n  parameters: {\n    document_ids: string[],\n    comparison_type: \"content\" | \"structure\" | \"entities\" | \"all\",\n    include_visualizations?: boolean\n  }\n}\n\n// Example Usage\nconst comparison = await mcp.callTool(\"compare_documents\", {\n  document_ids: [\"doc_123\", \"doc_456\", \"doc_789\"],\n  comparison_type: \"all\",\n  include_visualizations: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-analyze_network_path","title":"3. analyze_network_path","text":"<p>Analyzes network paths and connections in diagrams.</p> <pre><code>// Tool Definition\n{\n  name: \"analyze_network_path\",\n  description: \"Analyze network paths and connections\",\n  parameters: {\n    start_point: string,\n    end_point?: string,\n    path_type: \"shortest\" | \"all\" | \"secure\" | \"redundant\",\n    include_metrics?: boolean\n  }\n}\n\n// Example Usage\nconst analysis = await mcp.callTool(\"analyze_network_path\", {\n  start_point: \"internet_gateway\",\n  end_point: \"database_server\",\n  path_type: \"secure\",\n  include_metrics: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#4-check_compliance","title":"4. check_compliance","text":"<p>Checks documents against compliance standards.</p> <pre><code>// Tool Definition\n{\n  name: \"check_compliance\",\n  description: \"Check documents against compliance standards\",\n  parameters: {\n    document_id: string,\n    standards: string[],  // [\"PCI-DSS\", \"HIPAA\", \"SOC2\", etc.]\n    detailed_report?: boolean\n  }\n}\n\n// Example Usage\nconst compliance = await mcp.callTool(\"check_compliance\", {\n  document_id: \"doc_123\",\n  standards: [\"PCI-DSS\", \"SOC2\"],\n  detailed_report: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#5-extract_entities","title":"5. extract_entities","text":"<p>Extracts named entities from documents.</p> <pre><code>// Tool Definition\n{\n  name: \"extract_entities\",\n  description: \"Extract named entities from documents\",\n  parameters: {\n    document_id: string,\n    entity_types?: string[],  // [\"IP\", \"HOSTNAME\", \"PERSON\", etc.]\n    confidence_threshold?: number,\n    include_relationships?: boolean\n  }\n}\n\n// Example Usage\nconst entities = await mcp.callTool(\"extract_entities\", {\n  document_id: \"doc_123\",\n  entity_types: [\"IP_ADDRESS\", \"HOSTNAME\", \"NETWORK_DEVICE\"],\n  confidence_threshold: 0.7,\n  include_relationships: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#milvus-operations-tools-5","title":"Milvus Operations Tools (5)","text":""},{"location":"mcp-integration-v0.1.18/#6-create_milvus_collection","title":"6. create_milvus_collection","text":"<p>Creates a new Milvus collection with schema.</p> <pre><code>// Tool Definition\n{\n  name: \"create_milvus_collection\",\n  description: \"Create a new Milvus collection with schema\",\n  parameters: {\n    collection_name: string,\n    dimension: number,\n    index_type?: string,\n    metric_type?: string,\n    additional_fields?: Array&lt;{\n      name: string,\n      type: string,\n      max_length?: number\n    }&gt;\n  }\n}\n\n// Example Usage\nconst collection = await mcp.callTool(\"create_milvus_collection\", {\n  collection_name: \"network_diagrams\",\n  dimension: 768,\n  index_type: \"IVF_FLAT\",\n  metric_type: \"L2\",\n  additional_fields: [\n    { name: \"content\", type: \"varchar\", max_length: 65535 },\n    { name: \"metadata\", type: \"json\" }\n  ]\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#7-milvus_vector_search","title":"7. milvus_vector_search","text":"<p>Performs vector similarity search in Milvus.</p> <pre><code>// Tool Definition\n{\n  name: \"milvus_vector_search\",\n  description: \"Perform vector similarity search\",\n  parameters: {\n    collection_name: string,\n    query_vector: number[] | string,  // vector or text to embed\n    top_k?: number,\n    filter?: string,\n    output_fields?: string[]\n  }\n}\n\n// Example Usage\nconst results = await mcp.callTool(\"milvus_vector_search\", {\n  collection_name: \"documents\",\n  query_vector: \"firewall configuration best practices\",\n  top_k: 5,\n  filter: \"category == 'security'\",\n  output_fields: [\"content\", \"metadata\", \"score\"]\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#8-milvus_hybrid_search","title":"8. milvus_hybrid_search","text":"<p>Performs hybrid search combining vector and scalar filters.</p> <pre><code>// Tool Definition\n{\n  name: \"milvus_hybrid_search\",\n  description: \"Hybrid search combining vector and scalar conditions\",\n  parameters: {\n    collection_name: string,\n    vector_query: number[] | string,\n    scalar_filters: object,\n    alpha?: number,  // weight between vector and scalar (0-1)\n    top_k?: number\n  }\n}\n\n// Example Usage\nconst results = await mcp.callTool(\"milvus_hybrid_search\", {\n  collection_name: \"documents\",\n  vector_query: \"network security\",\n  scalar_filters: {\n    date: { \"$gte\": \"2024-01-01\" },\n    type: { \"$in\": [\"diagram\", \"architecture\"] }\n  },\n  alpha: 0.7,\n  top_k: 10\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#9-manage_milvus_collection","title":"9. manage_milvus_collection","text":"<p>Manages Milvus collection operations.</p> <pre><code>// Tool Definition\n{\n  name: \"manage_milvus_collection\",\n  description: \"Manage Milvus collection operations\",\n  parameters: {\n    collection_name: string,\n    operation: \"load\" | \"release\" | \"flush\" | \"compact\" | \"drop\",\n    params?: object\n  }\n}\n\n// Example Usage\nawait mcp.callTool(\"manage_milvus_collection\", {\n  collection_name: \"documents\",\n  operation: \"load\",\n  params: { replica_number: 2 }\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#10-get_collection_stats","title":"10. get_collection_stats","text":"<p>Retrieves collection statistics and metrics.</p> <pre><code>// Tool Definition\n{\n  name: \"get_collection_stats\",\n  description: \"Get collection statistics and metrics\",\n  parameters: {\n    collection_name: string,\n    include_index_info?: boolean,\n    include_segments?: boolean\n  }\n}\n\n// Example Usage\nconst stats = await mcp.callTool(\"get_collection_stats\", {\n  collection_name: \"documents\",\n  include_index_info: true,\n  include_segments: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#knowledge-graph-operations-tools-5","title":"Knowledge Graph Operations Tools (5)","text":""},{"location":"mcp-integration-v0.1.18/#11-kg_initialize","title":"11. kg_initialize","text":"<p>Initializes FalkorDB knowledge graph.</p> <pre><code>// Tool Definition\n{\n  name: \"kg_initialize\",\n  description: \"Initialize FalkorDB knowledge graph\",\n  parameters: {\n    graph_name?: string,\n    clear_existing?: boolean,\n    schema?: object\n  }\n}\n\n// Example Usage\nawait mcp.callTool(\"kg_initialize\", {\n  graph_name: \"network_topology\",\n  clear_existing: false,\n  schema: {\n    nodes: [\"Device\", \"Network\", \"Application\"],\n    relationships: [\"CONNECTS_TO\", \"HOSTS\", \"DEPENDS_ON\"]\n  }\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#12-kg_cypher_query","title":"12. kg_cypher_query","text":"<p>Executes Cypher queries on the knowledge graph.</p> <pre><code>// Tool Definition\n{\n  name: \"kg_cypher_query\",\n  description: \"Execute Cypher queries on knowledge graph\",\n  parameters: {\n    query: string,\n    params?: object,\n    explain?: boolean\n  }\n}\n\n// Example Usage\nconst result = await mcp.callTool(\"kg_cypher_query\", {\n  query: `\n    MATCH (fw:Firewall)-[:PROTECTS]-&gt;(n:Network)\n    WHERE n.zone = $zone\n    RETURN fw.name, fw.rules, n.name\n  `,\n  params: { zone: \"DMZ\" }\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#13-kg_hybrid_search","title":"13. kg_hybrid_search","text":"<p>Performs hybrid search using KG and vector embeddings.</p> <pre><code>// Tool Definition\n{\n  name: \"kg_hybrid_search\",\n  description: \"Hybrid search combining KG and vectors\",\n  parameters: {\n    query: string,\n    strategy: \"adaptive\" | \"vector_first\" | \"graph_first\" | \"parallel\",\n    max_hops?: number,\n    include_embeddings?: boolean\n  }\n}\n\n// Example Usage\nconst results = await mcp.callTool(\"kg_hybrid_search\", {\n  query: \"Find all paths from DMZ to internal network\",\n  strategy: \"adaptive\",\n  max_hops: 3,\n  include_embeddings: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#14-kg_find_paths","title":"14. kg_find_paths","text":"<p>Finds paths between entities in the knowledge graph.</p> <pre><code>// Tool Definition\n{\n  name: \"kg_find_paths\",\n  description: \"Find paths between entities\",\n  parameters: {\n    start_entity: string,\n    end_entity: string,\n    max_length?: number,\n    path_type?: \"shortest\" | \"all\" | \"no_loops\",\n    relationship_types?: string[]\n  }\n}\n\n// Example Usage\nconst paths = await mcp.callTool(\"kg_find_paths\", {\n  start_entity: \"web_server\",\n  end_entity: \"database\",\n  max_length: 5,\n  path_type: \"shortest\",\n  relationship_types: [\"CONNECTS_TO\", \"ROUTES_THROUGH\"]\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#15-kg_rag_query","title":"15. kg_rag_query","text":"<p>Performs RAG-powered queries using knowledge graph context.</p> <pre><code>// Tool Definition\n{\n  name: \"kg_rag_query\",\n  description: \"RAG-powered query using KG context\",\n  parameters: {\n    question: string,\n    mode: \"kg_only\" | \"vector_only\" | \"hybrid\",\n    context_size?: number,\n    include_reasoning?: boolean\n  }\n}\n\n// Example Usage\nconst answer = await mcp.callTool(\"kg_rag_query\", {\n  question: \"What are the security vulnerabilities in our DMZ architecture?\",\n  mode: \"hybrid\",\n  context_size: 5000,\n  include_reasoning: true\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#mcp-resources","title":"MCP Resources","text":"<p>NetIntel-OCR provides 6 interactive resources for exploration and visualization.</p>"},{"location":"mcp-integration-v0.1.18/#1-documentexploreid","title":"1. document://explore/{id}","text":"<p>Interactive document exploration interface.</p> <pre><code>// Resource Definition\n{\n  uri: \"document://explore/{document_id}\",\n  name: \"Document Explorer\",\n  description: \"Interactive document exploration with search and navigation\",\n  mimeType: \"text/html\"\n}\n\n// Example Usage\nconst explorer = await mcp.readResource(\"document://explore/doc_123\");\n\n// Returns interactive HTML interface with:\n// - Document content viewer\n// - Search within document\n// - Entity highlighting\n// - Navigation sidebar\n// - Export options\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-topologyvisualizeid","title":"2. topology://visualize/{id}","text":"<p>Network topology visualization.</p> <pre><code>// Resource Definition\n{\n  uri: \"topology://visualize/{topology_id}\",\n  name: \"Topology Visualizer\",\n  description: \"Interactive network topology visualization\",\n  mimeType: \"text/html\"\n}\n\n// Example Usage\nconst visualizer = await mcp.readResource(\"topology://visualize/network_001\");\n\n// Returns interactive visualization with:\n// - Zoomable network diagram\n// - Node details on click\n// - Path highlighting\n// - Traffic flow animation\n// - Export to various formats\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-kgexploreid","title":"3. kg://explore/{id}","text":"<p>Knowledge graph exploration interface.</p> <pre><code>// Resource Definition\n{\n  uri: \"kg://explore/{graph_id}\",\n  name: \"KG Explorer\",\n  description: \"Interactive knowledge graph exploration\",\n  mimeType: \"text/html\"\n}\n\n// Example Usage\nconst kgExplorer = await mcp.readResource(\"kg://explore/main_graph\");\n\n// Returns interactive KG interface with:\n// - Graph visualization\n// - Query builder\n// - Node/edge filtering\n// - Pattern matching\n// - Export capabilities\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#4-milvuscollectionname","title":"4. milvus://collection/{name}","text":"<p>Milvus collection exploration.</p> <pre><code>// Resource Definition\n{\n  uri: \"milvus://collection/{collection_name}\",\n  name: \"Collection Explorer\",\n  description: \"Explore Milvus collection data and schema\",\n  mimeType: \"application/json\"\n}\n\n// Example Usage\nconst collection = await mcp.readResource(\"milvus://collection/documents\");\n\n// Returns collection details:\n{\n  \"name\": \"documents\",\n  \"schema\": { /* field definitions */ },\n  \"statistics\": {\n    \"row_count\": 10000,\n    \"index_info\": { /* index details */ }\n  },\n  \"sample_data\": [ /* sample vectors */ ]\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#5-milvussearchname","title":"5. milvus://search/{name}","text":"<p>Milvus search interface.</p> <pre><code>// Resource Definition\n{\n  uri: \"milvus://search/{collection_name}\",\n  name: \"Search Interface\",\n  description: \"Interactive search interface for Milvus collection\",\n  mimeType: \"text/html\"\n}\n\n// Example Usage\nconst searchUI = await mcp.readResource(\"milvus://search/documents\");\n\n// Returns search interface with:\n// - Query input\n// - Filter builder\n// - Result visualization\n// - Export options\n// - Search history\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#6-configsystem","title":"6. config://system","text":"<p>System configuration viewer.</p> <pre><code>// Resource Definition\n{\n  uri: \"config://system\",\n  name: \"System Configuration\",\n  description: \"View and validate system configuration\",\n  mimeType: \"application/json\"\n}\n\n// Example Usage\nconst config = await mcp.readResource(\"config://system\");\n\n// Returns system configuration:\n{\n  \"version\": \"0.1.18.0\",\n  \"modules\": {\n    \"kg\": { \"enabled\": true, \"version\": \"1.0.0\" },\n    \"vector\": { \"enabled\": true, \"backend\": \"milvus\" },\n    \"api\": { \"enabled\": true, \"port\": 8000 }\n  },\n  \"services\": {\n    \"milvus\": { \"status\": \"connected\", \"collections\": 5 },\n    \"falkordb\": { \"status\": \"connected\", \"graphs\": 2 },\n    \"ollama\": { \"status\": \"connected\", \"models\": 3 }\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#mcp-prompts","title":"MCP Prompts","text":"<p>NetIntel-OCR provides 5 specialized prompts for contextual operations.</p>"},{"location":"mcp-integration-v0.1.18/#1-contextual_analysis","title":"1. contextual_analysis","text":"<p>Performs contextual analysis with memory of previous interactions.</p> <pre><code>// Prompt Definition\n{\n  name: \"contextual_analysis\",\n  description: \"Analyze with context from previous interactions\",\n  arguments: [\n    { name: \"query\", type: \"string\", required: true },\n    { name: \"context_window\", type: \"number\", default: 5 },\n    { name: \"include_history\", type: \"boolean\", default: true }\n  ]\n}\n\n// Example Usage\nconst analysis = await mcp.callPrompt(\"contextual_analysis\", {\n  query: \"How has our network security posture changed?\",\n  context_window: 10,\n  include_history: true\n});\n\n// Returns contextual analysis considering:\n// - Previous queries and results\n// - Document history\n// - Temporal patterns\n// - Trend analysis\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-synthesize_documents","title":"2. synthesize_documents","text":"<p>Synthesizes information from multiple documents.</p> <pre><code>// Prompt Definition\n{\n  name: \"synthesize_documents\",\n  description: \"Synthesize insights from multiple documents\",\n  arguments: [\n    { name: \"document_ids\", type: \"array\", required: true },\n    { name: \"synthesis_type\", type: \"string\", default: \"comprehensive\" },\n    { name: \"focus_areas\", type: \"array\", optional: true }\n  ]\n}\n\n// Example Usage\nconst synthesis = await mcp.callPrompt(\"synthesize_documents\", {\n  document_ids: [\"doc_123\", \"doc_456\", \"doc_789\"],\n  synthesis_type: \"security_focused\",\n  focus_areas: [\"vulnerabilities\", \"recommendations\"]\n});\n\n// Returns synthesized report with:\n// - Key findings across documents\n// - Common patterns\n// - Contradictions or gaps\n// - Unified recommendations\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-troubleshooting_guide","title":"3. troubleshooting_guide","text":"<p>Generates troubleshooting guides based on issues.</p> <pre><code>// Prompt Definition\n{\n  name: \"troubleshooting_guide\",\n  description: \"Generate troubleshooting guide for issues\",\n  arguments: [\n    { name: \"issue_description\", type: \"string\", required: true },\n    { name: \"system_context\", type: \"object\", optional: true },\n    { name: \"detail_level\", type: \"string\", default: \"standard\" }\n  ]\n}\n\n// Example Usage\nconst guide = await mcp.callPrompt(\"troubleshooting_guide\", {\n  issue_description: \"Network connectivity issues in DMZ\",\n  system_context: {\n    topology: \"topology_001\",\n    recent_changes: [\"firewall_update\", \"vlan_reconfiguration\"]\n  },\n  detail_level: \"detailed\"\n});\n\n// Returns troubleshooting guide with:\n// - Step-by-step diagnosis procedures\n// - Common causes and solutions\n// - Verification steps\n// - Escalation paths\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#4-security_audit_prompt","title":"4. security_audit_prompt","text":"<p>Performs security audit analysis.</p> <pre><code>// Prompt Definition\n{\n  name: \"security_audit_prompt\",\n  description: \"Perform security audit analysis\",\n  arguments: [\n    { name: \"scope\", type: \"object\", required: true },\n    { name: \"standards\", type: \"array\", default: [\"CIS\", \"NIST\"] },\n    { name: \"risk_assessment\", type: \"boolean\", default: true }\n  ]\n}\n\n// Example Usage\nconst audit = await mcp.callPrompt(\"security_audit_prompt\", {\n  scope: {\n    documents: [\"network_diagram_001\", \"security_policy_002\"],\n    systems: [\"firewall\", \"ids\", \"vpn\"]\n  },\n  standards: [\"CIS\", \"PCI-DSS\", \"ISO27001\"],\n  risk_assessment: true\n});\n\n// Returns audit report with:\n// - Compliance status per standard\n// - Identified vulnerabilities\n// - Risk scores and rankings\n// - Remediation recommendations\n// - Priority action items\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#5-network_design_review","title":"5. network_design_review","text":"<p>Reviews network design for best practices.</p> <pre><code>// Prompt Definition\n{\n  name: \"network_design_review\",\n  description: \"Review network design against best practices\",\n  arguments: [\n    { name: \"design_document\", type: \"string\", required: true },\n    { name: \"review_aspects\", type: \"array\", optional: true },\n    { name: \"include_alternatives\", type: \"boolean\", default: false }\n  ]\n}\n\n// Example Usage\nconst review = await mcp.callPrompt(\"network_design_review\", {\n  design_document: \"doc_network_arch_v2\",\n  review_aspects: [\"scalability\", \"security\", \"redundancy\", \"performance\"],\n  include_alternatives: true\n});\n\n// Returns design review with:\n// - Strengths and weaknesses\n// - Best practice violations\n// - Scalability analysis\n// - Security assessment\n// - Alternative design suggestions\n// - Implementation roadmap\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#integration-examples","title":"Integration Examples","text":""},{"location":"mcp-integration-v0.1.18/#example-1-complete-document-analysis-pipeline","title":"Example 1: Complete Document Analysis Pipeline","text":"<pre><code>// Complete document analysis using MCP tools\nasync function analyzeDocument(documentPath) {\n  // 1. Upload and process document\n  const doc = await uploadDocument(documentPath);\n\n  // 2. Extract entities\n  const entities = await mcp.callTool(\"extract_entities\", {\n    document_id: doc.id,\n    entity_types: [\"NETWORK_DEVICE\", \"IP_ADDRESS\", \"PROTOCOL\"],\n    include_relationships: true\n  });\n\n  // 3. Initialize knowledge graph\n  await mcp.callTool(\"kg_initialize\", {\n    graph_name: `doc_${doc.id}_graph`\n  });\n\n  // 4. Build knowledge graph from entities\n  for (const entity of entities.entities) {\n    await mcp.callTool(\"kg_cypher_query\", {\n      query: `\n        MERGE (e:Entity {name: $name, type: $type})\n        SET e.properties = $properties\n      `,\n      params: {\n        name: entity.value,\n        type: entity.type,\n        properties: entity.metadata\n      }\n    });\n  }\n\n  // 5. Create relationships\n  for (const rel of entities.relationships) {\n    await mcp.callTool(\"kg_cypher_query\", {\n      query: `\n        MATCH (a:Entity {name: $from})\n        MATCH (b:Entity {name: $to})\n        MERGE (a)-[r:${rel.type}]-&gt;(b)\n        SET r.properties = $properties\n      `,\n      params: {\n        from: rel.from,\n        to: rel.to,\n        properties: rel.metadata\n      }\n    });\n  }\n\n  // 6. Perform security audit\n  const audit = await mcp.callPrompt(\"security_audit_prompt\", {\n    scope: { documents: [doc.id] },\n    standards: [\"CIS\", \"NIST\"],\n    risk_assessment: true\n  });\n\n  // 7. Generate vector embeddings\n  await mcp.callTool(\"create_milvus_collection\", {\n    collection_name: `doc_${doc.id}_vectors`,\n    dimension: 768\n  });\n\n  // 8. Index document chunks\n  for (const chunk of doc.chunks) {\n    await mcp.callTool(\"milvus_vector_search\", {\n      collection_name: `doc_${doc.id}_vectors`,\n      query_vector: chunk.embedding,\n      top_k: 1\n    });\n  }\n\n  return {\n    document: doc,\n    entities: entities,\n    audit: audit,\n    graph: `kg://explore/doc_${doc.id}_graph`,\n    search: `milvus://search/doc_${doc.id}_vectors`\n  };\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#example-2-network-topology-analysis","title":"Example 2: Network Topology Analysis","text":"<pre><code>// Analyze network topology using MCP\nasync function analyzeNetworkTopology(topologyId) {\n  // 1. Load topology\n  const topology = await mcp.readResource(`topology://visualize/${topologyId}`);\n\n  // 2. Find critical paths\n  const criticalPaths = await mcp.callTool(\"analyze_network_path\", {\n    start_point: \"internet\",\n    end_point: \"database_tier\",\n    path_type: \"all\",\n    include_metrics: true\n  });\n\n  // 3. Identify single points of failure\n  const spof = await mcp.callTool(\"kg_cypher_query\", {\n    query: `\n      MATCH (n:NetworkDevice)\n      WHERE NOT EXISTS((n)-[:HAS_BACKUP]-&gt;())\n      AND size((n)&lt;-[:DEPENDS_ON]-()) &gt; 3\n      RETURN n.name as device,\n             size((n)&lt;-[:DEPENDS_ON]-()) as dependencies\n      ORDER BY dependencies DESC\n    `\n  });\n\n  // 4. Check compliance\n  const compliance = await mcp.callTool(\"check_compliance\", {\n    document_id: topologyId,\n    standards: [\"PCI-DSS\", \"HIPAA\"],\n    detailed_report: true\n  });\n\n  // 5. Generate design review\n  const review = await mcp.callPrompt(\"network_design_review\", {\n    design_document: topologyId,\n    review_aspects: [\"security\", \"redundancy\", \"scalability\"],\n    include_alternatives: true\n  });\n\n  return {\n    topology: topology,\n    critical_paths: criticalPaths,\n    single_points_of_failure: spof,\n    compliance: compliance,\n    review: review\n  };\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#example-3-intelligent-search-with-context","title":"Example 3: Intelligent Search with Context","text":"<pre><code>// Perform intelligent contextual search\nasync function intelligentSearch(query, context = {}) {\n  // 1. Classify query intent\n  const classification = await mcp.callTool(\"intelligent_query\", {\n    query: query,\n    mode: \"auto\"\n  });\n\n  // 2. Perform appropriate search based on classification\n  let results;\n\n  switch (classification.suggested_mode) {\n    case \"kg\":\n      // Knowledge graph search\n      results = await mcp.callTool(\"kg_hybrid_search\", {\n        query: query,\n        strategy: \"graph_first\",\n        max_hops: 3\n      });\n      break;\n\n    case \"vector\":\n      // Vector similarity search\n      results = await mcp.callTool(\"milvus_vector_search\", {\n        collection_name: \"documents\",\n        query_vector: query,\n        top_k: 10\n      });\n      break;\n\n    case \"hybrid\":\n      // Hybrid search\n      results = await mcp.callTool(\"milvus_hybrid_search\", {\n        collection_name: \"documents\",\n        vector_query: query,\n        scalar_filters: context.filters || {},\n        alpha: 0.7\n      });\n      break;\n\n    default:\n      // RAG-based search\n      results = await mcp.callTool(\"kg_rag_query\", {\n        question: query,\n        mode: \"hybrid\",\n        context_size: 5000\n      });\n  }\n\n  // 3. Apply contextual analysis\n  const contextualResults = await mcp.callPrompt(\"contextual_analysis\", {\n    query: query,\n    context_window: 5,\n    include_history: true\n  });\n\n  // 4. Synthesize final results\n  const synthesis = await mcp.callPrompt(\"synthesize_documents\", {\n    document_ids: results.documents.map(d =&gt; d.id),\n    synthesis_type: \"query_focused\",\n    focus_areas: [query]\n  });\n\n  return {\n    mode: classification.suggested_mode,\n    results: results,\n    context: contextualResults,\n    synthesis: synthesis\n  };\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#best-practices","title":"Best Practices","text":""},{"location":"mcp-integration-v0.1.18/#1-tool-selection","title":"1. Tool Selection","text":"<p>Choose the right tool for your use case:</p> <pre><code>// Decision tree for tool selection\nfunction selectTool(intent) {\n  const toolMap = {\n    // Document operations\n    \"compare\": \"compare_documents\",\n    \"extract\": \"extract_entities\",\n    \"compliance\": \"check_compliance\",\n\n    // Search operations\n    \"semantic_search\": \"milvus_vector_search\",\n    \"filtered_search\": \"milvus_hybrid_search\",\n    \"relationship_search\": \"kg_cypher_query\",\n\n    // Analysis operations\n    \"network_analysis\": \"analyze_network_path\",\n    \"path_finding\": \"kg_find_paths\",\n    \"question_answering\": \"kg_rag_query\"\n  };\n\n  return toolMap[intent] || \"intelligent_query\";\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-error-handling","title":"2. Error Handling","text":"<p>Implement robust error handling:</p> <pre><code>async function safeMCPCall(tool, params, retries = 3) {\n  for (let i = 0; i &lt; retries; i++) {\n    try {\n      const result = await mcp.callTool(tool, params);\n\n      // Check for partial failures\n      if (result.warnings) {\n        console.warn(`Tool ${tool} completed with warnings:`, result.warnings);\n      }\n\n      return result;\n    } catch (error) {\n      console.error(`Attempt ${i + 1} failed for ${tool}:`, error);\n\n      if (i === retries - 1) {\n        // Final attempt failed\n        throw new Error(`Tool ${tool} failed after ${retries} attempts: ${error.message}`);\n      }\n\n      // Exponential backoff\n      await new Promise(resolve =&gt; setTimeout(resolve, Math.pow(2, i) * 1000));\n    }\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-resource-caching","title":"3. Resource Caching","text":"<p>Cache resource responses for better performance:</p> <pre><code>class MCPResourceCache {\n  constructor(ttl = 3600000) { // 1 hour default\n    this.cache = new Map();\n    this.ttl = ttl;\n  }\n\n  async getResource(uri) {\n    const cached = this.cache.get(uri);\n\n    if (cached &amp;&amp; Date.now() - cached.timestamp &lt; this.ttl) {\n      return cached.data;\n    }\n\n    const data = await mcp.readResource(uri);\n    this.cache.set(uri, {\n      data: data,\n      timestamp: Date.now()\n    });\n\n    return data;\n  }\n\n  invalidate(uri) {\n    this.cache.delete(uri);\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#4-batch-operations","title":"4. Batch Operations","text":"<p>Batch operations for efficiency:</p> <pre><code>async function batchMCPOperations(operations) {\n  // Group operations by type\n  const grouped = operations.reduce((acc, op) =&gt; {\n    if (!acc[op.tool]) acc[op.tool] = [];\n    acc[op.tool].push(op.params);\n    return acc;\n  }, {});\n\n  // Execute batches in parallel\n  const results = await Promise.all(\n    Object.entries(grouped).map(async ([tool, paramsList]) =&gt; {\n      // Some tools support batch operations directly\n      if (tool === \"milvus_vector_search\") {\n        return await mcp.callTool(tool, {\n          batch: paramsList\n        });\n      }\n\n      // Others need parallel execution\n      return await Promise.all(\n        paramsList.map(params =&gt; mcp.callTool(tool, params))\n      );\n    })\n  );\n\n  return results.flat();\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#5-context-management","title":"5. Context Management","text":"<p>Manage context effectively for prompts:</p> <pre><code>class ContextManager {\n  constructor(maxSize = 100000) {\n    this.context = [];\n    this.maxSize = maxSize;\n  }\n\n  addContext(item) {\n    this.context.push({\n      ...item,\n      timestamp: Date.now()\n    });\n\n    // Trim if exceeds max size\n    this.trimContext();\n  }\n\n  trimContext() {\n    let totalSize = JSON.stringify(this.context).length;\n\n    while (totalSize &gt; this.maxSize &amp;&amp; this.context.length &gt; 0) {\n      this.context.shift(); // Remove oldest\n      totalSize = JSON.stringify(this.context).length;\n    }\n  }\n\n  getRelevantContext(query, limit = 5) {\n    // Sort by relevance and recency\n    return this.context\n      .sort((a, b) =&gt; {\n        const relevanceA = this.calculateRelevance(query, a);\n        const relevanceB = this.calculateRelevance(query, b);\n        return (relevanceB + b.timestamp) - (relevanceA + a.timestamp);\n      })\n      .slice(0, limit);\n  }\n\n  calculateRelevance(query, item) {\n    // Simple keyword matching (can be enhanced)\n    const keywords = query.toLowerCase().split(' ');\n    const itemText = JSON.stringify(item).toLowerCase();\n    return keywords.filter(k =&gt; itemText.includes(k)).length;\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mcp-integration-v0.1.18/#common-issues","title":"Common Issues","text":""},{"location":"mcp-integration-v0.1.18/#1-mcp-server-connection-failed","title":"1. MCP Server Connection Failed","text":"<pre><code># Check if MCP server is running\ncurl http://localhost:3000/health\n\n# Check logs\ntail -f ~/.netintel-ocr/logs/mcp-server.log\n\n# Restart with debug mode\nnetintel-ocr server mcp --debug --port 3000\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-tool-timeout","title":"2. Tool Timeout","text":"<pre><code>// Increase timeout for long-running operations\nconst result = await mcp.callTool(\"kg_cypher_query\", {\n  query: \"MATCH (n) RETURN n\",  // Large query\n  timeout: 60000  // 60 seconds\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-resource-not-found","title":"3. Resource Not Found","text":"<pre><code>// Check resource availability before access\nconst resources = await mcp.listResources();\nif (resources.includes(\"kg://explore/main\")) {\n  const kg = await mcp.readResource(\"kg://explore/main\");\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#performance-optimization","title":"Performance Optimization","text":""},{"location":"mcp-integration-v0.1.18/#1-connection-pooling","title":"1. Connection Pooling","text":"<pre><code>// Configure connection pool\nconst mcpConfig = {\n  connection: {\n    pool: {\n      min: 2,\n      max: 10,\n      idle: 30000\n    }\n  }\n};\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-parallel-tool-execution","title":"2. Parallel Tool Execution","text":"<pre><code>// Execute tools in parallel when possible\nconst [entities, paths, stats] = await Promise.all([\n  mcp.callTool(\"extract_entities\", { document_id: \"doc_123\" }),\n  mcp.callTool(\"kg_find_paths\", { start: \"A\", end: \"B\" }),\n  mcp.callTool(\"get_collection_stats\", { collection_name: \"docs\" })\n]);\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-streaming-results","title":"3. Streaming Results","text":"<pre><code>// Stream large results\nconst stream = await mcp.streamTool(\"milvus_vector_search\", {\n  collection_name: \"large_collection\",\n  query_vector: vector,\n  top_k: 1000,\n  stream: true\n});\n\nfor await (const chunk of stream) {\n  processChunk(chunk);\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#security-considerations","title":"Security Considerations","text":""},{"location":"mcp-integration-v0.1.18/#1-authentication","title":"1. Authentication","text":"<pre><code>// Configure MCP with authentication\nconst mcp = new MCPClient({\n  url: \"http://localhost:3000\",\n  auth: {\n    type: \"api_key\",\n    key: process.env.MCP_API_KEY\n  }\n});\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#2-input-validation","title":"2. Input Validation","text":"<pre><code>// Validate inputs before MCP calls\nfunction validateMCPInput(tool, params) {\n  const schema = getToolSchema(tool);\n\n  for (const [key, value] of Object.entries(params)) {\n    if (!schema[key]) {\n      throw new Error(`Unknown parameter: ${key}`);\n    }\n\n    if (!validateType(value, schema[key].type)) {\n      throw new Error(`Invalid type for ${key}: expected ${schema[key].type}`);\n    }\n\n    if (schema[key].pattern &amp;&amp; !new RegExp(schema[key].pattern).test(value)) {\n      throw new Error(`Invalid format for ${key}`);\n    }\n  }\n\n  return true;\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#3-rate-limiting","title":"3. Rate Limiting","text":"<pre><code>// Implement client-side rate limiting\nclass RateLimiter {\n  constructor(maxRequests = 100, windowMs = 60000) {\n    this.maxRequests = maxRequests;\n    this.windowMs = windowMs;\n    this.requests = [];\n  }\n\n  async checkLimit() {\n    const now = Date.now();\n    this.requests = this.requests.filter(t =&gt; now - t &lt; this.windowMs);\n\n    if (this.requests.length &gt;= this.maxRequests) {\n      const oldestRequest = this.requests[0];\n      const waitTime = this.windowMs - (now - oldestRequest);\n      await new Promise(resolve =&gt; setTimeout(resolve, waitTime));\n    }\n\n    this.requests.push(now);\n  }\n}\n</code></pre>"},{"location":"mcp-integration-v0.1.18/#next-steps","title":"Next Steps","text":"<ol> <li>Explore API v2: See the API v2 Guide</li> <li>Learn Milvus: Read the Milvus Vector Database Guide</li> <li>Deploy to Production: Follow the Production Deployment Guide</li> </ol>"},{"location":"mcp/","title":"MCP Server Guide","text":""},{"location":"mcp/#model-context-protocol-integration","title":"Model Context Protocol Integration","text":"<p>NetIntel-OCR supports the Model Context Protocol (MCP) for seamless integration with AI assistants and LLM applications.</p>"},{"location":"mcp/#starting-mcp-server","title":"Starting MCP Server","text":""},{"location":"mcp/#basic-setup","title":"Basic Setup","text":"<pre><code># Start MCP server\nnetintel-ocr server mcp\n\n# With custom configuration\nnetintel-ocr server mcp --mcp-port 3000\n</code></pre>"},{"location":"mcp/#configuration-file","title":"Configuration File","text":"<pre><code>{\n  \"mcp\": {\n    \"enabled\": true,\n    \"port\": 3000,\n    \"tools\": [\n      \"process_document\",\n      \"search_diagrams\",\n      \"extract_components\"\n    ],\n    \"auth\": {\n      \"type\": \"bearer\",\n      \"token\": \"mcp-secret-token\"\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#available-tools","title":"Available Tools","text":""},{"location":"mcp/#process_document","title":"process_document","text":"<p>Process PDF documents and extract network/flow diagrams.</p> <pre><code>{\n  \"tool\": \"process_document\",\n  \"parameters\": {\n    \"file_path\": \"/path/to/document.pdf\",\n    \"start_page\": 1,\n    \"end_page\": 10,\n    \"model\": \"qwen2.5vl:7b\"\n  }\n}\n</code></pre>"},{"location":"mcp/#search_diagrams","title":"search_diagrams","text":"<p>Search for specific network components or patterns.</p> <pre><code>{\n  \"tool\": \"search_diagrams\", \n  \"parameters\": {\n    \"query\": \"firewall DMZ configuration\",\n    \"limit\": 5,\n    \"filters\": {\n      \"type\": \"network_diagram\"\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#extract_components","title":"extract_components","text":"<p>Extract specific components from diagrams.</p> <pre><code>{\n  \"tool\": \"extract_components\",\n  \"parameters\": {\n    \"image_path\": \"/path/to/diagram.png\",\n    \"component_types\": [\"firewall\", \"router\", \"switch\"]\n  }\n}\n</code></pre>"},{"location":"mcp/#claude-desktop-integration","title":"Claude Desktop Integration","text":""},{"location":"mcp/#configuration","title":"Configuration","text":"<p>Add to Claude Desktop config (<code>~/.config/claude/config.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"netintel-ocr\": {\n      \"command\": \"netintel-ocr\",\n      \"args\": [\"--mcp\"],\n      \"env\": {\n        \"OLLAMA_HOST\": \"http://localhost:11434\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#usage-in-claude","title":"Usage in Claude","text":"<pre><code>User: Process the network architecture document and find all firewall configurations.\n\nClaude: I'll process the document using NetIntel-OCR to extract network diagrams and identify firewall configurations.\n\n[Uses process_document tool]\n[Uses search_diagrams tool with \"firewall\" query]\n\nI found 3 network diagrams containing firewall configurations:\n1. Page 5: DMZ architecture with dual firewalls\n2. Page 12: Internal segmentation firewall\n3. Page 18: Cloud gateway firewall setup\n</code></pre>"},{"location":"mcp/#vs-code-integration","title":"VS Code Integration","text":""},{"location":"mcp/#extension-setup","title":"Extension Setup","text":"<pre><code>{\n  \"mcp.servers\": [\n    {\n      \"name\": \"netintel-ocr\",\n      \"command\": \"netintel-ocr server mcp\",\n      \"env\": {\n        \"OLLAMA_HOST\": \"http://localhost:11434\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"mcp/#commands","title":"Commands","text":"<ul> <li><code>MCP: Process Current File</code> - Process open PDF</li> <li><code>MCP: Search Diagrams</code> - Search across processed documents</li> <li><code>MCP: Extract Components</code> - Extract from selected image</li> </ul>"},{"location":"mcp/#programmatic-usage","title":"Programmatic Usage","text":""},{"location":"mcp/#python-mcp-client","title":"Python MCP Client","text":"<pre><code>from mcp_client import MCPClient\n\n# Connect to MCP server\nclient = MCPClient(\"localhost:3000\")\n\n# Use tools\nresult = await client.call_tool(\n    \"process_document\",\n    {\n        \"file_path\": \"network.pdf\",\n        \"model\": \"qwen2.5vl:7b\"\n    }\n)\n\n# Get network diagrams\ndiagrams = result['diagrams']\nfor diagram in diagrams:\n    print(f\"Page {diagram['page']}: {diagram['type']}\")\n    print(diagram['mermaid'])\n</code></pre>"},{"location":"mcp/#nodejs-mcp-client","title":"Node.js MCP Client","text":"<pre><code>const { MCPClient } = require('@modelcontextprotocol/client');\n\nconst client = new MCPClient({\n  url: 'http://localhost:3000'\n});\n\n// Process document\nconst result = await client.callTool('process_document', {\n  file_path: 'network.pdf'\n});\n\nconsole.log(`Found ${result.diagrams.length} diagrams`);\n</code></pre>"},{"location":"mcp/#tool-responses","title":"Tool Responses","text":""},{"location":"mcp/#structured-output","title":"Structured Output","text":"<p>All tools return structured JSON responses:</p> <pre><code>{\n  \"success\": true,\n  \"data\": {\n    \"diagrams\": [\n      {\n        \"page\": 5,\n        \"type\": \"network_topology\",\n        \"confidence\": 0.95,\n        \"mermaid\": \"graph TB...\",\n        \"components\": [...],\n        \"context\": {\n          \"summary\": \"DMZ network architecture\",\n          \"security_zones\": [\"DMZ\", \"Internal\", \"External\"]\n        }\n      }\n    ],\n    \"processing_time\": 12.5\n  }\n}\n</code></pre>"},{"location":"mcp/#error-handling","title":"Error Handling","text":"<pre><code>{\n  \"success\": false,\n  \"error\": {\n    \"code\": \"MODEL_NOT_FOUND\",\n    \"message\": \"Model 'unknown' not available\",\n    \"suggestions\": [\"qwen2.5vl:7b\", \"llava:13b\"]\n  }\n}\n</code></pre>"},{"location":"mcp/#advanced-features","title":"Advanced Features","text":""},{"location":"mcp/#streaming-responses","title":"Streaming Responses","text":"<pre><code># Enable streaming for large documents\nasync for chunk in client.stream_tool(\n    \"process_document\",\n    {\"file_path\": \"large.pdf\", \"stream\": True}\n):\n    print(f\"Processing page {chunk['page']}\")\n</code></pre>"},{"location":"mcp/#context-management","title":"Context Management","text":"<pre><code># Maintain context across calls\ncontext = client.create_context()\n\n# First call\nawait context.call_tool(\"process_document\", {...})\n\n# Subsequent call uses previous context\nawait context.call_tool(\"search_diagrams\", {\n    \"query\": \"related to previous document\"\n})\n</code></pre>"},{"location":"mcp/#custom-tools","title":"Custom Tools","text":"<p>Register custom tools for specific workflows:</p> <pre><code>@mcp_server.register_tool\ndef analyze_security(params):\n    \"\"\"Analyze security aspects of network diagrams.\"\"\"\n    return {\n        \"vulnerabilities\": [...],\n        \"recommendations\": [...],\n        \"risk_score\": 7.5\n    }\n</code></pre>"},{"location":"mcp/#all-in-one-mode","title":"All-in-One Mode","text":"<p>Start with all services:</p> <pre><code># MCP + API + Vector Store\nnetintel-ocr server all\n\n# Services available:\n# - MCP Server: port 3000\n# - REST API: port 8000\n# - Milvus: port 19530\n</code></pre>"},{"location":"mcp/#security","title":"Security","text":""},{"location":"mcp/#authentication","title":"Authentication","text":"<pre><code># Token authentication\nnetintel-ocr server mcp --mcp-token YOUR_SECRET_TOKEN\n\n# mTLS authentication\nnetintel-ocr server mcp \\\n  --mcp-cert server.crt \\\n  --mcp-key server.key \\\n  --mcp-ca ca.crt\n</code></pre>"},{"location":"mcp/#access-control","title":"Access Control","text":"<pre><code>{\n  \"mcp\": {\n    \"acl\": {\n      \"process_document\": [\"admin\", \"user\"],\n      \"search_diagrams\": [\"admin\", \"user\", \"readonly\"],\n      \"extract_components\": [\"admin\"]\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/#monitoring","title":"Monitoring","text":""},{"location":"mcp/#metrics","title":"Metrics","text":"<pre><code>GET http://localhost:3000/metrics\n\nmcp_requests_total{tool=\"process_document\"} 156\nmcp_request_duration_seconds{tool=\"process_document\",quantile=\"0.99\"} 12.5\nmcp_active_connections 3\n</code></pre>"},{"location":"mcp/#logging","title":"Logging","text":"<pre><code># Enable debug logging\nnetintel-ocr server mcp --mcp-log-level DEBUG\n\n# Log format\n2024-01-15 10:30:45 [MCP] Tool called: process_document\n2024-01-15 10:30:57 [MCP] Response sent: success=true, time=12.5s\n</code></pre>"},{"location":"mcp/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Model Guide - Optimize model selection</li> <li>API Integration - REST API reference</li> <li>Batch Processing - Process multiple documents</li> </ul>"},{"location":"migration-v01171/","title":"Migration Guide to v0.1.17.1","text":"<p>This guide helps you migrate from NetIntel-OCR v0.1.17 to v0.1.17.1, which introduces modular installation and enhanced version display.</p>"},{"location":"migration-v01171/#whats-new-in-v01171","title":"What's New in v0.1.17.1","text":""},{"location":"migration-v01171/#1-modular-installation","title":"1. Modular Installation","text":"<ul> <li>Reduced base size: From 2.5GB to 500MB</li> <li>Optional features: Install only what you need</li> <li>7 modules available: kg, vector, api, mcp, performance, dev, all</li> </ul>"},{"location":"migration-v01171/#2-enhanced-version-display","title":"2. Enhanced Version Display","text":"<ul> <li>Comprehensive status: Shows all installed and available modules</li> <li>Connection status: Real-time status of services (FalkorDB, Milvus, Ollama)</li> <li>Installation hints: Shows exact commands to add missing features</li> </ul>"},{"location":"migration-v01171/#before-you-upgrade","title":"Before You Upgrade","text":""},{"location":"migration-v01171/#check-your-current-setup","title":"Check Your Current Setup","text":"<p>First, understand what features you're currently using:</p> <pre><code># Check current version\nnetintel-ocr --version\n\n# If on v0.1.17, check what you're using:\n# Check if using Knowledge Graph\nls ~/.netintel-ocr/kg/ 2&gt;/dev/null &amp;&amp; echo \"Using KG\"\n\n# Check if using Milvus\ndocker ps | grep milvus &amp;&amp; echo \"Using Milvus\"\n\n# Check if using API server\nps aux | grep \"netintel-ocr.*--api\" &amp;&amp; echo \"Using API\"\n</code></pre>"},{"location":"migration-v01171/#backup-your-data","title":"Backup Your Data","text":"<pre><code># Backup configuration\ncp -r ~/.netintel-ocr ~/.netintel-ocr.backup\n\n# Backup any custom templates\ncp -r ~/netintel-templates ~/netintel-templates.backup\n\n# If using FalkorDB, backup graph data\ndocker exec falkordb redis-cli --rdb /data/dump.rdb\n</code></pre>"},{"location":"migration-v01171/#migration-paths","title":"Migration Paths","text":""},{"location":"migration-v01171/#path-1-minimal-user-just-ocr","title":"Path 1: Minimal User (Just OCR)","text":"<p>If you only use basic OCR features:</p> <pre><code># Uninstall old version\npip uninstall netintel-ocr\n\n# Install base package only (500MB)\npip install netintel-ocr==0.1.17.1\n\n# Verify\nnetintel-ocr --version\n</code></pre>"},{"location":"migration-v01171/#path-2-knowledge-graph-user","title":"Path 2: Knowledge Graph User","text":"<p>If you use Knowledge Graph features:</p> <pre><code># Uninstall old version\npip uninstall netintel-ocr\n\n# Install with KG support (2GB total)\npip install \"netintel-ocr[kg]==0.1.17.1\"\n\n# Verify KG is available\nnetintel-ocr --version | grep \"Knowledge Graph\"\n</code></pre>"},{"location":"migration-v01171/#path-3-production-user","title":"Path 3: Production User","text":"<p>If you use NetIntel-OCR in production:</p> <pre><code># Uninstall old version\npip uninstall netintel-ocr\n\n# Install production features (KG + Vector + API + Performance)\npip install \"netintel-ocr[production]==0.1.17.1\"\n\n# Verify all features\nnetintel-ocr --version --detailed\n</code></pre>"},{"location":"migration-v01171/#path-4-full-installation-user","title":"Path 4: Full Installation User","text":"<p>If you want everything (equivalent to v0.1.17):</p> <pre><code># Uninstall old version\npip uninstall netintel-ocr\n\n# Install all features (2.5GB)\npip install \"netintel-ocr[all]==0.1.17.1\"\n\n# Verify\nnetintel-ocr --version\n</code></pre>"},{"location":"migration-v01171/#command-changes","title":"Command Changes","text":""},{"location":"migration-v01171/#cli-commands-no-changes","title":"CLI Commands (No Changes)","text":"<p>The hierarchical CLI structure from v0.1.17 remains the same:</p> <pre><code># Old syntax (pre-v0.1.17) - Still deprecated\nnetintel-ocr document.pdf\n\n# Current syntax (v0.1.17+) - Still works\nnetintel-ocr process pdf document.pdf\n</code></pre>"},{"location":"migration-v01171/#new-version-command-features","title":"New Version Command Features","text":"<pre><code># Basic version (shows modules)\nnetintel-ocr --version\n\n# Detailed version info\nnetintel-ocr --version --detailed\n\n# JSON output for scripts\nnetintel-ocr --version --json\n\n# Check for updates\nnetintel-ocr --version --check-updates\n</code></pre>"},{"location":"migration-v01171/#feature-specific-migration","title":"Feature-Specific Migration","text":""},{"location":"migration-v01171/#knowledge-graph-features","title":"Knowledge Graph Features","text":"<p>If KG commands fail after upgrade:</p> <pre><code># Check if KG is installed\nnetintel-ocr --version | grep \"kg\"\n\n# If not installed, add it\npip install \"netintel-ocr[kg]\"\n\n# Verify KG works\nnetintel-ocr kg init\n</code></pre>"},{"location":"migration-v01171/#vector-store-features","title":"Vector Store Features","text":"<p>If Milvus/vector features fail:</p> <pre><code># Check if vector module is installed\nnetintel-ocr --version | grep \"vector\"\n\n# If not installed, add it\npip install \"netintel-ocr[vector]\"\n\n# Test connection\nnetintel-ocr db stats\n</code></pre>"},{"location":"migration-v01171/#api-server","title":"API Server","text":"<p>If API server doesn't start:</p> <pre><code># Check if API module is installed\nnetintel-ocr --version | grep \"api\"\n\n# If not installed, add it\npip install \"netintel-ocr[api]\"\n\n# Start server\nnetintel-ocr server api\n</code></pre>"},{"location":"migration-v01171/#troubleshooting","title":"Troubleshooting","text":""},{"location":"migration-v01171/#module-not-found-errors","title":"Module Not Found Errors","text":"<pre><code># Error: ImportError: No module named 'pykeen'\n# Solution: Install KG module\npip install \"netintel-ocr[kg]\"\n\n# Error: ImportError: No module named 'fastapi'\n# Solution: Install API module\npip install \"netintel-ocr[api]\"\n\n# Error: ImportError: No module named 'pymilvus'\n# Solution: Install vector module\npip install \"netintel-ocr[vector]\"\n</code></pre>"},{"location":"migration-v01171/#check-whats-missing","title":"Check What's Missing","text":"<pre><code># Run version command to see what's missing\nnetintel-ocr --version\n\n# Look for \"Available for Install\" section\n# It shows exact commands to install missing features\n</code></pre>"},{"location":"migration-v01171/#performance-issues","title":"Performance Issues","text":"<p>If processing is slower after upgrade:</p> <pre><code># Install performance optimizations\npip install \"netintel-ocr[performance]\"\n\n# Check C++ core is enabled\nnetintel-ocr --version | grep \"C++ Core\"\n</code></pre>"},{"location":"migration-v01171/#docker-migration","title":"Docker Migration","text":""},{"location":"migration-v01171/#update-docker-image","title":"Update Docker Image","text":"<pre><code># Old Dockerfile (v0.1.17)\nFROM python:3.11-slim\nRUN pip install netintel-ocr==0.1.17\n\n# New Dockerfile (v0.1.17.1) - Choose what you need\nFROM python:3.11-slim\n\n# Option 1: Minimal\nRUN pip install netintel-ocr==0.1.17.1\n\n# Option 2: With KG\nRUN pip install \"netintel-ocr[kg]==0.1.17.1\"\n\n# Option 3: Production\nRUN pip install \"netintel-ocr[production]==0.1.17.1\"\n</code></pre>"},{"location":"migration-v01171/#docker-compose-update","title":"Docker Compose Update","text":"<pre><code># docker-compose.yml\nservices:\n  netintel-ocr:\n    image: netintel/netintel-ocr:0.1.17.1\n    environment:\n      # No changes to environment variables\n      - OLLAMA_HOST=ollama:11434\n      - FALKORDB_HOST=falkordb:6379\n</code></pre>"},{"location":"migration-v01171/#configuration-files","title":"Configuration Files","text":""},{"location":"migration-v01171/#no-changes-required","title":"No Changes Required","text":"<p>Configuration files from v0.1.17 work without changes: - <code>~/.netintel-ocr/config.yml</code> - Template files - Environment variables</p>"},{"location":"migration-v01171/#rollback-plan","title":"Rollback Plan","text":"<p>If you need to rollback to v0.1.17:</p> <pre><code># Uninstall v0.1.17.1\npip uninstall netintel-ocr\n\n# Reinstall v0.1.17\npip install netintel-ocr==0.1.17\n\n# Restore backup if needed\nmv ~/.netintel-ocr.backup ~/.netintel-ocr\n</code></pre>"},{"location":"migration-v01171/#benefits-after-migration","title":"Benefits After Migration","text":""},{"location":"migration-v01171/#storage-savings","title":"Storage Savings","text":"Installation Type v0.1.17 v0.1.17.1 Savings Minimal (OCR only) 2.5GB 500MB 2GB (80%) With KG 2.5GB 2GB 500MB (20%) Production 2.5GB 2.3GB 200MB (8%) Everything 2.5GB 2.5GB 0"},{"location":"migration-v01171/#better-visibility","title":"Better Visibility","text":"<ul> <li>Know exactly what's installed</li> <li>See what features are available</li> <li>Get installation commands instantly</li> <li>Check service connections</li> </ul>"},{"location":"migration-v01171/#faster-installation","title":"Faster Installation","text":"<ul> <li>Base install: 5x faster</li> <li>Incremental upgrades: Add features as needed</li> <li>Reduced dependency conflicts</li> </ul>"},{"location":"migration-v01171/#getting-help","title":"Getting Help","text":""},{"location":"migration-v01171/#check-installation-status","title":"Check Installation Status","text":"<pre><code># See comprehensive status\nnetintel-ocr --version --detailed\n</code></pre>"},{"location":"migration-v01171/#report-issues","title":"Report Issues","text":"<ul> <li>GitHub: https://github.com/VisionMLNet/NetIntelOCR/issues</li> <li>Discord: https://discord.gg/netintel-ocr</li> </ul>"},{"location":"migration-v01171/#documentation","title":"Documentation","text":"<ul> <li>Installation Guide</li> <li>Troubleshooting</li> <li>CLI Reference</li> </ul>"},{"location":"milvus-vector-guide/","title":"Milvus Vector Database Guide v0.1.18.0","text":""},{"location":"milvus-vector-guide/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.18.0 features comprehensive Milvus integration for high-performance vector similarity search, enabling semantic search, document retrieval, and intelligent querying at scale. This guide covers all Milvus operations, optimization strategies, and best practices.</p>"},{"location":"milvus-vector-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Milvus Setup</li> <li>Collection Management</li> <li>Vector Operations</li> <li>Index Management</li> <li>Search Operations</li> <li>Partitions and Segments</li> <li>Performance Optimization</li> <li>Monitoring and Maintenance</li> <li>Troubleshooting</li> </ol>"},{"location":"milvus-vector-guide/#milvus-setup","title":"Milvus Setup","text":""},{"location":"milvus-vector-guide/#docker-deployment","title":"Docker Deployment","text":"<pre><code># Run Milvus Standalone\ndocker-compose -f docker-compose-milvus.yml up -d\n\n# docker-compose-milvus.yml\nversion: '3.5'\n\nservices:\n  etcd:\n    container_name: milvus-etcd\n    image: quay.io/coreos/etcd:v3.5.5\n    environment:\n      - ETCD_AUTO_COMPACTION_MODE=revision\n      - ETCD_AUTO_COMPACTION_RETENTION=1000\n      - ETCD_QUOTA_BACKEND_BYTES=4294967296\n      - ETCD_SNAPSHOT_COUNT=50000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd\n    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379\n\n  minio:\n    container_name: milvus-minio\n    image: minio/minio:RELEASE.2023-03-20T20-16-18Z\n    environment:\n      MINIO_ACCESS_KEY: minioadmin\n      MINIO_SECRET_KEY: minioadmin\n    ports:\n      - \"9001:9001\"\n      - \"9000:9000\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data\n    command: minio server /minio_data --console-address \":9001\"\n\n  milvus:\n    container_name: milvus-standalone\n    image: milvusdb/milvus:v2.3.3\n    command: [\"milvus\", \"run\", \"standalone\"]\n    environment:\n      ETCD_ENDPOINTS: etcd:2379\n      MINIO_ADDRESS: minio:9000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\n    ports:\n      - \"19530:19530\"\n      - \"9091:9091\"\n    depends_on:\n      - etcd\n      - minio\n</code></pre>"},{"location":"milvus-vector-guide/#configuration","title":"Configuration","text":"<pre><code># milvus.yml configuration\nlog:\n  level: info\n  file:\n    rootPath: /var/log/milvus\n    maxSize: 300MB\n    maxAge: 10\n    maxBackups: 20\n\ndataCoord:\n  segment:\n    maxSize: 512MB\n    sealProportion: 0.25\n\nindexCoord:\n  autoIndex:\n    enable: true\n\nqueryCoord:\n  autoHandoff: true\n  autoBalance: true\n  balanceIntervalSeconds: 60\n  memoryUsageMaxDifferencePercentage: 30\n\nqueryNode:\n  cache:\n    enabled: true\n    memoryLimit: 2GB\n\nproxy:\n  port: 19530\n  internalPort: 19529\n</code></pre>"},{"location":"milvus-vector-guide/#connecting-to-milvus","title":"Connecting to Milvus","text":"<pre><code>from pymilvus import connections, Collection, utility\n\n# Connect to Milvus\nconnections.connect(\n    alias=\"default\",\n    host=\"localhost\",\n    port=\"19530\",\n    user=\"username\",  # Optional\n    password=\"password\",  # Optional\n    secure=False  # Set to True for TLS\n)\n\n# Check connection\nprint(f\"Milvus server version: {utility.get_server_version()}\")\nprint(f\"Connected: {connections.has_connection('default')}\")\n</code></pre>"},{"location":"milvus-vector-guide/#collection-management","title":"Collection Management","text":""},{"location":"milvus-vector-guide/#creating-collections","title":"Creating Collections","text":"<pre><code>from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n\n# Define schema\nfields = [\n    FieldSchema(\n        name=\"id\",\n        dtype=DataType.INT64,\n        is_primary=True,\n        auto_id=True,\n        description=\"Primary ID\"\n    ),\n    FieldSchema(\n        name=\"document_id\",\n        dtype=DataType.VARCHAR,\n        max_length=100,\n        description=\"Document identifier\"\n    ),\n    FieldSchema(\n        name=\"content\",\n        dtype=DataType.VARCHAR,\n        max_length=65535,\n        description=\"Text content\"\n    ),\n    FieldSchema(\n        name=\"embedding\",\n        dtype=DataType.FLOAT_VECTOR,\n        dim=768,\n        description=\"Text embedding vector\"\n    ),\n    FieldSchema(\n        name=\"metadata\",\n        dtype=DataType.JSON,\n        description=\"Document metadata\"\n    ),\n    FieldSchema(\n        name=\"timestamp\",\n        dtype=DataType.INT64,\n        description=\"Creation timestamp\"\n    )\n]\n\n# Create schema\nschema = CollectionSchema(\n    fields=fields,\n    description=\"Document embeddings collection\",\n    enable_dynamic_field=True  # Allow additional fields\n)\n\n# Create collection\ncollection = Collection(\n    name=\"documents\",\n    schema=schema,\n    consistency_level=\"Session\",  # Options: Strong, Session, Bounded, Eventually\n    shards_num=2  # Number of shards\n)\n\nprint(f\"Collection created: {collection.name}\")\n</code></pre>"},{"location":"milvus-vector-guide/#collection-with-custom-properties","title":"Collection with Custom Properties","text":"<pre><code># Advanced collection creation with properties\ncollection = Collection(\n    name=\"advanced_documents\",\n    schema=schema,\n    properties={\n        \"collection.ttl.seconds\": 3600,  # TTL for data\n        \"collection.autoID.enable\": True,\n        \"collection.segment.rowLimit\": 1024000\n    }\n)\n\n# Set collection properties after creation\ncollection.set_properties({\n    \"collection.ttl.seconds\": 7200\n})\n</code></pre>"},{"location":"milvus-vector-guide/#managing-collections","title":"Managing Collections","text":"<pre><code>from pymilvus import utility\n\n# List all collections\ncollections = utility.list_collections()\nprint(f\"Collections: {collections}\")\n\n# Check if collection exists\nexists = utility.has_collection(\"documents\")\nprint(f\"Collection exists: {exists}\")\n\n# Get collection info\ncollection = Collection(\"documents\")\nprint(f\"Collection name: {collection.name}\")\nprint(f\"Description: {collection.description}\")\nprint(f\"Schema: {collection.schema}\")\nprint(f\"Number of entities: {collection.num_entities}\")\n\n# Rename collection\nutility.rename_collection(\n    old_collection_name=\"documents\",\n    new_collection_name=\"document_vectors\"\n)\n\n# Drop collection\nutility.drop_collection(\"old_collection\")\n</code></pre>"},{"location":"milvus-vector-guide/#vector-operations","title":"Vector Operations","text":""},{"location":"milvus-vector-guide/#inserting-vectors","title":"Inserting Vectors","text":"<pre><code>import numpy as np\nfrom datetime import datetime\n\n# Prepare data\nnum_entities = 1000\ndim = 768\n\n# Generate sample data\ndocuments = [f\"document_{i}\" for i in range(num_entities)]\ncontents = [f\"This is the content of document {i}\" for i in range(num_entities)]\nembeddings = np.random.random((num_entities, dim)).tolist()\ntimestamps = [int(datetime.now().timestamp()) for _ in range(num_entities)]\nmetadata = [{\"page\": i % 10, \"category\": f\"cat_{i % 5}\"} for i in range(num_entities)]\n\n# Insert data\ndata = [\n    documents,  # document_id\n    contents,   # content\n    embeddings, # embedding\n    metadata,   # metadata\n    timestamps  # timestamp\n]\n\ncollection = Collection(\"documents\")\ninsert_result = collection.insert(data)\n\nprint(f\"Inserted {insert_result.insert_count} entities\")\nprint(f\"Primary keys: {insert_result.primary_keys[:5]}...\")\n\n# Flush to persist data\ncollection.flush()\n</code></pre>"},{"location":"milvus-vector-guide/#batch-insert-with-error-handling","title":"Batch Insert with Error Handling","text":"<pre><code>def batch_insert_with_retry(collection, data, batch_size=1000, max_retries=3):\n    \"\"\"Insert data in batches with retry logic\"\"\"\n\n    total_inserted = 0\n    failed_batches = []\n\n    # Split data into batches\n    num_entities = len(data[0])\n\n    for start_idx in range(0, num_entities, batch_size):\n        end_idx = min(start_idx + batch_size, num_entities)\n        batch_data = [field[start_idx:end_idx] for field in data]\n\n        # Try inserting batch with retries\n        for attempt in range(max_retries):\n            try:\n                result = collection.insert(batch_data)\n                total_inserted += result.insert_count\n                print(f\"Batch {start_idx}-{end_idx} inserted successfully\")\n                break\n            except Exception as e:\n                print(f\"Attempt {attempt + 1} failed for batch {start_idx}-{end_idx}: {e}\")\n                if attempt == max_retries - 1:\n                    failed_batches.append((start_idx, end_idx))\n                else:\n                    time.sleep(2 ** attempt)  # Exponential backoff\n\n    collection.flush()\n\n    return {\n        \"total_inserted\": total_inserted,\n        \"failed_batches\": failed_batches\n    }\n</code></pre>"},{"location":"milvus-vector-guide/#upsert-operations","title":"Upsert Operations","text":"<pre><code># Upsert: Insert or update if exists\nupsert_data = [\n    [\"document_1\", \"document_2\"],  # document_id\n    [\"Updated content 1\", \"Updated content 2\"],  # content\n    [embedding1, embedding2],  # embeddings\n    [{\"updated\": True}, {\"updated\": True}],  # metadata\n    [timestamp1, timestamp2]  # timestamps\n]\n\ncollection.upsert(upsert_data)\ncollection.flush()\n</code></pre>"},{"location":"milvus-vector-guide/#delete-operations","title":"Delete Operations","text":"<pre><code># Delete by primary key\ncollection.delete(expr=\"id in [1, 2, 3, 4, 5]\")\n\n# Delete by expression\ncollection.delete(expr=\"document_id == 'document_123'\")\n\n# Delete with complex expression\ncollection.delete(\n    expr=\"timestamp &lt; 1609459200 and JSON_CONTAINS(metadata, '{\\\"category\\\": \\\"obsolete\\\"}')\"\n)\n\ncollection.flush()\n</code></pre>"},{"location":"milvus-vector-guide/#index-management","title":"Index Management","text":""},{"location":"milvus-vector-guide/#creating-indexes","title":"Creating Indexes","text":"<pre><code># Create IVF_FLAT index (good for accuracy)\nindex_params = {\n    \"metric_type\": \"L2\",  # L2, IP, COSINE\n    \"index_type\": \"IVF_FLAT\",\n    \"params\": {\"nlist\": 1024}\n}\n\ncollection.create_index(\n    field_name=\"embedding\",\n    index_params=index_params,\n    index_name=\"embedding_index\"\n)\n\n# Create IVF_SQ8 index (balanced accuracy/speed/size)\nindex_params_sq8 = {\n    \"metric_type\": \"IP\",  # Inner Product\n    \"index_type\": \"IVF_SQ8\",\n    \"params\": {\"nlist\": 2048}\n}\n\ncollection.create_index(\n    field_name=\"embedding\",\n    index_params=index_params_sq8\n)\n\n# Create HNSW index (good for high recall)\nindex_params_hnsw = {\n    \"metric_type\": \"COSINE\",\n    \"index_type\": \"HNSW\",\n    \"params\": {\n        \"M\": 16,\n        \"efConstruction\": 200\n    }\n}\n\ncollection.create_index(\n    field_name=\"embedding\",\n    index_params=index_params_hnsw\n)\n\n# Create scalar index\ncollection.create_index(\n    field_name=\"timestamp\",\n    index_name=\"timestamp_index\"\n)\n</code></pre>"},{"location":"milvus-vector-guide/#index-types-comparison","title":"Index Types Comparison","text":"Index Type Speed Accuracy Memory Use Case FLAT Slow 100% High Small datasets (&lt;1M) IVF_FLAT Medium High Medium General purpose IVF_SQ8 Fast Good Low Large datasets IVF_PQ Very Fast Moderate Very Low Huge datasets HNSW Fast High High High recall needed ANNOY Fast Good Low Read-heavy workloads DISKANN Fast High Low Disk-based search"},{"location":"milvus-vector-guide/#managing-indexes","title":"Managing Indexes","text":"<pre><code># Check index status\nutility.index_building_progress(\"documents\")\n\n# List indexes\nindexes = collection.indexes\nfor index in indexes:\n    print(f\"Index: {index.field_name} - {index.params}\")\n\n# Drop index\ncollection.drop_index(index_name=\"embedding_index\")\n\n# Rebuild index\ncollection.drop_index()\ncollection.create_index(field_name=\"embedding\", index_params=new_params)\n</code></pre>"},{"location":"milvus-vector-guide/#search-operations","title":"Search Operations","text":""},{"location":"milvus-vector-guide/#basic-vector-search","title":"Basic Vector Search","text":"<pre><code># Load collection into memory\ncollection.load()\n\n# Prepare search vectors\nsearch_vectors = [[random.random() for _ in range(768)] for _ in range(5)]\n\n# Basic search\nsearch_params = {\n    \"metric_type\": \"L2\",\n    \"params\": {\"nprobe\": 16}\n}\n\nresults = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=10,\n    output_fields=[\"document_id\", \"content\", \"metadata\"]\n)\n\n# Process results\nfor i, result in enumerate(results):\n    print(f\"\\nQuery {i} results:\")\n    for j, hit in enumerate(result):\n        print(f\"  {j}. ID: {hit.id}, Score: {hit.distance}\")\n        print(f\"     Document: {hit.entity.get('document_id')}\")\n        print(f\"     Content: {hit.entity.get('content')[:100]}...\")\n</code></pre>"},{"location":"milvus-vector-guide/#filtered-search","title":"Filtered Search","text":"<pre><code># Search with filter expressions\nfilter_expr = \"timestamp &gt; 1609459200 and JSON_CONTAINS(metadata, '{\\\"category\\\": \\\"cat_1\\\"}')\"\n\nresults = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=10,\n    expr=filter_expr,\n    output_fields=[\"document_id\", \"content\", \"metadata\", \"timestamp\"]\n)\n</code></pre>"},{"location":"milvus-vector-guide/#hybrid-search","title":"Hybrid Search","text":"<pre><code>def hybrid_search(collection, text_query, vector_query, alpha=0.7):\n    \"\"\"\n    Perform hybrid search combining vector and keyword search\n\n    Args:\n        collection: Milvus collection\n        text_query: Text for keyword matching\n        vector_query: Vector for similarity search\n        alpha: Weight for vector search (1-alpha for keyword)\n    \"\"\"\n\n    # Vector search\n    vector_results = collection.search(\n        data=[vector_query],\n        anns_field=\"embedding\",\n        param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 32}},\n        limit=50,\n        output_fields=[\"document_id\", \"content\", \"metadata\"]\n    )[0]\n\n    # Keyword search using filter\n    keyword_filter = f\"content like '%{text_query}%'\"\n    keyword_results = collection.query(\n        expr=keyword_filter,\n        output_fields=[\"document_id\", \"content\", \"metadata\"],\n        limit=50\n    )\n\n    # Combine and rerank results\n    combined_scores = {}\n\n    # Add vector search results\n    for i, hit in enumerate(vector_results):\n        doc_id = hit.entity.get('document_id')\n        vector_score = 1.0 / (1.0 + hit.distance)  # Convert distance to score\n        combined_scores[doc_id] = alpha * vector_score\n\n    # Add keyword search results\n    for i, result in enumerate(keyword_results):\n        doc_id = result['document_id']\n        keyword_score = 1.0 - (i / len(keyword_results))  # Rank-based score\n\n        if doc_id in combined_scores:\n            combined_scores[doc_id] += (1 - alpha) * keyword_score\n        else:\n            combined_scores[doc_id] = (1 - alpha) * keyword_score\n\n    # Sort by combined score\n    ranked_results = sorted(\n        combined_scores.items(),\n        key=lambda x: x[1],\n        reverse=True\n    )\n\n    return ranked_results[:10]\n</code></pre>"},{"location":"milvus-vector-guide/#range-search","title":"Range Search","text":"<pre><code># Search within a distance range\nrange_search_params = {\n    \"metric_type\": \"L2\",\n    \"params\": {\n        \"nprobe\": 16,\n        \"radius\": 1.0,  # Maximum distance\n        \"range_filter\": 0.5  # Minimum distance\n    }\n}\n\nresults = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=range_search_params,\n    limit=10\n)\n</code></pre>"},{"location":"milvus-vector-guide/#multi-vector-search","title":"Multi-Vector Search","text":"<pre><code>def multi_vector_search(collection, query_vectors, aggregation=\"mean\"):\n    \"\"\"\n    Search with multiple query vectors\n\n    Args:\n        collection: Milvus collection\n        query_vectors: List of query vectors\n        aggregation: How to combine results (\"mean\", \"max\", \"reciprocal_rank\")\n    \"\"\"\n\n    all_results = []\n\n    # Perform searches for each vector\n    for vector in query_vectors:\n        results = collection.search(\n            data=[vector],\n            anns_field=\"embedding\",\n            param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}},\n            limit=50,\n            output_fields=[\"document_id\", \"content\"]\n        )[0]\n        all_results.append(results)\n\n    # Aggregate results\n    if aggregation == \"mean\":\n        # Average scores across queries\n        score_map = {}\n        count_map = {}\n\n        for results in all_results:\n            for hit in results:\n                doc_id = hit.entity.get('document_id')\n                if doc_id not in score_map:\n                    score_map[doc_id] = 0\n                    count_map[doc_id] = 0\n\n                score_map[doc_id] += hit.distance\n                count_map[doc_id] += 1\n\n        # Calculate mean scores\n        final_scores = {\n            doc_id: score_map[doc_id] / count_map[doc_id]\n            for doc_id in score_map\n        }\n\n    elif aggregation == \"reciprocal_rank\":\n        # Reciprocal Rank Fusion\n        rrf_scores = {}\n        k = 60  # RRF parameter\n\n        for results in all_results:\n            for rank, hit in enumerate(results):\n                doc_id = hit.entity.get('document_id')\n                if doc_id not in rrf_scores:\n                    rrf_scores[doc_id] = 0\n\n                rrf_scores[doc_id] += 1.0 / (k + rank + 1)\n\n        final_scores = rrf_scores\n\n    # Sort and return top results\n    sorted_results = sorted(\n        final_scores.items(),\n        key=lambda x: x[1],\n        reverse=(aggregation == \"reciprocal_rank\")\n    )\n\n    return sorted_results[:10]\n</code></pre>"},{"location":"milvus-vector-guide/#partitions-and-segments","title":"Partitions and Segments","text":""},{"location":"milvus-vector-guide/#creating-and-managing-partitions","title":"Creating and Managing Partitions","text":"<pre><code># Create partitions for data organization\ncollection.create_partition(\"2024_Q1\")\ncollection.create_partition(\"2024_Q2\")\ncollection.create_partition(\"2024_Q3\")\ncollection.create_partition(\"2024_Q4\")\n\n# List partitions\npartitions = collection.partitions\nfor partition in partitions:\n    print(f\"Partition: {partition.name}, Entities: {partition.num_entities}\")\n\n# Insert into specific partition\npartition = collection.partition(\"2024_Q1\")\npartition.insert(data)\n\n# Load specific partitions for search\ncollection.load(partition_names=[\"2024_Q3\", \"2024_Q4\"])\n\n# Search within partitions\nresults = collection.search(\n    data=search_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=10,\n    partition_names=[\"2024_Q3\", \"2024_Q4\"]\n)\n\n# Drop partition\ncollection.drop_partition(\"2024_Q1\")\n</code></pre>"},{"location":"milvus-vector-guide/#segment-management","title":"Segment Management","text":"<pre><code># Get segment information\nfrom pymilvus import utility\n\n# Get query segment info\nsegments = utility.get_query_segment_info(\"documents\")\nfor segment in segments:\n    print(f\"Segment ID: {segment.segmentID}\")\n    print(f\"Collection: {segment.collectionID}\")\n    print(f\"Partition: {segment.partitionID}\")\n    print(f\"Mem size: {segment.mem_size}\")\n    print(f\"Num rows: {segment.num_rows}\")\n    print(f\"Index: {segment.index_name}\")\n\n# Compact segments\ncollection.compact()\n\n# Get compaction state\ncompaction_state = collection.get_compaction_state()\nprint(f\"Compaction state: {compaction_state}\")\n\n# Manual flush\ncollection.flush(_async=False)\n</code></pre>"},{"location":"milvus-vector-guide/#performance-optimization","title":"Performance Optimization","text":""},{"location":"milvus-vector-guide/#1-index-optimization","title":"1. Index Optimization","text":"<pre><code>def optimize_index_for_dataset(collection, num_entities, dim):\n    \"\"\"\n    Choose optimal index based on dataset characteristics\n    \"\"\"\n\n    if num_entities &lt; 10000:\n        # Small dataset: use FLAT for accuracy\n        index_params = {\n            \"metric_type\": \"L2\",\n            \"index_type\": \"FLAT\"\n        }\n    elif num_entities &lt; 100000:\n        # Medium dataset: use IVF_FLAT\n        index_params = {\n            \"metric_type\": \"L2\",\n            \"index_type\": \"IVF_FLAT\",\n            \"params\": {\"nlist\": int(np.sqrt(num_entities))}\n        }\n    elif num_entities &lt; 1000000:\n        # Large dataset: use IVF_SQ8\n        index_params = {\n            \"metric_type\": \"L2\",\n            \"index_type\": \"IVF_SQ8\",\n            \"params\": {\"nlist\": int(4 * np.sqrt(num_entities))}\n        }\n    else:\n        # Very large dataset: use IVF_PQ or HNSW\n        if dim &gt; 128:\n            # High dimension: use PQ for compression\n            index_params = {\n                \"metric_type\": \"L2\",\n                \"index_type\": \"IVF_PQ\",\n                \"params\": {\n                    \"nlist\": 4096,\n                    \"m\": 8,  # PQ subvector count\n                    \"nbits\": 8  # Bits per subvector\n                }\n            }\n        else:\n            # Lower dimension: use HNSW\n            index_params = {\n                \"metric_type\": \"L2\",\n                \"index_type\": \"HNSW\",\n                \"params\": {\n                    \"M\": 16,\n                    \"efConstruction\": 200\n                }\n            }\n\n    collection.create_index(\n        field_name=\"embedding\",\n        index_params=index_params\n    )\n\n    return index_params\n</code></pre>"},{"location":"milvus-vector-guide/#2-search-optimization","title":"2. Search Optimization","text":"<pre><code>def optimize_search_params(index_type, recall_requirement=0.9):\n    \"\"\"\n    Get optimal search parameters based on index type and recall requirement\n    \"\"\"\n\n    search_params = {\"metric_type\": \"L2\"}\n\n    if index_type == \"IVF_FLAT\" or index_type == \"IVF_SQ8\":\n        if recall_requirement &gt;= 0.95:\n            search_params[\"params\"] = {\"nprobe\": 64}\n        elif recall_requirement &gt;= 0.9:\n            search_params[\"params\"] = {\"nprobe\": 32}\n        else:\n            search_params[\"params\"] = {\"nprobe\": 16}\n\n    elif index_type == \"IVF_PQ\":\n        if recall_requirement &gt;= 0.95:\n            search_params[\"params\"] = {\"nprobe\": 128}\n        elif recall_requirement &gt;= 0.9:\n            search_params[\"params\"] = {\"nprobe\": 64}\n        else:\n            search_params[\"params\"] = {\"nprobe\": 32}\n\n    elif index_type == \"HNSW\":\n        if recall_requirement &gt;= 0.95:\n            search_params[\"params\"] = {\"ef\": 128}\n        elif recall_requirement &gt;= 0.9:\n            search_params[\"params\"] = {\"ef\": 64}\n        else:\n            search_params[\"params\"] = {\"ef\": 32}\n\n    return search_params\n</code></pre>"},{"location":"milvus-vector-guide/#3-batch-processing-optimization","title":"3. Batch Processing Optimization","text":"<pre><code>class MilvusBatchProcessor:\n    \"\"\"Optimized batch processing for Milvus operations\"\"\"\n\n    def __init__(self, collection, batch_size=1000):\n        self.collection = collection\n        self.batch_size = batch_size\n        self.buffer = []\n\n    def add_to_buffer(self, data):\n        \"\"\"Add data to buffer and auto-flush when full\"\"\"\n        self.buffer.append(data)\n\n        if len(self.buffer) &gt;= self.batch_size:\n            self.flush()\n\n    def flush(self):\n        \"\"\"Flush buffer to Milvus\"\"\"\n        if not self.buffer:\n            return\n\n        # Reorganize data for batch insert\n        batch_data = [[] for _ in range(len(self.buffer[0]))]\n\n        for item in self.buffer:\n            for i, field_value in enumerate(item):\n                batch_data[i].append(field_value)\n\n        # Insert batch\n        self.collection.insert(batch_data)\n        self.buffer = []\n\n    def search_parallel(self, query_vectors, num_threads=4):\n        \"\"\"Parallel search for multiple queries\"\"\"\n        import concurrent.futures\n\n        def single_search(vector):\n            return self.collection.search(\n                data=[vector],\n                anns_field=\"embedding\",\n                param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}},\n                limit=10\n            )[0]\n\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n            results = list(executor.map(single_search, query_vectors))\n\n        return results\n</code></pre>"},{"location":"milvus-vector-guide/#4-memory-optimization","title":"4. Memory Optimization","text":"<pre><code># Configure memory settings\nfrom pymilvus import utility\n\n# Set memory limit for index\nutility.set_config(\"queryNode.cache.memoryLimit\", \"4GB\")\n\n# Configure segment settings\nutility.set_config(\"dataCoord.segment.maxSize\", \"256MB\")\nutility.set_config(\"dataCoord.segment.sealProportion\", \"0.25\")\n\n# Release collection from memory when not needed\ncollection.release()\n\n# Load only needed partitions\ncollection.load(partition_names=[\"recent_data\"])\n\n# Use resource groups for isolation\nutility.create_resource_group(\n    name=\"high_priority\",\n    config={\n        \"limits\": {\"node_num\": 2},\n        \"requests\": {\"node_num\": 1}\n    }\n)\n\n# Transfer replicas to resource group\nutility.update_resource_groups(\n    source=\"__default__\",\n    target=\"high_priority\",\n    collection_names=[\"documents\"]\n)\n</code></pre>"},{"location":"milvus-vector-guide/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"milvus-vector-guide/#monitoring-metrics","title":"Monitoring Metrics","text":"<pre><code>from pymilvus import utility\nimport json\n\ndef get_milvus_metrics():\n    \"\"\"Get comprehensive Milvus metrics\"\"\"\n\n    metrics = {}\n\n    # System info\n    metrics['server_version'] = utility.get_server_version()\n\n    # Collections info\n    collections = utility.list_collections()\n    metrics['collections'] = {}\n\n    for coll_name in collections:\n        coll = Collection(coll_name)\n        coll.load()\n\n        metrics['collections'][coll_name] = {\n            'num_entities': coll.num_entities,\n            'partitions': len(coll.partitions),\n            'indexes': [idx.field_name for idx in coll.indexes],\n            'loaded': utility.load_state(coll_name)\n        }\n\n        # Get query segment info\n        segments = utility.get_query_segment_info(coll_name)\n        metrics['collections'][coll_name]['segments'] = [\n            {\n                'id': seg.segmentID,\n                'rows': seg.num_rows,\n                'mem_size': seg.mem_size,\n                'index': seg.index_name\n            }\n            for seg in segments\n        ]\n\n    # Resource groups\n    resource_groups = utility.list_resource_groups()\n    metrics['resource_groups'] = resource_groups\n\n    return metrics\n\n# Get and display metrics\nmetrics = get_milvus_metrics()\nprint(json.dumps(metrics, indent=2))\n</code></pre>"},{"location":"milvus-vector-guide/#maintenance-tasks","title":"Maintenance Tasks","text":"<pre><code>def perform_maintenance(collection_name):\n    \"\"\"Perform routine maintenance tasks\"\"\"\n\n    collection = Collection(collection_name)\n\n    # 1. Compact segments\n    print(\"Compacting segments...\")\n    collection.compact()\n\n    # Wait for compaction\n    import time\n    while True:\n        state = collection.get_compaction_state()\n        if state.state != \"Executing\":\n            break\n        time.sleep(5)\n\n    print(f\"Compaction completed: {state}\")\n\n    # 2. Rebuild index if needed\n    segments = utility.get_query_segment_info(collection_name)\n    unindexed_rows = sum(seg.num_rows for seg in segments if not seg.index_name)\n\n    if unindexed_rows &gt; 10000:  # Threshold for rebuilding\n        print(f\"Rebuilding index for {unindexed_rows} unindexed rows...\")\n        collection.drop_index()\n        collection.create_index(\n            field_name=\"embedding\",\n            index_params={\n                \"metric_type\": \"L2\",\n                \"index_type\": \"IVF_SQ8\",\n                \"params\": {\"nlist\": 2048}\n            }\n        )\n\n    # 3. Balance segments across nodes\n    utility.load_balance(\n        collection_name=collection_name,\n        src_node_id=1,\n        dst_node_ids=[2, 3],\n        sealed_segment_ids=None  # Balance all segments\n    )\n\n    # 4. Clean up deleted data\n    collection.flush()\n\n    print(\"Maintenance completed\")\n</code></pre>"},{"location":"milvus-vector-guide/#backup-and-recovery","title":"Backup and Recovery","text":"<pre><code>def backup_collection(collection_name, backup_path):\n    \"\"\"Backup collection data and schema\"\"\"\n\n    import pickle\n    import os\n\n    collection = Collection(collection_name)\n\n    # Get schema\n    schema = collection.schema.to_dict()\n\n    # Query all data\n    all_data = collection.query(\n        expr=\"id &gt; 0\",\n        output_fields=[\"*\"],\n        limit=None\n    )\n\n    # Save backup\n    backup = {\n        \"schema\": schema,\n        \"data\": all_data,\n        \"num_entities\": collection.num_entities,\n        \"timestamp\": datetime.now().isoformat()\n    }\n\n    backup_file = os.path.join(backup_path, f\"{collection_name}_backup.pkl\")\n\n    with open(backup_file, 'wb') as f:\n        pickle.dump(backup, f)\n\n    print(f\"Backup saved to {backup_file}\")\n    return backup_file\n\ndef restore_collection(backup_file, new_collection_name=None):\n    \"\"\"Restore collection from backup\"\"\"\n\n    import pickle\n\n    with open(backup_file, 'rb') as f:\n        backup = pickle.load(f)\n\n    # Create collection from schema\n    schema_dict = backup['schema']\n    fields = []\n\n    for field in schema_dict['fields']:\n        fields.append(FieldSchema(\n            name=field['name'],\n            dtype=DataType[field['type']],\n            **field.get('params', {})\n        ))\n\n    schema = CollectionSchema(\n        fields=fields,\n        description=schema_dict.get('description', '')\n    )\n\n    collection_name = new_collection_name or schema_dict['name']\n    collection = Collection(name=collection_name, schema=schema)\n\n    # Restore data\n    if backup['data']:\n        # Reorganize data for insert\n        field_names = [field['name'] for field in schema_dict['fields'] if not field.get('auto_id')]\n\n        insert_data = []\n        for field_name in field_names:\n            field_data = [item[field_name] for item in backup['data']]\n            insert_data.append(field_data)\n\n        collection.insert(insert_data)\n        collection.flush()\n\n    print(f\"Collection {collection_name} restored with {collection.num_entities} entities\")\n    return collection\n</code></pre>"},{"location":"milvus-vector-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"milvus-vector-guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"milvus-vector-guide/#1-connection-issues","title":"1. Connection Issues","text":"<pre><code>def diagnose_connection():\n    \"\"\"Diagnose Milvus connection issues\"\"\"\n\n    import socket\n\n    host = \"localhost\"\n    port = 19530\n\n    # Check if port is open\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    result = sock.connect_ex((host, port))\n\n    if result == 0:\n        print(f\"\u2713 Port {port} is open\")\n    else:\n        print(f\"\u2717 Port {port} is closed\")\n        return False\n\n    # Try connecting\n    try:\n        connections.connect(alias=\"test\", host=host, port=str(port))\n        print(\"\u2713 Successfully connected to Milvus\")\n\n        # Check server version\n        version = utility.get_server_version()\n        print(f\"\u2713 Server version: {version}\")\n\n        connections.disconnect(\"test\")\n        return True\n\n    except Exception as e:\n        print(f\"\u2717 Connection failed: {e}\")\n        return False\n</code></pre>"},{"location":"milvus-vector-guide/#2-search-performance-issues","title":"2. Search Performance Issues","text":"<pre><code>def diagnose_search_performance(collection_name):\n    \"\"\"Diagnose search performance issues\"\"\"\n\n    collection = Collection(collection_name)\n\n    # Check if collection is loaded\n    load_state = utility.load_state(collection_name)\n    print(f\"Load state: {load_state}\")\n\n    if load_state != \"Loaded\":\n        print(\"\u26a0 Collection not loaded in memory\")\n        collection.load()\n\n    # Check index status\n    indexes = collection.indexes\n    if not indexes:\n        print(\"\u26a0 No index created\")\n    else:\n        for index in indexes:\n            print(f\"Index on {index.field_name}: {index.params}\")\n\n    # Check segment info\n    segments = utility.get_query_segment_info(collection_name)\n    print(f\"Number of segments: {len(segments)}\")\n\n    # Check for too many small segments\n    small_segments = [s for s in segments if s.num_rows &lt; 1024]\n    if len(small_segments) &gt; 10:\n        print(f\"\u26a0 Too many small segments ({len(small_segments)}), consider compaction\")\n\n    # Test search performance\n    import time\n    import numpy as np\n\n    test_vector = np.random.random(768).tolist()\n\n    # Warm up\n    collection.search(\n        data=[test_vector],\n        anns_field=\"embedding\",\n        param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}},\n        limit=10\n    )\n\n    # Measure search time\n    times = []\n    for _ in range(10):\n        start = time.time()\n        collection.search(\n            data=[test_vector],\n            anns_field=\"embedding\",\n            param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 16}},\n            limit=10\n        )\n        times.append(time.time() - start)\n\n    avg_time = sum(times) / len(times)\n    print(f\"Average search time: {avg_time*1000:.2f}ms\")\n\n    if avg_time &gt; 0.1:\n        print(\"\u26a0 Search is slow, consider:\")\n        print(\"  - Reducing nprobe parameter\")\n        print(\"  - Using a faster index type (IVF_SQ8, IVF_PQ)\")\n        print(\"  - Adding more query nodes\")\n</code></pre>"},{"location":"milvus-vector-guide/#3-memory-issues","title":"3. Memory Issues","text":"<pre><code>def diagnose_memory_usage(collection_name):\n    \"\"\"Diagnose memory usage issues\"\"\"\n\n    collection = Collection(collection_name)\n\n    # Get memory usage\n    segments = utility.get_query_segment_info(collection_name)\n    total_memory = sum(seg.mem_size for seg in segments)\n\n    print(f\"Total memory usage: {total_memory / (1024**3):.2f} GB\")\n    print(f\"Number of segments: {len(segments)}\")\n\n    # Memory per segment\n    for seg in segments:\n        print(f\"  Segment {seg.segmentID}: {seg.mem_size / (1024**2):.2f} MB ({seg.num_rows} rows)\")\n\n    # Suggestions\n    if total_memory &gt; 10 * (1024**3):  # &gt; 10GB\n        print(\"\\n\u26a0 High memory usage detected\")\n        print(\"Suggestions:\")\n        print(\"  - Use disk-based index (DiskANN)\")\n        print(\"  - Enable scalar field filtering to reduce loaded data\")\n        print(\"  - Use smaller embedding dimensions\")\n        print(\"  - Partition data and load only needed partitions\")\n        print(\"  - Use quantization (IVF_SQ8, IVF_PQ)\")\n</code></pre>"},{"location":"milvus-vector-guide/#error-recovery","title":"Error Recovery","text":"<pre><code>def recover_from_errors(collection_name):\n    \"\"\"Recover from common error states\"\"\"\n\n    try:\n        collection = Collection(collection_name)\n\n        # Try to release and reload\n        print(\"Attempting to release and reload collection...\")\n        try:\n            collection.release()\n        except:\n            pass\n\n        time.sleep(2)\n\n        # Reload\n        collection.load()\n\n        # Verify\n        state = utility.load_state(collection_name)\n        if state == \"Loaded\":\n            print(\"\u2713 Collection recovered and loaded\")\n        else:\n            print(\"\u2717 Failed to load collection\")\n\n            # Try dropping and recreating index\n            print(\"Attempting to rebuild index...\")\n            collection.drop_index()\n            collection.create_index(\n                field_name=\"embedding\",\n                index_params={\n                    \"metric_type\": \"L2\",\n                    \"index_type\": \"IVF_FLAT\",\n                    \"params\": {\"nlist\": 128}\n                }\n            )\n            collection.load()\n\n    except Exception as e:\n        print(f\"Recovery failed: {e}\")\n        print(\"Manual intervention may be required\")\n</code></pre>"},{"location":"milvus-vector-guide/#best-practices","title":"Best Practices","text":""},{"location":"milvus-vector-guide/#1-schema-design","title":"1. Schema Design","text":"<pre><code># Good schema design practices\ngood_schema = CollectionSchema(\n    fields=[\n        # Use auto_id for primary key\n        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n\n        # Use appropriate max_length for VARCHAR\n        FieldSchema(name=\"doc_id\", dtype=DataType.VARCHAR, max_length=100),\n\n        # Use JSON for flexible metadata\n        FieldSchema(name=\"metadata\", dtype=DataType.JSON),\n\n        # Choose appropriate vector dimension\n        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768)\n    ],\n    # Enable dynamic fields for flexibility\n    enable_dynamic_field=True,\n\n    # Add meaningful description\n    description=\"Document embeddings with metadata\"\n)\n</code></pre>"},{"location":"milvus-vector-guide/#2-insert-best-practices","title":"2. Insert Best Practices","text":"<pre><code># Batch inserts for efficiency\nBATCH_SIZE = 10000\n\n# Use context manager for automatic flush\nwith collection.insert_context():\n    for batch in data_batches:\n        collection.insert(batch)\n# Automatic flush on context exit\n</code></pre>"},{"location":"milvus-vector-guide/#3-search-best-practices","title":"3. Search Best Practices","text":"<pre><code># Pre-filter to reduce search space\nefficient_search = collection.search(\n    data=query_vectors,\n    anns_field=\"embedding\",\n    param=search_params,\n    limit=10,\n    # Filter first, then search\n    expr=\"timestamp &gt; 1609459200 AND category IN ['A', 'B']\",\n    # Only return needed fields\n    output_fields=[\"doc_id\", \"title\"],\n    # Use consistency level based on needs\n    consistency_level=\"Session\"\n)\n</code></pre>"},{"location":"milvus-vector-guide/#4-production-configuration","title":"4. Production Configuration","text":"<pre><code># production-milvus.yml\netcd:\n  endpoints:\n    - etcd-0:2379\n    - etcd-1:2379\n    - etcd-2:2379\n\nminio:\n  address: minio:9000\n  useSSL: true\n  bucketName: milvus-prod\n\nproxy:\n  port: 19530\n  maxImportSize: 17179869184  # 16GB\n\ndataCoord:\n  segment:\n    maxSize: 1024  # MB\n    sealProportion: 0.25\n\nqueryCoord:\n  autoHandoff: true\n  autoBalance: true\n  overloadedMemoryThresholdPercentage: 90\n\nqueryNode:\n  cache:\n    enabled: true\n    memoryLimit: 8192  # MB\n\nlog:\n  level: warn\n  file:\n    maxSize: 1024  # MB\n    maxBackups: 10\n</code></pre>"},{"location":"milvus-vector-guide/#next-steps","title":"Next Steps","text":"<ol> <li>Learn about Enterprise Features: See the Enterprise Features Guide</li> <li>Configure Authentication: Read the Authentication &amp; Security Guide</li> <li>Deploy to Production: Follow the Production Deployment Guide</li> </ol>"},{"location":"minirag/","title":"MiniRAG - Enhanced Retrieval with Knowledge Graphs","text":""},{"location":"minirag/#overview","title":"Overview","text":"<p>MiniRAG is NetIntel-OCR's advanced Retrieval-Augmented Generation system that combines traditional vector search with Knowledge Graph context for more accurate, explainable, and context-aware answers. It leverages both structured graph data and unstructured text to provide comprehensive responses to complex queries.</p> <p>MiniRAG vs Ingestion Models</p> <p>MiniRAG models are used AFTER document ingestion for Q&amp;A and retrieval: - <code>gemma3:4b-it-qat</code> - For generating answers to questions - <code>qwen3-embedding:8b</code> - For semantic search during retrieval</p> <p>Ingestion models are used DURING PDF processing: - <code>qwen2.5vl:7b</code> - For analyzing network diagrams - <code>Nanonets-OCR-s:latest</code> - For OCR text extraction</p> <p>These are completely separate model sets serving different purposes!</p>"},{"location":"minirag/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           User Query                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Query Intent Classifier            \u2502\n\u2502  (Determines optimal retrieval path)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc                 \u25bc          \u25bc          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FalkorDB \u2502    \u2502  PyKEEN  \u2502  \u2502 Milvus  \u2502 \u2502  Ollama  \u2502\n\u2502  Graph   \u2502    \u2502Embeddings\u2502  \u2502 Vectors \u2502 \u2502   LLM    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502                 \u2502          \u2502          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        Result Fusion (RRF)              \u2502\n\u2502   (Combines multiple retrieval paths)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Context-Enhanced Response          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"minirag/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"minirag/#prerequisites","title":"Prerequisites","text":"<pre><code># Ensure NetIntel-OCR v0.1.17+ is installed\npip install netintel-ocr&gt;=0.1.17\n\n# Configure external Ollama server\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\n\n# Verify Ollama has MiniRAG models (NOT ingestion models)\ncurl $OLLAMA_HOST/api/tags | jq '.models[].name'\n\n# MiniRAG MODELS ONLY (for Q&amp;A after ingestion):\n# - qwen3-embedding:8b (for semantic search embeddings)\n# - gemma3:4b-it-qat (for answer generation)\n\n# Pull MiniRAG models if missing\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen3-embedding:8b\"}'\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"gemma3:4b-it-qat\"}'\n\n# Note: Ingestion models (qwen2.5vl:7b, Nanonets-OCR-s) are separate!\n\n# Start required graph/vector services\ndocker-compose up -d falkordb milvus\n\n# Verify MiniRAG components\nnetintel-ocr rag check\n\n# Output:\n# \u2705 FalkorDB: Connected\n# \u2705 Milvus: Connected  \n# \u2705 Ollama: Connected (http://your-ollama-server:11434)\n# \u2705 MiniRAG: Ready\n# \u2705 Available Models: qwen3-embedding:8b, gemma3:4b-it-qat\n</code></pre>"},{"location":"minirag/#initialize-minirag","title":"Initialize MiniRAG","text":"<pre><code># Initialize MiniRAG with Q&amp;A models (NOT ingestion models)\nnetintel-ocr rag init \\\n  --collection network_docs \\\n  --llm-model gemma3:4b-it-qat \\       # MiniRAG answer generation\n  --embedding-model qwen3-embedding:8b  # MiniRAG semantic search\n\n# Advanced initialization with custom settings\nnetintel-ocr rag init \\\n  --collection production_infrastructure \\\n  --llm-model gemma3:4b-it-qat \\        # MiniRAG model (NOT ingestion)\n  --embedding-model qwen3-embedding:8b \\ # MiniRAG model (NOT ingestion)\n  --chunk-size 512 \\\n  --chunk-overlap 50 \\\n  --temperature 0.7 \\\n  --max-tokens 2000 \\\n  --ollama-host $OLLAMA_HOST\n</code></pre>"},{"location":"minirag/#basic-usage","title":"Basic Usage","text":""},{"location":"minirag/#simple-question-answering","title":"Simple Question Answering","text":"<pre><code># Ask a question about your processed telecom infrastructure\nnetintel-ocr rag query \\\n  --question \"What are the main components of our 5G network architecture?\" \\\n  --collection telecom_docs\n\n# Output:\n# Question: What are the main components of our 5G network architecture?\n#\n# Answer: Based on the analyzed documentation, your 5G network architecture consists of:\n#\n# RAN Infrastructure:\n# \u2022 12,000 gNodeBs (5G base stations) across 3 frequency bands\n# \u2022 8,000 Small cells for urban densification\n# \u2022 450 Distributed Units (DUs) for edge processing\n# \u2022 45 Centralized Units (CUs) for baseband processing\n#\n# 5G Core Network:\n# \u2022 AMF (Access and Mobility Management Function) - 4 instances\n# \u2022 SMF (Session Management Function) - 6 instances\n# \u2022 UPF (User Plane Function) - 24 edge instances\n# \u2022 PCF (Policy Control Function) - 2 instances\n# \u2022 UDM (Unified Data Management) - 2 instances\n#\n# Transport Network:\n# \u2022 MPLS backbone with 100G/400G links\n# \u2022 Segment Routing for network slicing\n# \u2022 Edge compute nodes at 150 locations\n#\n# Sources: network-topology.pdf (pages 3-5), infrastructure-design.pdf (pages 12-14)\n# Confidence: 0.94\n</code></pre>"},{"location":"minirag/#query-with-context","title":"Query with Context","text":"<pre><code># Include surrounding context for better answers\nnetintel-ocr rag query \\\n  --question \"How does traffic flow from a UE to the internet in our 5G network?\" \\\n  --include-context \\\n  --context-window 3 \\\n  --collection telecom_docs\n\n# Output includes:\n# - Direct answer with traffic flow path\n# - Network diagram visualization\n# - Security checkpoints along the path\n# - Relevant firewall rules\n# - Performance metrics for each hop\n</code></pre>"},{"location":"minirag/#query-modes","title":"Query Modes","text":""},{"location":"minirag/#1-graph-mode-structured-data-queries","title":"1. Graph Mode - Structured Data Queries","text":"<p>Best for queries about relationships, dependencies, and network topology.</p> <pre><code># Query using only Knowledge Graph\nnetintel-ocr rag query \\\n  --mode graph \\\n  --question \"List all network functions in the 5G Core\" \\\n  --collection telecom_infrastructure\n\n# Output:\n# Network Functions in 5G Core (from Knowledge Graph):\n# \n# Control Plane Functions:\n# \u2022 AMF-01, AMF-02 (Access &amp; Mobility Management)\n# \u2022 SMF-01 to SMF-06 (Session Management)\n# \u2022 PCF-01, PCF-02 (Policy Control)\n# \u2022 UDM-01, UDM-02 (Unified Data Management)\n# \u2022 AUSF-01 (Authentication Server)\n# \u2022 NSSF-01 (Network Slice Selection)\n# \n# User Plane Functions:\n# \u2022 UPF-EDGE-01 to UPF-EDGE-24 (Edge locations)\n# \u2022 UPF-CORE-01 to UPF-CORE-04 (Core locations)\n# \n# Supporting Functions:\n# \u2022 NRF-01, NRF-02 (Network Repository)\n# \u2022 NEF-01 (Network Exposure Function)\n# \n# Total: 8 devices\n# Graph traversal time: 12ms\n</code></pre>"},{"location":"minirag/#2-vector-mode-unstructured-text-queries","title":"2. Vector Mode - Unstructured Text Queries","text":"<p>Best for policy questions, procedures, and descriptive content.</p> <pre><code># Query using only vector search\nnetintel-ocr rag query \\\n  --mode vector \\\n  --question \"What are the password policy requirements?\" \\\n  --collection security_policies\n\n# Output:\n# Password Policy Requirements (from document search):\n# \n# According to the Security Policy document (v2.3):\n# \n# 1. Minimum Length: 12 characters\n# 2. Complexity Requirements:\n#    \u2022 At least one uppercase letter\n#    \u2022 At least one lowercase letter\n#    \u2022 At least one number\n#    \u2022 At least one special character\n# 3. Password History: Cannot reuse last 12 passwords\n# 4. Expiration: 90 days\n# 5. Account Lockout: 5 failed attempts\n# 6. Multi-Factor Authentication: Required for privileged accounts\n# \n# Source: security-policy.pdf (page 23)\n# Relevance Score: 0.96\n</code></pre>"},{"location":"minirag/#3-hybrid-mode-combined-intelligence","title":"3. Hybrid Mode - Combined Intelligence","text":"<p>Best for complex queries requiring both structured and unstructured data.</p> <pre><code># Query using hybrid retrieval (default)\nnetintel-ocr rag query \\\n  --mode hybrid \\\n  --question \"What would be the impact of upgrading the core router firmware?\" \\\n  --collection network_docs\n\n# Output:\n# Impact Analysis for Core Router Firmware Upgrade:\n# \n# From Knowledge Graph Analysis:\n# \u2022 Affected Devices: 47 directly connected systems\n# \u2022 Service Dependencies: 23 critical services rely on core router\n# \u2022 Redundancy: Core-Router-02 can handle traffic during upgrade\n# \u2022 Estimated Affected Users: 2,500\n# \n# From Documentation:\n# \u2022 Upgrade Window: 2-4 hours (per upgrade guide)\n# \u2022 Required Downtime: 15-30 minutes for failover\n# \u2022 Rollback Procedure: Available (documented in section 4.3)\n# \u2022 Known Issues: Memory leak fixed in new version (CVE-2024-1234)\n# \n# Risk Assessment: MEDIUM\n# Recommendation: Schedule during maintenance window with failover testing\n# \n# Sources: \n# - Knowledge Graph: 47 entities, 156 relationships analyzed\n# - Documents: upgrade-guide.pdf (p.12), network-sop.pdf (p.45)\n# Confidence: 0.91\n</code></pre>"},{"location":"minirag/#4-embedding-mode-similarity-queries","title":"4. Embedding Mode - Similarity Queries","text":"<p>Best for finding similar configurations or patterns.</p> <pre><code># Query using KG embeddings\nnetintel-ocr rag query \\\n  --mode embeddings \\\n  --question \"Find all firewalls with similar configurations to FW-PROD-01\" \\\n  --similarity-threshold 0.85 \\\n  --collection network_configs\n\n# Output:\n# Firewalls Similar to FW-PROD-01:\n# \n# 1. FW-PROD-02 (Similarity: 0.98)\n#    \u2022 Location: Data Center 1\n#    \u2022 Config Match: 98% identical rules\n#    \u2022 Differences: NAT pool ranges\n# \n# 2. FW-DR-01 (Similarity: 0.92)\n#    \u2022 Location: DR Site\n#    \u2022 Config Match: 85% identical rules\n#    \u2022 Differences: IP ranges, VLAN assignments\n# \n# 3. FW-PROD-03 (Similarity: 0.87)\n#    \u2022 Location: Data Center 2\n#    \u2022 Config Match: 82% identical rules\n#    \u2022 Differences: Additional DMZ rules\n# \n# Embedding Model: RotatE (200D)\n# Comparison Time: 34ms\n</code></pre>"},{"location":"minirag/#advanced-features","title":"Advanced Features","text":""},{"location":"minirag/#multi-hop-reasoning","title":"Multi-Hop Reasoning","text":"<pre><code># Complex reasoning across multiple relationships\nnetintel-ocr rag query \\\n  --question \"If the primary 5G Core AMF fails, what services are affected and what's the recovery plan?\" \\\n  --reasoning-depth 4 \\\n  --include-alternatives \\\n  --collection telecom_infrastructure\n\n# Output:\n# Multi-Hop Analysis for AMF Failure:\n# \n# Immediate Impact (1 hop):\n# \u2022 UE Registration \u2192 Failed for new devices\n# \u2022 Mobility Management \u2192 Handover failures\n# \u2022 Session Management \u2192 Cannot establish new PDU sessions\n# \n# Cascading Impact (2-3 hops):\n# \u2022 Voice Services (VoNR) \u2192 New calls fail\n# \u2022 Network Slicing \u2192 Slice selection unavailable\n# \u2022 Roaming Services \u2192 Inbound roamers affected\n# \n# Recovery Plan (from runbooks):\n# 1. Automatic failover to DR database (RTO: 5 min)\n# 2. If failover fails:\n#    a. Start manual recovery procedure\n#    b. Restore from backup (RPO: 1 hour)\n#    c. Replay transaction logs\n# 3. Notify stakeholders per escalation matrix\n# \n# Alternative Paths:\n# \u2022 Read-only mode using replica\n# \u2022 Cache-based operations for 2 hours\n# \u2022 Queue writes for later processing\n</code></pre>"},{"location":"minirag/#comparative-analysis","title":"Comparative Analysis","text":"<pre><code># Compare configurations or architectures\nnetintel-ocr rag compare \\\n  --entities \"gNodeB-NYC-001,gNodeB-NYC-002\" \\\n  --aspects \"config,performance,capacity\" \\\n  --collection telecom_configs\n\n# Output:\n# Comparative Analysis: gNodeB-NYC-001 vs gNodeB-NYC-002\n# \n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Aspect          \u2502 gNodeB-NYC-001 \u2502 gNodeB-NYC-002 \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 Frequency Bands \u2502 n77, n41, n5   \u2502 n77, n41      \u2502\n# \u2502 MIMO Config     \u2502 64T64R         \u2502 32T32R        \u2502\n# \u2502 Max UEs         \u2502 4,000          \u2502 2,000         \u2502\n# \u2502 Active UEs      \u2502 3,421          \u2502 1,876         \u2502\n# \u2502 Throughput      \u2502 8.2 Gbps       \u2502 4.7 Gbps      \u2502\n# \u2502 PRB Utilization \u2502 78%            \u2502 82%           \u2502\n# \u2502 Handover Success\u2502 99.2%          \u2502 98.7%         \u2502\n# \u2502 CPU Usage       \u2502 62%            \u2502 71%           \u2502\n# \u2502 Power Output    \u2502 40W            \u2502 20W           \u2502\n# \u2502 Last Config     \u2502 2024-01-10     \u2502 2024-01-09    \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n# \n# Key Differences:\n# \u2022 Production has 45 additional rules for specific services\n# \u2022 DR has simplified NAT configuration\n# \u2022 Configuration sync lag: 2 days\n</code></pre>"},{"location":"minirag/#temporal-queries","title":"Temporal Queries","text":"<pre><code># Query with time context\nnetintel-ocr rag query \\\n  --question \"What changes were made to the network in the last 30 days?\" \\\n  --temporal \\\n  --lookback-days 30 \\\n  --include-changelog \\\n  --collection network_docs\n\n# Output:\n# Network Changes (Last 30 Days):\n# \n# Week 1 (Jan 1-7):\n# \u2022 Added VLAN 245 for new development team\n# \u2022 Updated firewall rules for cloud migration\n# \u2022 Replaced Switch-Access-12 (hardware failure)\n# \n# Week 2 (Jan 8-14):\n# \u2022 Implemented new QoS policies\n# \u2022 Added redundant link between DC1 and DC2\n# \u2022 Updated routing tables for new subnet\n# \n# Week 3 (Jan 15-21):\n# \u2022 Patched 15 devices for CVE-2024-1234\n# \u2022 Migrated 3 services to cloud\n# \u2022 Decommissioned legacy mail server\n# \n# Week 4 (Jan 22-28):\n# \u2022 Upgraded core router firmware\n# \u2022 Added new load balancer for web tier\n# \u2022 Implemented zero-trust policies in DMZ\n# \n# Total Changes: 23\n# Change Frequency: Increasing trend (+35%)\n</code></pre>"},{"location":"minirag/#compliance-and-security-queries","title":"Compliance and Security Queries","text":""},{"location":"minirag/#compliance-checking","title":"Compliance Checking","text":"<pre><code># Check compliance with specific framework\nnetintel-ocr rag compliance-check \\\n  --question \"Does our network segmentation meet PCI-DSS requirements?\" \\\n  --framework PCI-DSS-v4.0 \\\n  --include-evidence \\\n  --generate-report \\\n  --collection compliance_docs\n\n# Output:\n# PCI-DSS Network Segmentation Compliance Check:\n# \n# \u2705 Requirement 1.1: Network diagram documented\n#    Evidence: network-topology.pdf, last updated 2024-01-15\n# \n# \u2705 Requirement 1.2: Firewall configuration standards\n#    Evidence: 234 rules reviewed, all follow standard\n# \n# \u26a0\ufe0f Requirement 1.3: DMZ implementation\n#    Issue: Direct route found between DMZ and Internal\n#    Risk: Medium\n#    Remediation: Add deny rule on FW-Internal\n# \n# \u2705 Requirement 1.4: Personal firewall software\n#    Evidence: Endpoint protection policy enforced\n# \n# \u274c Requirement 1.5: Security policy review\n#    Issue: Policy last reviewed 13 months ago (requires annual)\n#    Risk: High\n#    Remediation: Schedule immediate policy review\n# \n# Overall Compliance: 78%\n# Critical Issues: 1\n# Warnings: 1\n# \n# Report saved to: pci_compliance_report_2024-01-30.pdf\n</code></pre>"},{"location":"minirag/#security-analysis","title":"Security Analysis","text":"<pre><code># Analyze security posture\nnetintel-ocr rag security-analysis \\\n  --question \"What are the potential attack vectors to our database?\" \\\n  --threat-model MITRE-ATT&amp;CK \\\n  --include-mitigations \\\n  --collection security_docs\n\n# Output:\n# Attack Vector Analysis for Database Access:\n# \n# Identified Attack Vectors:\n# \n# 1. External Network Path (High Risk)\n#    Path: Internet \u2192 Firewall \u2192 DMZ \u2192 App Server \u2192 Database\n#    MITRE Techniques: T1190 (Exploit Public-Facing Application)\n#    Current Mitigations:\n#    \u2022 WAF in place\n#    \u2022 IPS monitoring\n#    \u2022 Rate limiting enabled\n#    Gaps: No API gateway authentication\n# \n# 2. Lateral Movement (Medium Risk)\n#    Path: Compromised Workstation \u2192 Internal Network \u2192 Database\n#    MITRE Techniques: T1021 (Remote Services)\n#    Current Mitigations:\n#    \u2022 Network segmentation\n#    \u2022 MFA on privileged accounts\n#    Gaps: Some service accounts without MFA\n# \n# 3. Insider Threat (Medium Risk)\n#    Path: Direct database access via admin credentials\n#    MITRE Techniques: T1078 (Valid Accounts)\n#    Current Mitigations:\n#    \u2022 Audit logging\n#    \u2022 Privileged access management\n#    Gaps: No behavior analytics\n# \n# Recommended Actions:\n# 1. Implement API gateway with authentication\n# 2. Enable MFA for all service accounts\n# 3. Deploy user behavior analytics\n# 4. Regular penetration testing\n</code></pre>"},{"location":"minirag/#batch-processing","title":"Batch Processing","text":""},{"location":"minirag/#process-multiple-questions","title":"Process Multiple Questions","text":"<pre><code># Create batch query file\ncat &gt; queries.txt &lt;&lt; EOF\nWhat is our current network capacity?\nWhich systems have no redundancy?\nWhat are the critical single points of failure?\nHow many firewall rules allow any-to-any traffic?\nWhat is the backup retention policy?\nEOF\n\n# Run batch queries\nnetintel-ocr rag batch \\\n  --input queries.txt \\\n  --collection network_docs \\\n  --output results.json \\\n  --parallel 4 \\\n  --format json\n\n# View results\ncat results.json | jq '.queries[0]'\n# {\n#   \"question\": \"What is our current network capacity?\",\n#   \"answer\": \"Current network capacity: Core: 40Gbps (60% utilized)...\",\n#   \"confidence\": 0.92,\n#   \"sources\": [\"capacity-report.pdf\", \"network-metrics.xlsx\"],\n#   \"response_time_ms\": 234\n# }\n</code></pre>"},{"location":"minirag/#interactive-session","title":"Interactive Session","text":"<pre><code># Start interactive RAG session\nnetintel-ocr rag interactive \\\n  --collection network_docs \\\n  --history-file session.log \\\n  --context-memory 5\n\n# Interactive prompt appears:\n# MiniRAG Interactive Mode\n# Type 'help' for commands, 'exit' to quit\n# \n# rag&gt; what is our primary data center location?\n# Answer: The primary data center is located in Dallas, TX...\n# \n# rag&gt; how many servers are there?\n# Answer: Based on the context, there are 47 servers total...\n# \n# rag&gt; show graph\n# [Displays interactive network graph visualization]\n# \n# rag&gt; export session\n# Session exported to: rag_session_2024-01-30.md\n</code></pre>"},{"location":"minirag/#performance-optimization","title":"Performance Optimization","text":""},{"location":"minirag/#caching-configuration","title":"Caching Configuration","text":"<pre><code># Enable response caching\nnetintel-ocr rag config \\\n  --enable-cache \\\n  --cache-size 1000 \\\n  --cache-ttl 3600 \\\n  --collection network_docs\n\n# Query with cache\nnetintel-ocr rag query \\\n  --question \"What is the network topology?\" \\\n  --use-cache \\\n  --collection network_docs\n\n# Clear cache\nnetintel-ocr rag cache-clear --collection network_docs\n</code></pre>"},{"location":"minirag/#retrieval-tuning","title":"Retrieval Tuning","text":"<pre><code># Optimize retrieval parameters\nnetintel-ocr rag tune \\\n  --test-queries evaluation_set.txt \\\n  --optimize-for accuracy \\\n  --collection network_docs\n\n# Output:\n# Optimization Results:\n# \n# Best Parameters:\n# \u2022 Chunk Size: 512\n# \u2022 Chunk Overlap: 64\n# \u2022 Top-K: 8\n# \u2022 Temperature: 0.7\n# \u2022 Retrieval Strategy: hybrid\n# \u2022 Vector Weight: 0.4\n# \u2022 Graph Weight: 0.6\n# \n# Performance Improvement:\n# \u2022 Accuracy: 87% \u2192 94% (+7%)\n# \u2022 Latency: 380ms \u2192 290ms (-24%)\n# \u2022 Relevance: 0.81 \u2192 0.93 (+15%)\n</code></pre>"},{"location":"minirag/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"<pre><code># View RAG performance metrics\nnetintel-ocr rag metrics \\\n  --period 7d \\\n  --collection network_docs\n\n# Output:\n# MiniRAG Performance Metrics (7 days):\n# \n# Query Statistics:\n# \u2022 Total Queries: 1,847\n# \u2022 Unique Questions: 423\n# \u2022 Avg Response Time: 312ms\n# \u2022 P95 Response Time: 780ms\n# \u2022 Cache Hit Rate: 67%\n# \n# Retrieval Performance:\n# \u2022 Graph Queries: 34% (avg 120ms)\n# \u2022 Vector Queries: 28% (avg 290ms)\n# \u2022 Hybrid Queries: 38% (avg 410ms)\n# \n# Accuracy Metrics:\n# \u2022 User Satisfaction: 92%\n# \u2022 Answer Relevance: 0.89\n# \u2022 Source Accuracy: 94%\n# \n# Top Query Categories:\n# 1. Configuration (34%)\n# 2. Troubleshooting (28%)\n# 3. Compliance (22%)\n# 4. Capacity Planning (16%)\n</code></pre>"},{"location":"minirag/#export-and-integration","title":"Export and Integration","text":""},{"location":"minirag/#export-conversations","title":"Export Conversations","text":"<pre><code># Export Q&amp;A as documentation\nnetintel-ocr rag export \\\n  --format markdown \\\n  --include-sources \\\n  --include-confidence \\\n  --output network_qa.md \\\n  --collection network_docs\n\n# Export as JSON for API integration\nnetintel-ocr rag export \\\n  --format json \\\n  --schema openapi \\\n  --output rag_api.json \\\n  --collection network_docs\n</code></pre>"},{"location":"minirag/#generate-knowledge-base","title":"Generate Knowledge Base","text":"<pre><code># Build comprehensive KB from queries\nnetintel-ocr rag build-kb \\\n  --min-confidence 0.8 \\\n  --categories \"network,security,operations\" \\\n  --format html \\\n  --output knowledge_base.html \\\n  --collection network_docs\n\n# Generate FAQ\nnetintel-ocr rag generate-faq \\\n  --top-questions 50 \\\n  --group-by-category \\\n  --output faq.md \\\n  --collection network_docs\n</code></pre>"},{"location":"minirag/#api-integration","title":"API Integration","text":""},{"location":"minirag/#rest-api-usage","title":"REST API Usage","text":"<pre><code>import requests\n\n# Query via API\nresponse = requests.post(\n    \"http://localhost:8000/rag/query\",\n    json={\n        \"question\": \"What is the database connection string?\",\n        \"collection\": \"network_docs\",\n        \"mode\": \"hybrid\",\n        \"include_sources\": True\n    }\n)\n\nresult = response.json()\nprint(f\"Answer: {result['answer']}\")\nprint(f\"Confidence: {result['confidence']}\")\nprint(f\"Sources: {result['sources']}\")\n</code></pre>"},{"location":"minirag/#python-sdk","title":"Python SDK","text":"<pre><code>import os\nfrom netintel_ocr.rag import MiniRAG\n\n# Configure external Ollama\nos.environ['OLLAMA_HOST'] = \"http://your-ollama-server:11434\"\n\n# Initialize MiniRAG\nrag = MiniRAG(\n    collection=\"network_docs\",\n    llm_model=\"gemma3:4b-it-qat\",\n    embedding_model=\"qwen3-embedding:8b\",\n    retrieval_strategy=\"adaptive\",\n    ollama_host=os.environ.get('OLLAMA_HOST', 'http://localhost:11434')\n)\n\n# Query\nresult = rag.query(\n    question=\"What are the backup procedures?\",\n    include_context=True,\n    max_tokens=500\n)\n\nprint(result.answer)\nprint(f\"Retrieved from: {result.sources}\")\nprint(f\"Confidence: {result.confidence}\")\n\n# Batch processing\nquestions = [\n    \"What is the network capacity?\",\n    \"How many servers do we have?\",\n    \"What is the DR strategy?\"\n]\n\nresults = rag.batch_query(questions)\nfor q, r in zip(questions, results):\n    print(f\"Q: {q}\")\n    print(f\"A: {r.answer}\\n\")\n</code></pre>"},{"location":"minirag/#troubleshooting","title":"Troubleshooting","text":""},{"location":"minirag/#common-issues","title":"Common Issues","text":"<pre><code># Debug slow queries\nnetintel-ocr rag debug \\\n  --question \"Your question here\" \\\n  --show-retrieval \\\n  --show-timing \\\n  --show-reasoning \\\n  --collection network_docs\n\n# Output:\n# Query Debug Information:\n# \n# 1. Query Classification (12ms)\n#    Type: entity_centric\n#    Strategy: graph-first\n# \n# 2. Graph Retrieval (45ms)\n#    Entities found: 12\n#    Relationships: 34\n# \n# 3. Vector Retrieval (89ms)\n#    Documents: 5\n#    Chunks: 15\n# \n# 4. Context Building (23ms)\n#    Context size: 2048 tokens\n# \n# 5. LLM Generation (234ms)\n#    Model: gemma3:4b-it-qat\n#    Tokens: 450\n# \n# Total Time: 403ms\n# Bottleneck: LLM Generation (58%)\n</code></pre>"},{"location":"minirag/#improve-answer-quality","title":"Improve Answer Quality","text":"<pre><code># Analyze answer quality\nnetintel-ocr rag analyze \\\n  --question \"Your question\" \\\n  --answer \"Generated answer\" \\\n  --check-hallucination \\\n  --check-completeness \\\n  --collection network_docs\n\n# Re-index for better retrieval\nnetintel-ocr rag reindex \\\n  --optimize-embeddings \\\n  --update-graph \\\n  --collection network_docs\n</code></pre>"},{"location":"minirag/#best-practices","title":"Best Practices","text":"<ol> <li>Choose the Right Mode:</li> <li>Use <code>graph</code> mode for structural queries</li> <li>Use <code>vector</code> mode for policy/procedure questions  </li> <li>Use <code>hybrid</code> mode for complex analysis</li> <li> <p>Use <code>embeddings</code> mode for similarity searches</p> </li> <li> <p>Optimize for Your Use Case:</p> </li> <li>Tune chunk size based on document types</li> <li>Adjust temperature for creativity vs accuracy</li> <li>Use caching for frequently asked questions</li> <li> <p>Enable monitoring to track performance</p> </li> <li> <p>Maintain Quality:</p> </li> <li>Regularly update your knowledge graph</li> <li>Re-index after major document changes</li> <li>Monitor confidence scores</li> <li>Collect user feedback for improvements</li> </ol>"},{"location":"minirag/#command-reference","title":"Command Reference","text":"<pre><code># Essential MiniRAG commands\nnetintel-ocr rag init              # Initialize MiniRAG\nnetintel-ocr rag query             # Ask a question\nnetintel-ocr rag batch             # Process multiple questions\nnetintel-ocr rag interactive       # Start interactive session\nnetintel-ocr rag compare           # Compare entities\nnetintel-ocr rag compliance-check  # Check compliance\nnetintel-ocr rag metrics           # View performance metrics\nnetintel-ocr rag export            # Export Q&amp;A pairs\nnetintel-ocr rag debug             # Debug queries\nnetintel-ocr rag tune              # Optimize parameters\n</code></pre>"},{"location":"monitoring/","title":"Monitoring Guide","text":""},{"location":"monitoring/#overview","title":"Overview","text":"<p>NetIntel-OCR provides comprehensive monitoring capabilities for production deployments, including metrics, logging, health checks, and alerting.</p>"},{"location":"monitoring/#monitoring-architecture","title":"Monitoring Architecture","text":"<pre><code>graph LR\n    A[NetIntel-OCR] --&gt; B[Metrics]\n    A --&gt; C[Logs]\n    A --&gt; D[Health Checks]\n    A --&gt; E[Traces]\n\n    B --&gt; F[Prometheus]\n    C --&gt; G[Elasticsearch]\n    D --&gt; H[Health API]\n    E --&gt; I[Jaeger]\n\n    F --&gt; J[Grafana]\n    G --&gt; J\n    H --&gt; K[Alerts]\n    I --&gt; J</code></pre>"},{"location":"monitoring/#system-monitoring","title":"System Monitoring","text":""},{"location":"monitoring/#health-checks","title":"Health Checks","text":"<pre><code># Check overall system health\nnetintel-ocr system health\n\n# Detailed health report\nnetintel-ocr system health --detailed\n\n# Component-specific health\nnetintel-ocr system health --component api\nnetintel-ocr system health --component mcp\nnetintel-ocr system health --component db\nnetintel-ocr system health --component models\n\n# JSON output for automation\nnetintel-ocr system health --json\n</code></pre>"},{"location":"monitoring/#system-metrics","title":"System Metrics","text":"<pre><code># View current metrics\nnetintel-ocr system metrics\n\n# Continuous metrics monitoring\nnetintel-ocr system metrics --watch\n\n# Export metrics\nnetintel-ocr system metrics --export metrics.json\n\n# Specific metric categories\nnetintel-ocr system metrics --category cpu\nnetintel-ocr system metrics --category memory\nnetintel-ocr system metrics --category disk\nnetintel-ocr system metrics --category network\n</code></pre>"},{"location":"monitoring/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Performance snapshot\nnetintel-ocr system performance\n\n# Performance profiling\nnetintel-ocr system profile --duration 60\n\n# Bottleneck analysis\nnetintel-ocr system analyze\n\n# Resource usage\nnetintel-ocr system resources\n</code></pre>"},{"location":"monitoring/#server-monitoring","title":"Server Monitoring","text":""},{"location":"monitoring/#api-server-metrics","title":"API Server Metrics","text":"<pre><code># Server status\nnetintel-ocr server status\n\n# Server metrics\nnetintel-ocr server metrics\n\n# Request statistics\nnetintel-ocr server requests --stats\n\n# Active connections\nnetintel-ocr server connections\n\n# Worker status\nnetintel-ocr server workers\n</code></pre>"},{"location":"monitoring/#endpoint-monitoring","title":"Endpoint Monitoring","text":"<pre><code># Health endpoints\nGET /health          # Basic health check\nGET /ready          # Readiness probe\nGET /alive          # Liveness probe\nGET /metrics        # Prometheus metrics\nGET /status         # Detailed status\n</code></pre>"},{"location":"monitoring/#example-health-response","title":"Example Health Response","text":"<pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"version\": \"0.1.17\",\n  \"uptime\": 3600,\n  \"components\": {\n    \"api\": \"healthy\",\n    \"mcp\": \"healthy\",\n    \"database\": \"healthy\",\n    \"models\": \"healthy\",\n    \"cache\": \"healthy\"\n  },\n  \"metrics\": {\n    \"requests_total\": 1234,\n    \"requests_per_second\": 10.5,\n    \"average_latency_ms\": 250,\n    \"error_rate\": 0.01\n  }\n}\n</code></pre>"},{"location":"monitoring/#prometheus-integration","title":"Prometheus Integration","text":""},{"location":"monitoring/#metrics-endpoint-configuration","title":"Metrics Endpoint Configuration","text":"<pre><code># Enable Prometheus metrics\nnetintel-ocr config set monitoring.prometheus.enabled true\nnetintel-ocr config set monitoring.prometheus.port 9090\nnetintel-ocr config set monitoring.prometheus.path /metrics\n</code></pre>"},{"location":"monitoring/#available-metrics","title":"Available Metrics","text":"<pre><code># Request metrics\nnetintel_requests_total{method=\"POST\",endpoint=\"/process\",status=\"200\"} 1234\nnetintel_request_duration_seconds{quantile=\"0.99\"} 1.5\nnetintel_requests_in_flight 5\n\n# Processing metrics\nnetintel_documents_processed_total 456\nnetintel_pages_processed_total 7890\nnetintel_diagrams_extracted_total 234\nnetintel_processing_duration_seconds{document=\"example.pdf\"} 45.2\n\n# Model metrics\nnetintel_model_inference_duration_seconds{model=\"qwen2.5vl:7b\"} 2.3\nnetintel_model_load_time_seconds{model=\"qwen2.5vl:7b\"} 15.4\nnetintel_model_memory_bytes{model=\"qwen2.5vl:7b\"} 7516192768\n\n# Database metrics\nnetintel_db_connections_active 10\nnetintel_db_queries_total{type=\"vector_search\"} 567\nnetintel_db_query_duration_seconds{operation=\"search\"} 0.15\n\n# System metrics\nnetintel_cpu_usage_percent 45.2\nnetintel_memory_usage_bytes 4294967296\nnetintel_disk_usage_bytes{path=\"/app/cache\"} 10737418240\n</code></pre>"},{"location":"monitoring/#prometheus-configuration","title":"Prometheus Configuration","text":"<pre><code># prometheus.yml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'netintel-ocr'\n    static_configs:\n      - targets: ['localhost:9090']\n    metrics_path: /metrics\n    scrape_interval: 10s\n</code></pre>"},{"location":"monitoring/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"monitoring/#import-dashboard","title":"Import Dashboard","text":"<pre><code># Export dashboard template\nnetintel-ocr monitoring dashboard export &gt; dashboard.json\n\n# Configure Grafana\nnetintel-ocr monitoring dashboard config \\\n  --grafana-url http://localhost:3000 \\\n  --grafana-api-key $GRAFANA_API_KEY\n\n# Deploy dashboard\nnetintel-ocr monitoring dashboard deploy\n</code></pre>"},{"location":"monitoring/#key-dashboard-panels","title":"Key Dashboard Panels","text":"<ol> <li>Request Rate: Requests per second over time</li> <li>Latency: P50, P95, P99 latencies</li> <li>Error Rate: Percentage of failed requests</li> <li>Processing Queue: Documents in queue</li> <li>Model Performance: Inference times by model</li> <li>Resource Usage: CPU, memory, disk utilization</li> <li>Database Performance: Query latencies and throughput</li> </ol>"},{"location":"monitoring/#logging","title":"Logging","text":""},{"location":"monitoring/#log-configuration","title":"Log Configuration","text":"<pre><code># Set log level\nnetintel-ocr config set logging.level INFO\n\n# Set log format\nnetintel-ocr config set logging.format json\n\n# Enable file logging\nnetintel-ocr config set logging.file /var/log/netintel.log\n\n# Configure rotation\nnetintel-ocr config set logging.rotation.enabled true\nnetintel-ocr config set logging.rotation.max_size 100MB\nnetintel-ocr config set logging.rotation.max_files 10\n</code></pre>"},{"location":"monitoring/#log-levels","title":"Log Levels","text":"<ul> <li>DEBUG: Detailed debugging information</li> <li>INFO: General informational messages</li> <li>WARNING: Warning messages</li> <li>ERROR: Error messages</li> <li>CRITICAL: Critical issues</li> </ul>"},{"location":"monitoring/#structured-logging","title":"Structured Logging","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"INFO\",\n  \"message\": \"Processing document\",\n  \"document\": \"example.pdf\",\n  \"pages\": 10,\n  \"request_id\": \"req-12345\",\n  \"user\": \"api-user\",\n  \"duration_ms\": 4500,\n  \"metadata\": {\n    \"model\": \"qwen2.5vl:7b\",\n    \"diagrams_found\": 3\n  }\n}\n</code></pre>"},{"location":"monitoring/#log-aggregation","title":"Log Aggregation","text":"<pre><code># Configure Elasticsearch output\nnetintel-ocr config set logging.elasticsearch.enabled true\nnetintel-ocr config set logging.elasticsearch.host elasticsearch:9200\nnetintel-ocr config set logging.elasticsearch.index netintel-logs\n\n# Configure Fluentd\nnetintel-ocr config set logging.fluentd.enabled true\nnetintel-ocr config set logging.fluentd.host fluentd:24224\n</code></pre>"},{"location":"monitoring/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"monitoring/#opentelemetry-integration","title":"OpenTelemetry Integration","text":"<pre><code># Enable tracing\nnetintel-ocr config set tracing.enabled true\nnetintel-ocr config set tracing.provider opentelemetry\n\n# Configure Jaeger\nnetintel-ocr config set tracing.jaeger.endpoint http://jaeger:14268/api/traces\nnetintel-ocr config set tracing.sample_rate 0.1\n</code></pre>"},{"location":"monitoring/#trace-context","title":"Trace Context","text":"<pre><code># Automatic trace propagation\n{\n  \"trace_id\": \"4bf92f3577b34da6a3ce929d0e0e4736\",\n  \"span_id\": \"00f067aa0ba902b7\",\n  \"trace_flags\": \"01\",\n  \"operations\": [\n    {\n      \"name\": \"process_document\",\n      \"duration_ms\": 4500,\n      \"children\": [\n        {\"name\": \"extract_text\", \"duration_ms\": 1200},\n        {\"name\": \"detect_diagrams\", \"duration_ms\": 2000},\n        {\"name\": \"generate_mermaid\", \"duration_ms\": 1000},\n        {\"name\": \"store_results\", \"duration_ms\": 300}\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"monitoring/#alerting","title":"Alerting","text":""},{"location":"monitoring/#alert-configuration","title":"Alert Configuration","text":"<pre><code># Configure alert rules\nnetintel-ocr monitoring alerts add \\\n  --name high-error-rate \\\n  --condition \"error_rate &gt; 0.05\" \\\n  --duration 5m \\\n  --severity critical\n\n# List alerts\nnetintel-ocr monitoring alerts list\n\n# Test alert\nnetintel-ocr monitoring alerts test high-error-rate\n</code></pre>"},{"location":"monitoring/#alert-channels","title":"Alert Channels","text":"<pre><code># Configure email alerts\nnetintel-ocr monitoring alerts channel add email \\\n  --smtp-host smtp.gmail.com \\\n  --smtp-port 587 \\\n  --from alerts@example.com \\\n  --to ops@example.com\n\n# Configure Slack alerts\nnetintel-ocr monitoring alerts channel add slack \\\n  --webhook-url https://hooks.slack.com/services/XXX\n\n# Configure PagerDuty\nnetintel-ocr monitoring alerts channel add pagerduty \\\n  --integration-key YOUR_KEY\n</code></pre>"},{"location":"monitoring/#alert-rules-examples","title":"Alert Rules Examples","text":"<pre><code># alerts.yaml\nalerts:\n  - name: high_error_rate\n    expr: rate(netintel_requests_total{status=~\"5..\"}[5m]) &gt; 0.05\n    for: 5m\n    severity: critical\n    annotations:\n      summary: \"High error rate detected\"\n      description: \"Error rate is {{ $value }} (threshold 0.05)\"\n\n  - name: slow_processing\n    expr: netintel_processing_duration_seconds{quantile=\"0.99\"} &gt; 60\n    for: 10m\n    severity: warning\n    annotations:\n      summary: \"Slow document processing\"\n\n  - name: low_disk_space\n    expr: netintel_disk_free_bytes &lt; 1073741824\n    for: 5m\n    severity: critical\n    annotations:\n      summary: \"Low disk space (&lt; 1GB)\"\n</code></pre>"},{"location":"monitoring/#performance-profiling","title":"Performance Profiling","text":""},{"location":"monitoring/#cpu-profiling","title":"CPU Profiling","text":"<pre><code># Start CPU profiling\nnetintel-ocr system profile cpu --duration 60 --output cpu.prof\n\n# Analyze profile\nnetintel-ocr system profile analyze cpu.prof\n\n# Generate flame graph\nnetintel-ocr system profile flamegraph cpu.prof --output flame.svg\n</code></pre>"},{"location":"monitoring/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Memory snapshot\nnetintel-ocr system profile memory --output memory.prof\n\n# Memory leaks detection\nnetintel-ocr system profile memory --detect-leaks\n\n# Heap analysis\nnetintel-ocr system profile heap\n</code></pre>"},{"location":"monitoring/#custom-metrics","title":"Custom Metrics","text":""},{"location":"monitoring/#adding-custom-metrics","title":"Adding Custom Metrics","text":"<pre><code>from netintel_ocr.monitoring import metrics\n\n# Counter\ndocuments_processed = metrics.Counter(\n    'documents_processed_total',\n    'Total documents processed'\n)\ndocuments_processed.inc()\n\n# Histogram\nprocessing_time = metrics.Histogram(\n    'processing_duration_seconds',\n    'Document processing duration'\n)\nwith processing_time.time():\n    process_document()\n\n# Gauge\nqueue_size = metrics.Gauge(\n    'processing_queue_size',\n    'Current queue size'\n)\nqueue_size.set(len(queue))\n</code></pre>"},{"location":"monitoring/#monitoring-best-practices","title":"Monitoring Best Practices","text":""},{"location":"monitoring/#1-set-up-dashboards-early","title":"1. Set Up Dashboards Early","text":"<pre><code># Deploy standard dashboards\nnetintel-ocr monitoring dashboard deploy --all\n\n# Customize for your needs\nnetintel-ocr monitoring dashboard customize \\\n  --template standard \\\n  --output custom-dashboard.json\n</code></pre>"},{"location":"monitoring/#2-configure-appropriate-retention","title":"2. Configure Appropriate Retention","text":"<pre><code># Set metrics retention\nnetintel-ocr config set monitoring.metrics.retention 30d\n\n# Set log retention\nnetintel-ocr config set logging.retention 7d\n\n# Set trace retention\nnetintel-ocr config set tracing.retention 3d\n</code></pre>"},{"location":"monitoring/#3-monitor-key-slis","title":"3. Monitor Key SLIs","text":"<ul> <li>Availability: Uptime percentage</li> <li>Latency: P50, P95, P99 response times</li> <li>Error Rate: Percentage of failed requests</li> <li>Throughput: Requests/documents per second</li> </ul>"},{"location":"monitoring/#4-set-up-alerting-thresholds","title":"4. Set Up Alerting Thresholds","text":"<pre><code># SLA-based alerts\nnetintel-ocr monitoring alerts add \\\n  --name sla-availability \\\n  --condition \"availability &lt; 0.999\" \\\n  --severity critical\n\nnetintel-ocr monitoring alerts add \\\n  --name sla-latency \\\n  --condition \"p99_latency &gt; 5s\" \\\n  --severity warning\n</code></pre>"},{"location":"monitoring/#troubleshooting-monitoring","title":"Troubleshooting Monitoring","text":""},{"location":"monitoring/#no-metrics-data","title":"No Metrics Data","text":"<pre><code># Check metrics endpoint\ncurl http://localhost:9090/metrics\n\n# Verify Prometheus scraping\nnetintel-ocr monitoring verify prometheus\n\n# Check configuration\nnetintel-ocr config get monitoring.prometheus\n</code></pre>"},{"location":"monitoring/#missing-logs","title":"Missing Logs","text":"<pre><code># Check log configuration\nnetintel-ocr config get logging\n\n# Test log output\nnetintel-ocr system test-logs\n\n# Verify permissions\nls -la /var/log/netintel.log\n</code></pre>"},{"location":"monitoring/#performance-issues","title":"Performance Issues","text":"<pre><code># Reduce metric cardinality\nnetintel-ocr config set monitoring.metrics.cardinality low\n\n# Adjust sampling\nnetintel-ocr config set tracing.sample_rate 0.01\n\n# Optimize log level\nnetintel-ocr config set logging.level WARNING\n</code></pre>"},{"location":"monitoring/#monitoring-in-production","title":"Monitoring in Production","text":""},{"location":"monitoring/#kubernetes-monitoring","title":"Kubernetes Monitoring","text":"<pre><code># ServiceMonitor for Prometheus Operator\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: netintel-ocr\nspec:\n  selector:\n    matchLabels:\n      app: netintel-ocr\n  endpoints:\n  - port: metrics\n    interval: 10s\n</code></pre>"},{"location":"monitoring/#docker-monitoring","title":"Docker Monitoring","text":"<pre><code># docker-compose.yml\nservices:\n  netintel-ocr:\n    image: netintel-ocr:latest\n    labels:\n      - \"prometheus.io/scrape=true\"\n      - \"prometheus.io/port=9090\"\n      - \"prometheus.io/path=/metrics\"\n</code></pre>"},{"location":"monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment Guide - Production deployment</li> <li>Performance Guide - Performance optimization</li> <li>Troubleshooting Guide - Common issues</li> <li>API Guide - API monitoring endpoints</li> </ul>"},{"location":"multi-model/","title":"Multi-Model Selection Guide","text":""},{"location":"multi-model/#overview","title":"Overview","text":"<p>NetIntel-OCR supports multiple vision-language models optimized for different tasks. Selecting the right model improves accuracy and performance.</p>"},{"location":"multi-model/#model-categories","title":"Model Categories","text":""},{"location":"multi-model/#ocr-optimized-models","title":"OCR-Optimized Models","text":"<p>Best for text extraction from documents.</p> Model Speed Accuracy Memory Use Case <code>Nanonets-OCR-s:latest</code> \u26a1\u26a1\u26a1 High 4GB Default OCR <code>moondream:latest</code> \u26a1\u26a1 Medium 3GB Fast processing <code>NetIntelOCR-7B-0925</code> \u26a1\u26a1 Very High 8GB Default (v0.1.16)"},{"location":"multi-model/#vision-language-models","title":"Vision-Language Models","text":"<p>Best for diagram understanding and component extraction.</p> Model Speed Accuracy Memory Use Case <code>qwen2.5vl:7b</code> \u26a1\u26a1 Very High 8GB Recommended <code>llava:13b</code> \u26a1 Highest 16GB Complex diagrams <code>cogvlm:latest</code> Slow Highest 32GB Critical accuracy <code>minicpm-v:latest</code> \u26a1\u26a1\u26a1 Medium 4GB Quick preview"},{"location":"multi-model/#lightweight-models","title":"Lightweight Models","text":"<p>Best for quick detection and simple diagrams.</p> Model Speed Accuracy Memory Use Case <code>bakllava:latest</code> \u26a1\u26a1\u26a1 Medium 4GB Fast detection <code>llava-phi3:latest</code> \u26a1\u26a1\u26a1 Medium 3GB Edge deployment <code>llama3.2-vision:11b</code> \u26a1 High 12GB Balanced"},{"location":"multi-model/#task-specific-recommendations","title":"Task-Specific Recommendations","text":""},{"location":"multi-model/#text-extraction","title":"Text Extraction","text":"<pre><code># Fast text extraction\nnetintel-ocr process file document.pdf --model moondream:latest\n\n# High accuracy OCR\nnetintel-ocr process file document.pdf --model Nanonets-OCR-s:latest\n\n# Default balanced approach\nnetintel-ocr process file document.pdf --model NetIntelOCR-7B-0925\n</code></pre>"},{"location":"multi-model/#network-diagrams","title":"Network Diagrams","text":"<pre><code># Simple network topology\nnetintel-ocr process file network.pdf --network-model minicpm-v:latest\n\n# Complex architecture\nnetintel-ocr process file architecture.pdf --network-model llava:13b\n\n# Recommended for most cases\nnetintel-ocr process file design.pdf --network-model qwen2.5vl:7b\n</code></pre>"},{"location":"multi-model/#flow-diagrams","title":"Flow Diagrams","text":"<pre><code># Business process flows\nnetintel-ocr process file process.pdf --flow-model qwen2.5vl:7b\n\n# Complex decision trees\nnetintel-ocr process file workflow.pdf --flow-model llava:13b\n\n# Quick extraction\nnetintel-ocr process file simple-flow.pdf --flow-model bakllava:latest\n</code></pre>"},{"location":"multi-model/#model-selection-strategy","title":"Model Selection Strategy","text":""},{"location":"multi-model/#by-document-type","title":"By Document Type","text":""},{"location":"multi-model/#technical-specifications","title":"Technical Specifications","text":"<pre><code>netintel-ocr \\\n  --model Nanonets-OCR-s:latest \\\n  --network-model cogvlm:latest \\\n  --flow-model llava:13b \\\n  technical-spec.pdf\n</code></pre>"},{"location":"multi-model/#marketing-materials","title":"Marketing Materials","text":"<pre><code>netintel-ocr \\\n  --model moondream:latest \\\n  --network-model minicpm-v:latest \\\n  --flow-model bakllava:latest \\\n  brochure.pdf\n</code></pre>"},{"location":"multi-model/#security-documentation","title":"Security Documentation","text":"<pre><code>netintel-ocr \\\n  --model NetIntelOCR-7B-0925 \\\n  --network-model qwen2.5vl:7b \\\n  --security-focus \\\n  security-guide.pdf\n</code></pre>"},{"location":"multi-model/#by-resource-constraints","title":"By Resource Constraints","text":""},{"location":"multi-model/#limited-memory-4gb","title":"Limited Memory (4GB)","text":"<pre><code>netintel-ocr \\\n  --model moondream:latest \\\n  --network-model minicpm-v:latest \\\n  --low-memory \\\n  document.pdf\n</code></pre>"},{"location":"multi-model/#gpu-available","title":"GPU Available","text":"<pre><code>netintel-ocr \\\n  --model NetIntelOCR-7B-0925 \\\n  --network-model llava:13b \\\n  --gpu \\\n  document.pdf\n</code></pre>"},{"location":"multi-model/#cpu-only","title":"CPU Only","text":"<pre><code>netintel-ocr \\\n  --model Nanonets-OCR-s:latest \\\n  --network-model bakllava:latest \\\n  --cpu-optimized \\\n  document.pdf\n</code></pre>"},{"location":"multi-model/#model-configuration","title":"Model Configuration","text":""},{"location":"multi-model/#default-models","title":"Default Models","text":"<p>Set default models in configuration:</p> <pre><code># config.yaml\nmodels:\n  text_extraction: NetIntelOCR-7B-0925\n  network_detection: qwen2.5vl:7b\n  flow_detection: qwen2.5vl:7b\n  component_extraction: qwen2.5vl:7b\n\nfallbacks:\n  text_extraction: Nanonets-OCR-s:latest\n  network_detection: minicpm-v:latest\n</code></pre>"},{"location":"multi-model/#model-specific-parameters","title":"Model-Specific Parameters","text":"<pre><code>model_configs:\n  qwen2.5vl:\n    temperature: 0.3\n    max_tokens: 4096\n    top_p: 0.9\n\n  llava:\n    temperature: 0.5\n    max_tokens: 8192\n    num_predict: 2048\n\n  NetIntelOCR-7B-0925:\n    temperature: 0.2\n    repeat_penalty: 1.1\n</code></pre>"},{"location":"multi-model/#performance-optimization","title":"Performance Optimization","text":""},{"location":"multi-model/#batch-processing","title":"Batch Processing","text":"<pre><code># Use fast models for batch\nnetintel-ocr process batch \\\n  --model moondream:latest \\\n  --network-model minicpm-v:latest \\\n  *.pdf\n</code></pre>"},{"location":"multi-model/#multi-pass-strategy","title":"Multi-Pass Strategy","text":"<pre><code># First pass: Quick detection\nnetintel-ocr --detect-only \\\n  --network-model bakllava:latest \\\n  document.pdf\n\n# Second pass: Detailed extraction on detected pages\nnetintel-ocr --pages 5,12,18 \\\n  --network-model llava:13b \\\n  document.pdf\n</code></pre>"},{"location":"multi-model/#model-caching","title":"Model Caching","text":"<pre><code># Preload models\nnetintel-ocr model preload \\\n  \"qwen2.5vl:7b,Nanonets-OCR-s:latest\"\n\n# Keep models in memory\nnetintel-ocr model keep-loaded \\\n  --model-cache-ttl 3600 \\\n  document.pdf\n</code></pre>"},{"location":"multi-model/#model-benchmarks","title":"Model Benchmarks","text":""},{"location":"multi-model/#processing-speed-pagesminute","title":"Processing Speed (pages/minute)","text":"Task Nanonets qwen2.5vl llava minicpm-v Text Only 12 8 4 15 Simple Diagram 8 6 3 10 Complex Diagram 4 4 2 6"},{"location":"multi-model/#accuracy-scores-f1","title":"Accuracy Scores (F1)","text":"Task Nanonets qwen2.5vl llava minicpm-v Text OCR 0.95 0.92 0.94 0.85 Component Detection 0.82 0.91 0.94 0.78 Connection Tracing 0.75 0.88 0.92 0.72"},{"location":"multi-model/#custom-model-integration","title":"Custom Model Integration","text":""},{"location":"multi-model/#add-custom-model","title":"Add Custom Model","text":"<pre><code># Download and configure\nollama pull your-custom-model:latest\n\n# Register with NetIntel-OCR\nnetintel-ocr model register \\\n  --name custom-model \\\n  --type vision-language \\\n  --capabilities \"network,flow,text\"\n</code></pre>"},{"location":"multi-model/#model-evaluation","title":"Model Evaluation","text":"<pre><code># Test model performance\nnetintel-ocr model evaluate custom-model:latest \\\n  --test-set /path/to/test/documents \\\n  --metrics \"accuracy,speed,memory\"\n</code></pre>"},{"location":"multi-model/#troubleshooting-models","title":"Troubleshooting Models","text":""},{"location":"multi-model/#model-not-found","title":"Model Not Found","text":"<pre><code># List available models\nollama list\n\n# Pull missing model\nollama pull qwen2.5vl:7b\n</code></pre>"},{"location":"multi-model/#out-of-memory","title":"Out of Memory","text":"<pre><code># Use smaller model\nnetintel-ocr process file document.pdf --network-model minicpm-v:latest\n\n# Reduce context size\nnetintel-ocr process file document.pdf --max-context 2048\n</code></pre>"},{"location":"multi-model/#slow-processing","title":"Slow Processing","text":"<pre><code># Use faster model\nnetintel-ocr process file document.pdf --network-model bakllava:latest\n\n# Enable GPU\nnetintel-ocr process file document.pdf --gpu\n\n# Reduce quality for speed\nnetintel-ocr process file document.pdf --fast-mode\n</code></pre>"},{"location":"multi-model/#next-steps","title":"Next Steps","text":"<ul> <li>Customization Guide - Fine-tune model parameters</li> <li>Performance Guide - Optimize for large batches</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"performance/","title":"Performance Tuning Guide","text":""},{"location":"performance/#overview","title":"Overview","text":"<p>This guide covers performance optimization techniques for NetIntel-OCR, including model optimization, processing parallelization, caching strategies, and resource management.</p>"},{"location":"performance/#performance-architecture","title":"Performance Architecture","text":"<pre><code>graph TB\n    A[Input Documents] --&gt; B[Queue Manager]\n    B --&gt; C[Parallel Workers]\n    C --&gt; D[Model Pool]\n    C --&gt; E[Cache Layer]\n    D --&gt; F[GPU/CPU Resources]\n    E --&gt; G[Results]\n    F --&gt; G</code></pre>"},{"location":"performance/#benchmarking","title":"Benchmarking","text":""},{"location":"performance/#performance-testing","title":"Performance Testing","text":"<pre><code># Run performance benchmark\nnetintel-ocr system benchmark\n\n# Benchmark specific operation\nnetintel-ocr system benchmark --operation processing\nnetintel-ocr system benchmark --operation vector-search\nnetintel-ocr system benchmark --operation kg-query\n\n# Custom benchmark\nnetintel-ocr system benchmark --custom \\\n  --documents 100 \\\n  --parallel 4 \\\n  --duration 300\n</code></pre>"},{"location":"performance/#performance-baseline","title":"Performance Baseline","text":"<pre><code># Establish baseline\nnetintel-ocr system baseline create\n\n# Compare with baseline\nnetintel-ocr system baseline compare\n\n# Export performance report\nnetintel-ocr system baseline report --output perf-report.html\n</code></pre>"},{"location":"performance/#model-optimization","title":"Model Optimization","text":""},{"location":"performance/#model-selection","title":"Model Selection","text":"<pre><code># List models by performance\nnetintel-ocr model list --sort-by speed\n\n# Compare model performance\nnetintel-ocr model compare \\\n  --models \"qwen2.5vl:7b,llava:13b,minicpm-v:latest\" \\\n  --metric speed\n\n# Recommend optimal model\nnetintel-ocr model recommend \\\n  --priority speed \\\n  --accuracy-threshold 0.8\n</code></pre>"},{"location":"performance/#model-performance-profiles","title":"Model Performance Profiles","text":"Model Speed Accuracy Memory Use Case minicpm-v:latest Fast Good 2GB Quick processing qwen2.5vl:7b Balanced Excellent 7GB Production llava:13b Slow Best 13GB High accuracy bakllava:latest Very Fast Fair 1GB Batch processing"},{"location":"performance/#model-configuration","title":"Model Configuration","text":"<pre><code># Use fast models for batch\nnetintel-ocr config set models.batch \"bakllava:latest\"\n\n# Use accurate models for critical docs\nnetintel-ocr config set models.critical \"llava:13b\"\n\n# Configure model-specific settings\nnetintel-ocr model config qwen2.5vl:7b \\\n  --max-context 2048 \\\n  --temperature 0.1 \\\n  --num-predict 1024\n</code></pre>"},{"location":"performance/#model-preloading","title":"Model Preloading","text":"<pre><code># Preload frequently used models\nnetintel-ocr model preload qwen2.5vl:7b\nnetintel-ocr model preload minicpm-v:latest\n\n# Keep models in memory\nnetintel-ocr model keep-loaded --models \"qwen2.5vl:7b,minicpm-v:latest\"\n\n# Configure model pool\nnetintel-ocr config set performance.model_pool.size 3\nnetintel-ocr config set performance.model_pool.ttl 3600\n</code></pre>"},{"location":"performance/#processing-optimization","title":"Processing Optimization","text":""},{"location":"performance/#parallel-processing","title":"Parallel Processing","text":"<pre><code># Optimize parallel workers\nnetintel-ocr config set processing.max_parallel $(nproc)\n\n# Configure by document type\nnetintel-ocr config set processing.parallel.text 8\nnetintel-ocr config set processing.parallel.network 4\nnetintel-ocr config set processing.parallel.flow 4\n\n# Dynamic scaling\nnetintel-ocr config set processing.scaling.enabled true\nnetintel-ocr config set processing.scaling.min_workers 2\nnetintel-ocr config set processing.scaling.max_workers 16\n</code></pre>"},{"location":"performance/#batch-processing-optimization","title":"Batch Processing Optimization","text":"<pre><code># Optimize batch size\nnetintel-ocr config set processing.batch_size 50\n\n# Enable streaming\nnetintel-ocr config set processing.streaming.enabled true\n\n# Configure pipeline\nnetintel-ocr config set processing.pipeline.stages 3\nnetintel-ocr config set processing.pipeline.buffer_size 100\n</code></pre>"},{"location":"performance/#processing-strategies","title":"Processing Strategies","text":"<pre><code># Fast mode - speed priority\nnetintel-ocr process file document.pdf --fast-mode\n\n# Balanced mode - default\nnetintel-ocr process file document.pdf\n\n# Accurate mode - quality priority\nnetintel-ocr process file document.pdf --accurate-mode\n\n# Custom strategy\nnetintel-ocr process file document.pdf \\\n  --strategy custom \\\n  --model minicpm-v:latest \\\n  --parallel 8 \\\n  --no-context \\\n  --skip-validation\n</code></pre>"},{"location":"performance/#gpu-acceleration","title":"GPU Acceleration","text":""},{"location":"performance/#gpu-configuration","title":"GPU Configuration","text":"<pre><code># Enable GPU\nnetintel-ocr config set performance.gpu.enabled true\n\n# Select GPU device\nnetintel-ocr config set performance.gpu.device 0\n\n# Configure GPU memory\nnetintel-ocr config set performance.gpu.memory_fraction 0.8\n\n# Multi-GPU setup\nnetintel-ocr config set performance.gpu.devices \"0,1\"\nnetintel-ocr config set performance.gpu.strategy \"data_parallel\"\n</code></pre>"},{"location":"performance/#gpu-optimization","title":"GPU Optimization","text":"<pre><code># Check GPU utilization\nnetintel-ocr system gpu status\n\n# Optimize GPU batch size\nnetintel-ocr system gpu optimize --auto\n\n# Monitor GPU performance\nnetintel-ocr system gpu monitor --interval 1\n</code></pre>"},{"location":"performance/#cuda-settings","title":"CUDA Settings","text":"<pre><code># Set CUDA environment\nexport CUDA_VISIBLE_DEVICES=0,1\nexport CUDA_LAUNCH_BLOCKING=0\nexport CUDA_CACHE_PATH=/tmp/cuda_cache\n\n# Configure CUDA in NetIntel\nnetintel-ocr config set performance.cuda.enabled true\nnetintel-ocr config set performance.cuda.allow_growth true\nnetintel-ocr config set performance.cuda.per_process_memory 4096\n</code></pre>"},{"location":"performance/#caching-strategies","title":"Caching Strategies","text":""},{"location":"performance/#cache-configuration","title":"Cache Configuration","text":"<pre><code># Enable caching\nnetintel-ocr config set cache.enabled true\nnetintel-ocr config set cache.dir ~/.cache/netintel-ocr\nnetintel-ocr config set cache.size 10GB\n\n# Configure cache layers\nnetintel-ocr config set cache.layers.memory.enabled true\nnetintel-ocr config set cache.layers.memory.size 1GB\nnetintel-ocr config set cache.layers.disk.enabled true\nnetintel-ocr config set cache.layers.disk.size 10GB\n</code></pre>"},{"location":"performance/#cache-types","title":"Cache Types","text":"<pre><code># Model cache\nnetintel-ocr config set cache.models.enabled true\nnetintel-ocr config set cache.models.ttl 86400\n\n# Results cache\nnetintel-ocr config set cache.results.enabled true\nnetintel-ocr config set cache.results.ttl 3600\n\n# Embedding cache\nnetintel-ocr config set cache.embeddings.enabled true\nnetintel-ocr config set cache.embeddings.ttl 604800\n</code></pre>"},{"location":"performance/#cache-management","title":"Cache Management","text":"<pre><code># View cache statistics\nnetintel-ocr cache stats\n\n# Clear specific cache\nnetintel-ocr cache clear --type models\nnetintel-ocr cache clear --type results\n\n# Warm up cache\nnetintel-ocr cache warmup --models \"qwen2.5vl:7b,minicpm-v:latest\"\n\n# Export/import cache\nnetintel-ocr cache export --output cache-backup.tar.gz\nnetintel-ocr cache import --input cache-backup.tar.gz\n</code></pre>"},{"location":"performance/#memory-management","title":"Memory Management","text":""},{"location":"performance/#memory-configuration","title":"Memory Configuration","text":"<pre><code># Set memory limits\nnetintel-ocr config set performance.memory.max_usage 8GB\nnetintel-ocr config set performance.memory.per_worker 2GB\n\n# Enable memory optimization\nnetintel-ocr config set performance.memory.optimize true\nnetintel-ocr config set performance.memory.gc_threshold 0.8\n\n# Configure swap\nnetintel-ocr config set performance.memory.swap.enabled true\nnetintel-ocr config set performance.memory.swap.path /tmp/netintel-swap\nnetintel-ocr config set performance.memory.swap.size 16GB\n</code></pre>"},{"location":"performance/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Monitor memory usage\nnetintel-ocr system memory monitor\n\n# Find memory leaks\nnetintel-ocr system memory leaks --duration 300\n\n# Optimize memory allocation\nnetintel-ocr system memory optimize\n</code></pre>"},{"location":"performance/#database-optimization","title":"Database Optimization","text":""},{"location":"performance/#vector-store-optimization","title":"Vector Store Optimization","text":"<pre><code># Optimize Milvus\nnetintel-ocr db optimize --type milvus\n\n# Configure index\nnetintel-ocr config set db.milvus.index_type IVF_SQ8\nnetintel-ocr config set db.milvus.nlist 1024\nnetintel-ocr config set db.milvus.nprobe 16\n\n# Build optimized index\nnetintel-ocr db rebuild-index --optimize\n</code></pre>"},{"location":"performance/#query-optimization","title":"Query Optimization","text":"<pre><code># Analyze query performance\nnetintel-ocr db analyze-queries\n\n# Optimize slow queries\nnetintel-ocr db optimize-queries --threshold 1000ms\n\n# Configure query cache\nnetintel-ocr config set db.query_cache.enabled true\nnetintel-ocr config set db.query_cache.size 100MB\n</code></pre>"},{"location":"performance/#network-optimization","title":"Network Optimization","text":""},{"location":"performance/#api-performance","title":"API Performance","text":"<pre><code># Configure connection pooling\nnetintel-ocr config set server.api.connection_pool.size 100\nnetintel-ocr config set server.api.connection_pool.timeout 30\n\n# Enable compression\nnetintel-ocr config set server.api.compression.enabled true\nnetintel-ocr config set server.api.compression.level 6\n\n# Configure keep-alive\nnetintel-ocr config set server.api.keep_alive.enabled true\nnetintel-ocr config set server.api.keep_alive.timeout 120\n</code></pre>"},{"location":"performance/#request-optimization","title":"Request Optimization","text":"<pre><code># Enable request batching\nnetintel-ocr config set server.api.batching.enabled true\nnetintel-ocr config set server.api.batching.max_size 10\nnetintel-ocr config set server.api.batching.timeout 100ms\n\n# Configure rate limiting\nnetintel-ocr config set server.api.rate_limit.enabled true\nnetintel-ocr config set server.api.rate_limit.requests_per_second 100\n</code></pre>"},{"location":"performance/#performance-profiles","title":"Performance Profiles","text":""},{"location":"performance/#create-performance-profiles","title":"Create Performance Profiles","text":"<pre><code># High throughput profile\nnetintel-ocr config profile create high-throughput\nnetintel-ocr config set processing.max_parallel 16 --profile high-throughput\nnetintel-ocr config set models.default minicpm-v:latest --profile high-throughput\nnetintel-ocr config set cache.aggressive true --profile high-throughput\n\n# Low latency profile\nnetintel-ocr config profile create low-latency\nnetintel-ocr config set processing.max_parallel 4 --profile low-latency\nnetintel-ocr config set models.preload all --profile low-latency\nnetintel-ocr config set cache.layers.memory.size 4GB --profile low-latency\n\n# Resource constrained profile\nnetintel-ocr config profile create resource-constrained\nnetintel-ocr config set processing.max_parallel 2 --profile resource-constrained\nnetintel-ocr config set performance.memory.max_usage 2GB --profile resource-constrained\nnetintel-ocr config set models.default bakllava:latest --profile resource-constrained\n</code></pre>"},{"location":"performance/#apply-performance-profile","title":"Apply Performance Profile","text":"<pre><code># Switch to performance profile\nnetintel-ocr config profile use high-throughput\n\n# Apply temporarily\nnetintel-ocr --profile low-latency process file document.pdf\n\n# Compare profiles\nnetintel-ocr config profile compare default high-throughput\n</code></pre>"},{"location":"performance/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"performance/#real-time-monitoring","title":"Real-time Monitoring","text":"<pre><code># Monitor performance metrics\nnetintel-ocr monitor performance --real-time\n\n# Watch specific metrics\nnetintel-ocr monitor performance \\\n  --metrics \"throughput,latency,cpu,memory\" \\\n  --interval 1\n\n# Export performance data\nnetintel-ocr monitor performance --export perf-data.csv\n</code></pre>"},{"location":"performance/#performance-alerts","title":"Performance Alerts","text":"<pre><code># Set performance thresholds\nnetintel-ocr monitor alerts add \\\n  --name slow-processing \\\n  --metric processing_time \\\n  --threshold 60s \\\n  --severity warning\n\nnetintel-ocr monitor alerts add \\\n  --name high-memory \\\n  --metric memory_usage \\\n  --threshold 90% \\\n  --severity critical\n</code></pre>"},{"location":"performance/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"performance/#document-type-optimization","title":"Document Type Optimization","text":"<pre><code># Text-heavy documents\nnetintel-ocr process file text-doc.pdf \\\n  --model Nanonets-OCR-s:latest \\\n  --text-only \\\n  --parallel 8\n\n# Diagram-heavy documents\nnetintel-ocr process file network-doc.pdf \\\n  --model qwen2.5vl:7b \\\n  --network-only \\\n  --parallel 4\n\n# Mixed documents\nnetintel-ocr process file mixed-doc.pdf \\\n  --model qwen2.5vl:7b \\\n  --adaptive-processing\n</code></pre>"},{"location":"performance/#batch-processing-optimization_1","title":"Batch Processing Optimization","text":"<pre><code># Sort by size for optimal batching\nls -S *.pdf | xargs netintel-ocr process batch\n\n# Process similar documents together\nnetintel-ocr process batch \\\n  --group-by similarity \\\n  --batch-size 20\n\n# Adaptive batch sizing\nnetintel-ocr process batch \\\n  --adaptive-batch \\\n  --min-batch 5 \\\n  --max-batch 50\n</code></pre>"},{"location":"performance/#troubleshooting-performance","title":"Troubleshooting Performance","text":""},{"location":"performance/#identify-bottlenecks","title":"Identify Bottlenecks","text":"<pre><code># Run performance diagnostic\nnetintel-ocr system diagnose --performance\n\n# Profile specific operation\nnetintel-ocr system profile \\\n  --operation \"process file test.pdf\" \\\n  --detailed\n\n# Analyze bottlenecks\nnetintel-ocr system analyze-bottlenecks\n</code></pre>"},{"location":"performance/#common-performance-issues","title":"Common Performance Issues","text":""},{"location":"performance/#slow-processing","title":"Slow Processing","text":"<pre><code># Check model performance\nnetintel-ocr model benchmark --current\n\n# Optimize settings\nnetintel-ocr system optimize --auto\n\n# Use faster model\nnetintel-ocr config set models.default minicpm-v:latest\n</code></pre>"},{"location":"performance/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Reduce parallel workers\nnetintel-ocr config set processing.max_parallel 2\n\n# Clear caches\nnetintel-ocr cache clear --all\n\n# Enable memory limits\nnetintel-ocr config set performance.memory.max_usage 4GB\n</code></pre>"},{"location":"performance/#gpu-underutilization","title":"GPU Underutilization","text":"<pre><code># Check GPU status\nnvidia-smi\nnetintel-ocr system gpu status\n\n# Increase batch size\nnetintel-ocr config set processing.gpu_batch_size 8\n\n# Enable GPU optimization\nnetintel-ocr system gpu optimize\n</code></pre>"},{"location":"performance/#best-practices","title":"Best Practices","text":""},{"location":"performance/#1-profile-before-optimizing","title":"1. Profile Before Optimizing","text":"<pre><code># Always benchmark first\nnetintel-ocr system benchmark --baseline\n\n# Make changes\nnetintel-ocr config set ...\n\n# Compare results\nnetintel-ocr system benchmark --compare baseline\n</code></pre>"},{"location":"performance/#2-start-with-quick-wins","title":"2. Start with Quick Wins","text":"<ul> <li>Enable caching</li> <li>Preload models</li> <li>Use appropriate parallelization</li> <li>Choose right model for task</li> </ul>"},{"location":"performance/#3-monitor-continuously","title":"3. Monitor Continuously","text":"<pre><code># Set up monitoring\nnetintel-ocr monitor performance --daemon\n\n# Review daily reports\nnetintel-ocr monitor report --daily\n</code></pre>"},{"location":"performance/#4-optimize-for-your-workload","title":"4. Optimize for Your Workload","text":"<pre><code># Analyze workload patterns\nnetintel-ocr system analyze-workload --duration 7d\n\n# Get optimization recommendations\nnetintel-ocr system recommend --based-on-workload\n</code></pre>"},{"location":"performance/#next-steps","title":"Next Steps","text":"<ul> <li>Monitoring Guide - Performance monitoring</li> <li>Configuration Guide - Performance configuration</li> <li>Deployment Guide - Production optimization</li> <li>Troubleshooting Guide - Performance issues</li> </ul>"},{"location":"quickstart-kg/","title":"Knowledge Graph Quick Start","text":"<p>Get started with NetIntel-OCR's Knowledge Graph capabilities in 5 minutes.</p>"},{"location":"quickstart-kg/#prerequisites","title":"Prerequisites","text":"<pre><code># Install NetIntel-OCR (KG included by default in v0.1.17+)\npip install netintel-ocr\n\n# Configure external Ollama server\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\n\n# Verify Ollama has required models\ncurl $OLLAMA_HOST/api/tags | jq '.models[].name'\n\n# IMPORTANT: Different models serve different purposes\n# ================================================\n# INGESTION MODELS (for processing PDFs):\n# - qwen2.5vl:7b (for network/diagram analysis during ingestion)\n# - Nanonets-OCR-s:latest (for OCR during ingestion)\n#\n# MINIRAG MODELS (for Q&amp;A after ingestion):\n# - gemma3:4b-it-qat (for LLM inference/generation)\n# - qwen3-embedding:8b (for semantic search embeddings)\n\n# Pull INGESTION models (for PDF processing)\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen2.5vl:7b\"}'\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"Nanonets-OCR-s:latest\"}'\n\n# Pull MINIRAG models (for Q&amp;A)\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"gemma3:4b-it-qat\"}'\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen3-embedding:8b\"}'\n\n# Start required graph/vector services with Docker\ndocker run -d --name falkordb -p 6379:6379 falkordb/falkordb\ndocker run -d --name milvus -p 19530:19530 milvusdb/milvus:latest\n\n# Verify everything is ready\nnetintel-ocr kg check-requirements\n# \u2705 Ollama: Connected (http://your-ollama-server:11434)\n# \u2705 FalkorDB: Connected (localhost:6379)\n# \u2705 Milvus: Connected (localhost:19530)\n</code></pre>"},{"location":"quickstart-kg/#basic-workflow","title":"Basic Workflow","text":""},{"location":"quickstart-kg/#1-process-your-first-document","title":"1. Process Your First Document","text":"<pre><code># Process a PDF with Knowledge Graph extraction (enabled by default)\nnetintel-ocr process file document.pdf\n\n# The output folder will contain:\n# - Extracted text and diagrams\n# - kg_entities.json - Extracted entities\n# - kg_relations.cypher - Graph relationships\n</code></pre>"},{"location":"quickstart-kg/#2-view-what-was-extracted","title":"2. View What Was Extracted","text":"<pre><code># See graph statistics\nnetintel-ocr kg stats\n\n# Output:\n# Entities: 47\n# Relationships: 156\n# Types: Router(5), Switch(12), Firewall(3), Server(15)...\n</code></pre>"},{"location":"quickstart-kg/#3-query-your-knowledge-graph","title":"3. Query Your Knowledge Graph","text":"<pre><code># Find dependencies\nnetintel-ocr kg query \\\n  --type dependencies \\\n  --entity \"Database-Server\"\n\n# Find paths between components\nnetintel-ocr kg query \\\n  --type path \\\n  --from \"Internet\" \\\n  --to \"Database\"\n\n# Search by properties\nnetintel-ocr kg search \\\n  --property \"type=firewall\"\n</code></pre>"},{"location":"quickstart-kg/#essential-commands","title":"Essential Commands","text":""},{"location":"quickstart-kg/#processing-documents","title":"Processing Documents","text":"<pre><code># Process with specific KG model (default: RotatE)\nnetintel-ocr process file document.pdf --kg-model RotatE\n\n# Process multiple documents into one KG\nnetintel-ocr process batch --collection my_network *.pdf\n\n# Disable KG if not needed (faster processing)\nnetintel-ocr process file document.pdf --no-kg\n</code></pre>"},{"location":"quickstart-kg/#querying","title":"Querying","text":"<pre><code># Basic entity query\nnetintel-ocr kg query --entity \"Router-Core-01\"\n\n# Find all connections\nnetintel-ocr kg query --type connections --entity \"Switch-01\"\n\n# Complex graph query with Cypher\nnetintel-ocr kg query \\\n  --cypher \"MATCH (n:Firewall)-[r]-(m) RETURN n,r,m\"\n</code></pre>"},{"location":"quickstart-kg/#analysis","title":"Analysis","text":"<pre><code># Find single points of failure\nnetintel-ocr kg analyze --type spof\n\n# Check compliance\nnetintel-ocr kg compliance --framework PCI-DSS\n\n# Find similar configurations\nnetintel-ocr kg find-similar --entity \"FW-01\" --threshold 0.85\n</code></pre>"},{"location":"quickstart-kg/#using-minirag-qa-system","title":"Using MiniRAG (Q&amp;A System)","text":"<pre><code># Ask questions about your documents\nnetintel-ocr rag query \\\n  --question \"What are the database dependencies?\" \\\n  --collection my_network\n\n# Get compliance answers\nnetintel-ocr rag query \\\n  --question \"Does our network meet PCI requirements?\" \\\n  --compliance-framework PCI-DSS\n</code></pre>"},{"location":"quickstart-kg/#export-your-graph","title":"Export Your Graph","text":"<pre><code># Export for visualization\nnetintel-ocr kg export --format json --output graph.json\n\n# Export for Neo4j\nnetintel-ocr kg export --format cypher --output graph.cypher\n\n# Generate visualization\nnetintel-ocr kg visualize --output network.html\n</code></pre>"},{"location":"quickstart-kg/#common-use-cases","title":"Common Use Cases","text":""},{"location":"quickstart-kg/#network-documentation-analysis","title":"Network Documentation Analysis","text":"<pre><code># Process network architecture PDFs\nnetintel-ocr process file network-architecture.pdf\nnetintel-ocr kg stats  # See what was extracted\nnetintel-ocr kg query --type dependencies --entity \"Core-Router\"\n</code></pre>"},{"location":"quickstart-kg/#security-compliance-check","title":"Security Compliance Check","text":"<pre><code># Process security policies\nnetintel-ocr process file security-policies.pdf\nnetintel-ocr kg compliance --framework PCI-DSS\nnetintel-ocr kg analyze --type access-paths\n</code></pre>"},{"location":"quickstart-kg/#incident-response","title":"Incident Response","text":"<pre><code># Find impact of component failure\nnetintel-ocr kg impact --entity \"Database-01\" --failure-type complete\nnetintel-ocr rag query --question \"What's the recovery procedure?\"\n</code></pre>"},{"location":"quickstart-kg/#configuration-options","title":"Configuration Options","text":"Option Description Default <code>--kg-model</code> TransE, RotatE, ComplEx, etc. RotatE <code>--kg-epochs</code> Training iterations 100 <code>--collection</code> KG collection name default <code>--no-kg</code> Disable KG extraction False"},{"location":"quickstart-kg/#available-kg-models","title":"Available KG Models","text":"<ul> <li>RotatE (default) - Best for complex relationships</li> <li>TransE - Fast, good for hierarchical data</li> <li>ComplEx - Good for bidirectional relationships</li> </ul>"},{"location":"quickstart-kg/#troubleshooting","title":"Troubleshooting","text":"<pre><code># If KG extraction is slow\nnetintel-ocr kg config model TransE --kg-epochs 50 document.pdf\n\n# If out of memory\nnetintel-ocr kg config batch-size 128 document.pdf\n\n# Debug mode\nnetintel-ocr --debug --kg-verbose document.pdf\n</code></pre>"},{"location":"quickstart-kg/#next-steps","title":"Next Steps","text":"<ul> <li>MiniRAG Guide - Advanced Q&amp;A capabilities</li> <li>Knowledge Graph Guide - Full features</li> <li>Use Cases - Real-world examples</li> </ul> <p>Quick Reference Card</p> <pre><code># Process\nnetintel-ocr process file document.pdf\n\n# Query\nnetintel-ocr kg query --entity \"System-Name\"\n\n# Analyze\nnetintel-ocr kg analyze --type spof\n\n# Ask Questions\nnetintel-ocr rag query --question \"Your question here\"\n\n# Export\nnetintel-ocr kg export --format json --output graph.json\n</code></pre>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>New in v0.1.18.1: Complete Feature Parity &amp; Test Framework</p> <p>NetIntel-OCR v0.1.18.1 achieves 100% feature parity between CLI and API v2, includes a comprehensive test framework, and defaults to Milvus for vector operations!</p> <p>All 30+ CLI options are now available through the API, with complete multi-model support for text, network, and flow diagram processing.</p> <p>What's New \u2192 | API Feature Parity \u2192 | Testing Guide \u2192</p>"},{"location":"quickstart/#installation","title":"Installation","text":""},{"location":"quickstart/#system-requirements","title":"System Requirements","text":"<p>Operating System Support</p> <p>Linux Only - NetIntel-OCR is currently tested and supported only on Linux distributions.</p> <p>Windows and macOS support is planned for future releases but not currently available.</p> <p>Python Version</p> <p>Python 3.11 or 3.12 Required - NetIntel-OCR is tested and supported only on Python 3.11 and 3.12.</p> <p>Other Python versions may work but are not officially supported.</p>"},{"location":"quickstart/#verified-configurations","title":"Verified Configurations","text":"<ul> <li>OS: Ubuntu 20.04/22.04, RHEL 8/9, Debian 11/12</li> <li>Python: 3.11.x or 3.12.x</li> <li>RAM: 8GB minimum (16GB recommended)</li> <li>Storage: 10GB for models + processing space</li> <li>Ollama: Version 0.1.0 or higher</li> </ul>"},{"location":"quickstart/#python-setup","title":"Python Setup","text":"<pre><code># Check Python version (must be 3.11 or 3.12)\npython3 --version\n\n# Install Python 3.11 on Ubuntu/Debian\nsudo apt update\nsudo apt install python3.11 python3.11-venv python3.11-dev\n\n# Or install Python 3.12\nsudo apt install python3.12 python3.12-venv python3.12-dev\n\n# Create virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Or with Python 3.12\npython3.12 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"quickstart/#install-netintel-ocr","title":"Install NetIntel-OCR","text":""},{"location":"quickstart/#choose-your-installation","title":"Choose Your Installation","text":"<pre><code># Option 1: Base installation (500MB) - Core OCR only\npip install netintel-ocr\n\n# Option 2: With Knowledge Graph (+1.5GB) - Recommended\npip install \"netintel-ocr[kg]\"\n\n# Option 3: Production setup (+2GB) - KG + Vector + API\npip install \"netintel-ocr[production]\"\n\n# Option 4: Everything (+2.5GB) - All features\npip install \"netintel-ocr[all]\"\n</code></pre>"},{"location":"quickstart/#verify-installation","title":"Verify Installation","text":"<pre><code># Check version and installed modules\nnetintel-ocr --version\n\n# Example output showing what's installed:\n# NetIntel-OCR v0.1.18.1\n# \u251c\u2500\u2500 Core Components:\n# \u2502   \u251c\u2500\u2500 C++ Core: \u2713 v1.0.1\n# \u2502   \u251c\u2500\u2500 AVX2: \u2713\n# \u2502   \u2514\u2500\u2500 Platform: Linux x86_64\n# \u251c\u2500\u2500 Installed Modules:\n# \u2502   \u251c\u2500\u2500 [base] Core OCR: \u2713 (always installed)\n# \u2502   \u251c\u2500\u2500 [kg] Knowledge Graph: \u2713 (pykeen 1.10.1)\n# \u2502   \u2514\u2500\u2500 [vector] Vector Store: \u2717 (not installed)\n# \u251c\u2500\u2500 Available for Install:\n# \u2502   \u2514\u2500\u2500 [vector] Vector Store: pip install netintel-ocr[vector]\n# \u2514\u2500\u2500 Active Features:\n#     \u251c\u2500\u2500 FalkorDB: \u2713 (connected to localhost:6379)\n#     \u2514\u2500\u2500 Ollama: \u2713 (connected to localhost:11434)\n\n# Get detailed JSON output\nnetintel-ocr --version --json\n</code></pre> <p>Package Information</p> <p>NetIntel-OCR v0.1.17.1 is available on PyPI with modular installation options.</p> <p>See Installation Guide for all options.</p>"},{"location":"quickstart/#configure-external-ollama-server","title":"Configure External Ollama Server","text":"<p>NetIntel-OCR requires an external Ollama server with different models for different purposes:</p> <pre><code># Configure external Ollama server\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\n\n# Verify Ollama has required models\ncurl $OLLAMA_HOST/api/tags | jq '.models[].name'\n\n# IMPORTANT: Models serve different purposes\n# ==========================================\n# INGESTION MODELS (for processing PDFs):\n# - qwen2.5vl:7b (network diagram analysis)\n# - Nanonets-OCR-s:latest (OCR text extraction)\n#\n# MINIRAG MODELS (for Q&amp;A after ingestion):\n# - gemma3:4b-it-qat (answer generation)\n# - qwen3-embedding:8b (semantic search)\n\n# Pull INGESTION models (for PDF processing)\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen2.5vl:7b\"}'\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"Nanonets-OCR-s:latest\"}'\n\n# Pull MINIRAG models (for Q&amp;A after ingestion)\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"gemma3:4b-it-qat\"}'\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen3-embedding:8b\"}'\n\n# Optional: Pull alternative models\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"llava:13b\"}'        # Alternative vision model\ncurl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"minicpm-v:latest\"}'  # Lightweight option\n</code></pre>"},{"location":"quickstart/#quick-configuration","title":"Quick Configuration","text":""},{"location":"quickstart/#using-configuration-templates-new-in-v0117","title":"Using Configuration Templates (NEW in v0.1.17)","text":"<p>NetIntel-OCR v0.1.17 provides pre-configured templates for different scenarios:</p> <pre><code># List available templates\nnetintel-ocr config template list\n# Available templates:\n# - minimal: Single-user local setup\n# - development: Development environment\n# - staging: Staging server configuration\n# - production: Production deployment\n# - enterprise: Full enterprise features\n# - cloud: Cloud-native deployment\n\n# Quick start with minimal template\nnetintel-ocr config template apply minimal --output config.json\nnetintel-ocr config use config.json\n\n# Or use development template for more features\nnetintel-ocr config template apply development --output dev.json\nnetintel-ocr --config dev.json process pdf document.pdf\n</code></pre>"},{"location":"quickstart/#model-selection","title":"Model Selection","text":"<p>Ingestion Models vs MiniRAG Models</p> <p>The models below are INGESTION MODELS used during PDF processing. They are completely separate from MiniRAG MODELS (gemma3:4b-it-qat, qwen3-embedding:8b) which are used for Q&amp;A after ingestion.</p> Parameter Purpose Recommended Model Model Type <code>--model</code> OCR and text extraction Nanonets-OCR-s:latest Ingestion <code>--network-model</code> Network diagram analysis qwen2.5vl:7b Ingestion <code>--flow-model</code> Flow chart processing qwen2.5vl:7b Ingestion"},{"location":"quickstart/#whats-new-in-v01181","title":"What's New in v0.1.18.1","text":""},{"location":"quickstart/#complete-multi-model-support","title":"Complete Multi-Model Support","text":"<pre><code># Use different models for different content types\nnetintel-ocr process file document.pdf \\\n    --model nanonets-ocr-s \\        # For text extraction\n    --network-model qwen2.5vl \\      # For network diagrams\n    --flow-model custom-flow         # For flow diagrams\n</code></pre>"},{"location":"quickstart/#api-v2-with-full-feature-parity","title":"API v2 with Full Feature Parity","text":"<pre><code># All CLI options now available in API\nfrom netintel_ocr import APIClient\n\nclient = APIClient()\nresult = client.process_document(\n    \"document.pdf\",\n    model=\"nanonets-ocr-s\",\n    network_model=\"qwen2.5vl\",\n    confidence=0.8,\n    fast_extraction=True,\n    with_kg=True,\n    vector_format=\"milvus\"  # Milvus is now default\n)\n</code></pre>"},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"quickstart/#process-a-pdf-document","title":"Process a PDF Document","text":"<p>Enhanced in v0.1.18.1</p> <p>All processing now defaults to Milvus for vector storage and supports complete multi-model configuration.</p> <pre><code># Process entire document with default settings\nnetintel-ocr process file document.pdf\n\n# Multi-model processing (NEW in v0.1.18.1!)\nnetintel-ocr process file document.pdf \\\n    --model nanonets-ocr-s \\\n    --network-model qwen2.5vl\n\n# Process specific pages\nnetintel-ocr process file document.pdf --pages 5-10\n\n# Extract only text\nnetintel-ocr process file document.pdf --text-only\n\n# Extract only network diagrams\nnetintel-ocr process file document.pdf --network-only\n\n# Extract tables\nnetintel-ocr process pdf document.pdf --extract-tables\n\n# Enable debug output\nnetintel-ocr --debug process pdf document.pdf\n</code></pre>"},{"location":"quickstart/#example-network-architecture-document","title":"Example: Network Architecture Document","text":"<pre><code># Using new v0.1.17 CLI structure\nnetintel-ocr process pdf cisco-sdwan-design-guide.pdf \\\n  --model Nanonets-OCR-s:latest \\\n  --network-model qwen2.5vl:7b \\\n  --start 5 --end 10 \\\n  --output results.json \\\n  --debug\n</code></pre> <p>Output structure: <pre><code>output/\n\u251c\u2500\u2500 cisco-sdwan-design-guide/\n\u2502   \u251c\u2500\u2500 page_005.md          # Extracted text\n\u2502   \u251c\u2500\u2500 page_006_network.md  # Network diagram with Mermaid\n\u2502   \u251c\u2500\u2500 page_007.md          # Regular page\n\u2502   \u251c\u2500\u2500 summary.json         # Processing summary\n\u2502   \u251c\u2500\u2500 kg_entities.json     # Extracted entities (v0.1.17)\n\u2502   \u251c\u2500\u2500 kg_relations.cypher  # Graph relationships (v0.1.17)\n\u2502   \u2514\u2500\u2500 kg_embeddings.npy    # Learned embeddings (v0.1.17)\n</code></pre></p>"},{"location":"quickstart/#batch-processing","title":"Batch Processing","text":"<p>Process multiple PDFs efficiently:</p> <pre><code># Process entire directory\nnetintel-ocr process batch /path/to/pdfs/ --output-dir results/\n\n# Process with parallel workers\nnetintel-ocr process batch /path/to/pdfs/ --parallel 4\n\n# Process from file list\necho \"doc1.pdf\\ndoc2.pdf\\ndoc3.pdf\" &gt; file_list.txt\nnetintel-ocr process batch file_list.txt\n\n# Watch directory for new PDFs\nnetintel-ocr process watch /input/folder --pattern \"*.pdf\"\n</code></pre>"},{"location":"quickstart/#query-processed-data","title":"Query Processed Data","text":""},{"location":"quickstart/#database-queries","title":"Database Queries","text":"<pre><code># Search for specific content\nnetintel-ocr db query \"firewall configuration\"\n\n# Query with filters\nnetintel-ocr db query \"router\" --limit 10 --threshold 0.8\n\n# Export results\nnetintel-ocr db query \"network topology\" --format json &gt; results.json\n</code></pre>"},{"location":"quickstart/#knowledge-graph-queries-new","title":"Knowledge Graph Queries (NEW)","text":"<pre><code># Query knowledge graph\nnetintel-ocr kg query \"show all routers\"\n\n# RAG-enhanced query\nnetintel-ocr kg rag-query \"What are the security vulnerabilities?\"\n\n# Visualize graph\nnetintel-ocr kg visualize --output network-graph.html\n</code></pre>"},{"location":"quickstart/#start-server-services","title":"Start Server Services","text":""},{"location":"quickstart/#quick-development-server","title":"Quick Development Server","text":"<pre><code># Start development server with hot reload\nnetintel-ocr server dev --reload\n\n# Access at:\n# - API: http://localhost:8000\n# - MCP: http://localhost:8001\n</code></pre>"},{"location":"quickstart/#production-deployment","title":"Production Deployment","text":"<pre><code># Start all services\nnetintel-ocr server all --api-port 8000 --mcp-port 8001\n\n# Or start individually\nnetintel-ocr server api --port 8000 --workers 8 &amp;\nnetintel-ocr server mcp --port 8001 --auth &amp;\nnetintel-ocr server worker --count 4 --queue redis &amp;\n\n# Check health\nnetintel-ocr server health\n</code></pre>"},{"location":"quickstart/#output-formats","title":"Output Formats","text":""},{"location":"quickstart/#markdown-files","title":"Markdown Files","text":"<p>Each page generates a markdown file containing: - Extracted text content - Mermaid diagrams for network/flow charts - Context analysis and interpretations - Component and connection listings</p>"},{"location":"quickstart/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<p>Network diagrams are converted to Mermaid syntax:</p> <pre><code>graph TB\n    Router[\"Core Router\"]\n    Switch1[\"Access Switch 1\"]\n    Switch2[\"Access Switch 2\"]\n\n    Router --&gt; Switch1\n    Router --&gt; Switch2</code></pre>"},{"location":"quickstart/#knowledge-graph-v0117","title":"Knowledge Graph (v0.1.17)","text":"<p>Entities and relationships are automatically extracted: - Entities: Routers, Switches, Firewalls, Servers, etc. - Relationships: Connected_To, Routes_Through, Protects, etc. - Properties: IP addresses, VLANs, protocols, ports</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ol> <li>Explore Commands: Run <code>netintel-ocr --help</code> to see all command groups</li> <li>Configure Templates: Try different configuration templates for your use case</li> <li>Process Documents: Start with a sample network document</li> <li>Query Results: Use database and knowledge graph queries</li> <li>Visualize: Generate network visualizations from extracted data</li> <li>Deploy: Set up production services when ready</li> </ol>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<pre><code># View general help\nnetintel-ocr --help\n\n# View help for command groups\nnetintel-ocr process --help\nnetintel-ocr server --help\nnetintel-ocr kg --help\n\n# View help for specific commands\nnetintel-ocr process pdf --help\nnetintel-ocr kg query --help\n\n# Check system status\nnetintel-ocr system check\nnetintel-ocr system diagnose\n</code></pre>"},{"location":"quickstart/#common-issues","title":"Common Issues","text":""},{"location":"quickstart/#command-not-found","title":"Command Not Found","text":"<p>If you see \"command not found\", update to the new v0.1.17 syntax: - Old: <code>netintel-ocr file.pdf</code> - New: <code>netintel-ocr process pdf file.pdf</code></p>"},{"location":"quickstart/#ollama-connection","title":"Ollama Connection","text":"<p>Ensure OLLAMA_HOST is set: <pre><code>export OLLAMA_HOST=\"http://your-server:11434\"\nnetintel-ocr system check\n</code></pre></p>"},{"location":"quickstart/#missing-models","title":"Missing Models","text":"<p>Pull required models: <pre><code>curl -X POST $OLLAMA_HOST/api/pull -d '{\"name\":\"qwen2.5vl:7b\"}'\n</code></pre></p> <p>For more help, see the Troubleshooting Guide or CLI Reference.</p>"},{"location":"testing-guide/","title":"Testing Guide for NetIntel-OCR v0.1.18.1","text":""},{"location":"testing-guide/#overview","title":"Overview","text":"<p>NetIntel-OCR v0.1.18.1 introduces a comprehensive testing framework designed to ensure reliability, performance, and quality across all components. This guide covers testing strategies, running tests, and interpreting results.</p> <p>New in v0.1.18.1</p> <p>Complete test framework with Docker Compose environment, quality metrics, and CI/CD integration!</p>"},{"location":"testing-guide/#test-framework-architecture","title":"Test Framework Architecture","text":""},{"location":"testing-guide/#test-categories","title":"Test Categories","text":"Category Purpose Coverage Goal Typical Duration Unit Tests Individual functions/methods 85%+ &lt; 5 minutes Integration Tests Component interactions 70%+ 10-15 minutes System Tests End-to-end workflows 60%+ 15-20 minutes Performance Tests Speed and resource usage Critical paths 10-15 minutes Regression Tests Previous bug fixes All fixed issues 5-10 minutes"},{"location":"testing-guide/#quality-metrics","title":"Quality Metrics","text":"<pre><code>Target Metrics:\n  Line Coverage: \u2265 85%\n  Branch Coverage: \u2265 70%\n  Cyclomatic Complexity: \u2264 10\n  Maintainability Index: \u2265 20\n  Security Score: \u2265 85/100\n  Performance:\n    PDF Processing: &lt; 30s median\n    API Latency: &lt; 100ms p95\n    KG Queries: &lt; 500ms median\n    Vector Search: &lt; 200ms median\n</code></pre>"},{"location":"testing-guide/#quick-start","title":"Quick Start","text":""},{"location":"testing-guide/#running-all-tests","title":"Running All Tests","text":"<pre><code># Run complete test suite\n./run-tests.sh\n\n# Run with coverage report\n./run-tests.sh --coverage\n\n# Run specific category\n./run-tests.sh --category unit\n./run-tests.sh --category integration\n./run-tests.sh --category performance\n\n# Run in Docker environment\ndocker-compose -f tests/docker-compose.test.yml up --abort-on-container-exit\n</code></pre>"},{"location":"testing-guide/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Unit tests only\npytest tests/unit/ -v\n\n# Integration tests with real PDFs\npytest tests/integration/ -v --pdf-fixtures\n\n# Performance benchmarks\npytest tests/performance/ -v --benchmark-only\n\n# API v2 tests\npytest tests/api/v2/ -v\n\n# Multi-model tests (NEW in v0.1.18.1)\npytest tests/integration/test_multimodel.py -v\n</code></pre>"},{"location":"testing-guide/#testing-multi-model-features","title":"Testing Multi-Model Features","text":""},{"location":"testing-guide/#test-multi-model-processing","title":"Test Multi-Model Processing","text":"<pre><code># tests/integration/test_multimodel.py\nimport pytest\nfrom netintel_ocr.hybrid_processor import process_pdf_hybrid\n\ndef test_multimodel_processing():\n    \"\"\"Test multi-model configuration\"\"\"\n    result = process_pdf_hybrid(\n        pdf_path=\"tests/fixtures/cisco-sdwan.pdf\",\n        output_dir=\"/tmp/test\",\n        model=\"nanonets-ocr-s\",\n        network_model=\"qwen2.5vl\",\n        flow_model=\"custom-flow\",\n        pages=\"1-5\"\n    )\n\n    assert result.text_extracted\n    assert result.diagrams_found\n    assert result.tables_extracted\n</code></pre>"},{"location":"testing-guide/#test-api-v2-feature-parity","title":"Test API v2 Feature Parity","text":"<pre><code># tests/api/v2/test_feature_parity.py\nimport pytest\nfrom netintel_ocr.api.client import APIClient\n\ndef test_api_feature_parity():\n    \"\"\"Verify all CLI options work in API\"\"\"\n    client = APIClient(base_url=\"http://localhost:8000\")\n\n    # Test all 30+ options\n    result = client.process_document(\n        file_path=\"test.pdf\",\n        model=\"nanonets-ocr-s\",\n        network_model=\"qwen2.5vl\",\n        confidence=0.8,\n        fast_extraction=True,\n        table_method=\"hybrid\",\n        vector_format=\"milvus\",  # Default\n        chunk_strategy=\"semantic\",\n        with_kg=True\n    )\n\n    assert result['status'] == 'completed'\n    assert 'embeddings_count' in result\n</code></pre>"},{"location":"testing-guide/#docker-compose-test-environment","title":"Docker Compose Test Environment","text":""},{"location":"testing-guide/#starting-test-services","title":"Starting Test Services","text":"<pre><code># Start all test services\ndocker-compose -f tests/docker-compose.test.yml up -d\n\n# Services included:\n# - Ollama (port 11434)\n# - Milvus (port 19530)\n# - FalkorDB (port 6379)\n# - MinIO (port 9000)\n# - Test API server (port 8000)\n</code></pre>"},{"location":"testing-guide/#running-tests-in-docker","title":"Running Tests in Docker","text":"<pre><code># tests/docker-compose.test.yml\nversion: '3.8'\nservices:\n  test-runner:\n    build:\n      context: ..\n      dockerfile: tests/Dockerfile\n    environment:\n      - OLLAMA_HOST=ollama:11434\n      - MILVUS_HOST=milvus\n      - FALKORDB_HOST=falkordb\n    volumes:\n      - ../tests:/tests\n      - test-results:/results\n    command: pytest -v --cov --html=/results/report.html\n</code></pre>"},{"location":"testing-guide/#performance-testing","title":"Performance Testing","text":""},{"location":"testing-guide/#benchmark-suite","title":"Benchmark Suite","text":"<pre><code># Run performance benchmarks\npython -m pytest tests/performance/ --benchmark-only\n\n# Generate performance report\npython tests/scripts/generate-performance-report.py\n\n# Expected results:\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 Operation               \u2502 Median  \u2502 P95  \u2502 P99  \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 PDF Processing (10 pg)  \u2502 12.3s   \u2502 18s  \u2502 22s  \u2502\n# \u2502 Text Extraction         \u2502 2.1s    \u2502 3.2s \u2502 4.1s \u2502\n# \u2502 Diagram Detection       \u2502 4.5s    \u2502 6.1s \u2502 7.8s \u2502\n# \u2502 Table Extraction        \u2502 1.8s    \u2502 2.4s \u2502 3.1s \u2502\n# \u2502 Vector Generation       \u2502 0.9s    \u2502 1.2s \u2502 1.5s \u2502\n# \u2502 KG Entity Extraction    \u2502 3.2s    \u2502 4.5s \u2502 5.8s \u2502\n# \u2502 Milvus Insert (1k)      \u2502 120ms   \u2502 180ms\u2502 220ms\u2502\n# \u2502 Milvus Search           \u2502 45ms    \u2502 68ms \u2502 95ms \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"testing-guide/#load-testing","title":"Load Testing","text":"<pre><code># tests/performance/test_load.py\nimport asyncio\nimport aiohttp\nfrom concurrent.futures import ThreadPoolExecutor\n\nasync def test_concurrent_processing():\n    \"\"\"Test system under load\"\"\"\n    async with aiohttp.ClientSession() as session:\n        tasks = []\n        for i in range(100):  # 100 concurrent requests\n            task = process_document_async(\n                session,\n                f\"test_{i}.pdf\"\n            )\n            tasks.append(task)\n\n        results = await asyncio.gather(*tasks)\n        success_rate = sum(1 for r in results if r['status'] == 'success') / 100\n\n        assert success_rate &gt;= 0.95  # 95% success rate\n        assert max(r['duration'] for r in results) &lt; 60  # Max 60s\n</code></pre>"},{"location":"testing-guide/#quality-assurance","title":"Quality Assurance","text":""},{"location":"testing-guide/#code-coverage","title":"Code Coverage","text":"<pre><code># Generate coverage report\npytest --cov=netintel_ocr --cov-report=html --cov-report=term\n\n# View coverage report\nopen htmlcov/index.html\n\n# Expected coverage:\n# \u251c\u2500\u2500 netintel_ocr/\n# \u2502   \u251c\u2500\u2500 hybrid_processor.py     92%\n# \u2502   \u251c\u2500\u2500 api/v2/                 89%\n# \u2502   \u251c\u2500\u2500 cli_v2/                 87%\n# \u2502   \u251c\u2500\u2500 mcp/                    85%\n# \u2502   \u2514\u2500\u2500 Overall:                86%\n</code></pre>"},{"location":"testing-guide/#security-testing","title":"Security Testing","text":"<pre><code># Run security scan\nbandit -r netintel_ocr/ -f json -o security-report.json\n\n# Check dependencies\nsafety check --json &gt; safety-report.json\n\n# SAST analysis\nsemgrep --config=auto netintel_ocr/\n</code></pre>"},{"location":"testing-guide/#linting-and-type-checking","title":"Linting and Type Checking","text":"<pre><code># Run all quality checks\n./scripts/quality-check.sh\n\n# Individual tools:\nblack netintel_ocr/ --check\nisort netintel_ocr/ --check\nflake8 netintel_ocr/\nmypy netintel_ocr/\npylint netintel_ocr/\n</code></pre>"},{"location":"testing-guide/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"testing-guide/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code># .github/workflows/test.yml\nname: Test Suite\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.10\", \"3.11\", \"3.12\"]\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        pip install -e \".[test]\"\n\n    - name: Run tests\n      run: |\n        pytest --cov --junitxml=results.xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"testing-guide/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"testing-guide/#1-test-data-management","title":"1. Test Data Management","text":"<pre><code># Use fixtures for test data\n@pytest.fixture\ndef sample_pdf():\n    return \"tests/fixtures/cisco-sdwan.pdf\"\n\n@pytest.fixture\ndef mock_ollama_response():\n    return {\"text\": \"Sample extracted text\"}\n</code></pre>"},{"location":"testing-guide/#2-mock-external-services","title":"2. Mock External Services","text":"<pre><code># Mock Ollama API\n@patch('netintel_ocr.ollama.client')\ndef test_with_mock_ollama(mock_client):\n    mock_client.generate.return_value = {\n        \"response\": \"Mocked response\"\n    }\n    result = process_document(\"test.pdf\")\n    assert result is not None\n</code></pre>"},{"location":"testing-guide/#3-test-isolation","title":"3. Test Isolation","text":"<pre><code># Use temporary directories\ndef test_processing(tmp_path):\n    output_dir = tmp_path / \"output\"\n    output_dir.mkdir()\n\n    result = process_pdf_hybrid(\n        pdf_path=\"test.pdf\",\n        output_dir=str(output_dir)\n    )\n\n    assert output_dir.exists()\n</code></pre>"},{"location":"testing-guide/#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"testing-guide/#common-issues","title":"Common Issues","text":"Issue Solution Ollama connection failed Ensure Ollama is running: <code>docker-compose up ollama</code> Milvus timeout Check Milvus status: <code>docker-compose ps milvus</code> PDF fixtures missing Download test PDFs: <code>./scripts/download-fixtures.sh</code> Coverage below threshold Run: <code>pytest --cov-fail-under=85</code> Performance regression Compare with baseline: <code>pytest-benchmark compare</code>"},{"location":"testing-guide/#debug-mode","title":"Debug Mode","text":"<pre><code># Run tests with debug output\npytest -vvv --log-cli-level=DEBUG\n\n# Run single test with pdb\npytest -k test_multimodel --pdb\n\n# Profile test performance\npytest --profile --profile-svg\n</code></pre>"},{"location":"testing-guide/#test-reports","title":"Test Reports","text":""},{"location":"testing-guide/#generate-comprehensive-report","title":"Generate Comprehensive Report","text":"<pre><code># Run full test suite with reporting\n./tests/scripts/generate-test-report.sh\n\n# Output includes:\n# - HTML coverage report\n# - JUnit XML results\n# - Performance benchmarks\n# - Security scan results\n# - Quality metrics\n</code></pre>"},{"location":"testing-guide/#view-test-dashboard","title":"View Test Dashboard","text":"<pre><code># Start test dashboard server\npython -m http.server 8080 --directory tests/reports/\n\n# Open in browser\nopen http://localhost:8080\n</code></pre>"},{"location":"testing-guide/#summary","title":"Summary","text":"<p>The v0.1.18.1 test framework provides:</p> <ul> <li>\u2705 Complete Coverage: All components and features tested</li> <li>\u2705 Docker Environment: Isolated, reproducible test environment</li> <li>\u2705 Quality Gates: Automated checks for coverage, performance, security</li> <li>\u2705 CI/CD Ready: GitHub Actions integration</li> <li>\u2705 Performance Benchmarks: Track and prevent regressions</li> <li>\u2705 Real PDF Testing: Integration tests with actual documents</li> </ul> <p>For more information, see: - API Testing Guide - Performance Guide - Troubleshooting</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Platform Requirements</p> <p>Linux Only - NetIntel-OCR runs only on Linux systems.</p> <p>Python 3.11 or 3.12 Only - Other versions are not supported.</p> <p>If you're on Windows/Mac or using a different Python version, these are likely the cause of your issues.</p> <p>New in v0.1.17: Hierarchical CLI</p> <p>NetIntel-OCR v0.1.17 uses a new hierarchical command structure. If commands aren't working, make sure you're using the new syntax: - OLD: <code>netintel-ocr document.pdf</code> - NEW: <code>netintel-ocr process pdf document.pdf</code></p>"},{"location":"troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"troubleshooting/#platform-issues","title":"Platform Issues","text":""},{"location":"troubleshooting/#wrong-operating-system","title":"Wrong Operating System","text":"<p><pre><code>ERROR: Unsupported platform detected\nERROR: Module compilation failed\nERROR: Binary wheel not available\n</code></pre> Solution: <pre><code># Check your OS (must be Linux)\nuname -s\n# Expected: Linux\n\n# NetIntel-OCR requires Linux. Options:\n# 1. Use WSL2 on Windows\n# 2. Use a Linux VM\n# 3. Use a Linux container\n# 4. Deploy to a Linux server\n</code></pre></p>"},{"location":"troubleshooting/#wrong-python-version","title":"Wrong Python Version","text":"<p><pre><code>ERROR: Python 3.11 or 3.12 required\nERROR: Unsupported Python version\nERROR: Module 'netintel_ocr' has no attribute...\n</code></pre> Solution: <pre><code># Check Python version (MUST be 3.11.x or 3.12.x)\npython --version\n\n# Install Python 3.11 on Ubuntu/Debian\nsudo apt update &amp;&amp; sudo apt install python3.11 python3.11-venv python3.11-dev\n\n# Install Python 3.12 on Ubuntu/Debian  \nsudo apt install python3.12 python3.12-venv python3.12-dev\n\n# Create virtual environment with correct version\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Verify version in virtual environment\npython --version  # Must show 3.11.x or 3.12.x\n</code></pre></p>"},{"location":"troubleshooting/#missing-dependencies","title":"Missing Dependencies","text":"<p><pre><code>ERROR: No module named 'pymupdf'\nERROR: ImportError: libGL.so.1: cannot open shared object file\n</code></pre> Solution: <pre><code># Install Linux system dependencies first\nsudo apt-get update\nsudo apt-get install -y \\\n    python3.11-dev \\  # or python3.12-dev\n    gcc g++ \\\n    libgl1-mesa-glx \\\n    libglib2.0-0 \\\n    libsm6 libxext6 libxrender-dev \\\n    libgomp1\n\n# Then reinstall with all dependencies\npip install --upgrade netintel-ocr[all]\n\n# Or install missing module\npip install pymupdf pillow opencv-python-headless\n</code></pre></p>"},{"location":"troubleshooting/#c-extension-build-failure","title":"C++ Extension Build Failure","text":"<p><pre><code>ERROR: Failed building wheel for netintel-ocr\nERROR: Microsoft Visual C++ 14.0 is required (Windows error)\n</code></pre> Solution: <pre><code># This is a Windows error - NetIntel-OCR only supports Linux\n# Switch to a Linux environment\n\n# On Linux, install build tools:\nsudo apt-get install build-essential python3.11-dev\n# or\nsudo yum install gcc gcc-c++ python3.11-devel\n</code></pre></p>"},{"location":"troubleshooting/#ollama-connection-issues","title":"Ollama Connection Issues","text":""},{"location":"troubleshooting/#ollama-not-running","title":"Ollama Not Running","text":"<p><pre><code>ERROR: Connection refused to localhost:11434\n</code></pre> Solution: <pre><code># Start Ollama\nollama serve\n\n# Check if running\ncurl http://localhost:11434/api/tags\n\n# Start in background\nnohup ollama serve &gt; ollama.log 2&gt;&amp;1 &amp;\n</code></pre></p>"},{"location":"troubleshooting/#remote-ollama-host","title":"Remote Ollama Host","text":"<p><pre><code>ERROR: Cannot connect to Ollama\n</code></pre> Solution: <pre><code># Set environment variable\nexport OLLAMA_HOST=http://192.168.1.100:11434\n\n# Or use CLI parameter (v0.1.17 syntax)\nnetintel-ocr process pdf document.pdf --ollama-host http://192.168.1.100:11434\n\n# Test connection\ncurl $OLLAMA_HOST/api/tags\n</code></pre></p>"},{"location":"troubleshooting/#model-issues","title":"Model Issues","text":""},{"location":"troubleshooting/#model-not-found","title":"Model Not Found","text":"<p><pre><code>ERROR: Model 'qwen2.5vl:7b' not found\n</code></pre> Solution: <pre><code># List available models\nollama list\n\n# Pull missing model\nollama pull qwen2.5vl:7b\n\n# Use available model (v0.1.17 syntax)\nnetintel-ocr process pdf document.pdf --network-model llava:latest\n</code></pre></p>"},{"location":"troubleshooting/#out-of-memory","title":"Out of Memory","text":"<p><pre><code>ERROR: Out of memory (OOM)\n</code></pre> Solution: <pre><code># Use smaller model\nnetintel-ocr process file document.pdf --network-model minicpm-v:latest\n\n# Limit context size\nnetintel-ocr process file document.pdf --max-context 2048\n\n# Process fewer pages\nnetintel-ocr process file document.pdf --pages 1-10\n\n# Free memory\nollama stop all\n</code></pre></p>"},{"location":"troubleshooting/#processing-errors","title":"Processing Errors","text":""},{"location":"troubleshooting/#pdf-read-error","title":"PDF Read Error","text":"<p><pre><code>ERROR: Cannot read PDF file\n</code></pre> Solution: <pre><code># Check file exists and is valid\nfile document.pdf\npdfinfo document.pdf\n\n# Try repairing PDF\nqpdf --replace-input document.pdf\n\n# Convert with ghostscript\ngs -sDEVICE=pdfwrite -o fixed.pdf document.pdf\n</code></pre></p>"},{"location":"troubleshooting/#timeout-during-processing","title":"Timeout During Processing","text":"<p><pre><code>ERROR: Processing timeout after 300 seconds\n</code></pre> Solution: <pre><code># Increase timeout\nnetintel-ocr process pdf document.pdf --timeout 600\n\n# Use faster model\nnetintel-ocr process pdf document.pdf --network-model bakllava:latest\n\n# Process in smaller chunks\nnetintel-ocr process pdf document.pdf --start 1 --end 20\nnetintel-ocr process pdf document.pdf --start 21 --end 40\n</code></pre></p>"},{"location":"troubleshooting/#mermaid-parse-error","title":"Mermaid Parse Error","text":"<p><pre><code>ERROR: Parse error on line 3\n</code></pre> Solution: <pre><code># Enable auto-fix\nnetintel-ocr process pdf document.pdf --fix-mermaid\n\n# Use robust validator\nnetintel-ocr process pdf document.pdf --validate-mermaid\n\n# Disable Mermaid generation\nnetintel-ocr process pdf document.pdf --no-mermaid\n</code></pre></p>"},{"location":"troubleshooting/#vector-store-issues","title":"Vector Store Issues","text":""},{"location":"troubleshooting/#milvus-connection-failed","title":"Milvus Connection Failed","text":"<p><pre><code>ERROR: Cannot connect to Milvus at localhost:19530\n</code></pre> Solution: <pre><code># Start Milvus\ndocker run -d --name milvus \\\n  -p 19530:19530 \\\n  milvusdb/milvus:latest\n\n# Check connection\npython -c \"from pymilvus import connections; connections.connect()\"\n\n# Use different host\nnetintel-ocr process pdf document.pdf --milvus-host milvus.server:19530\n</code></pre></p>"},{"location":"troubleshooting/#collection-already-exists","title":"Collection Already Exists","text":"<p><pre><code>ERROR: Collection 'network_docs' already exists\n</code></pre> Solution: <pre><code># Drop existing collection\nnetintel-ocr db cleanup --collection network_docs\n\n# Or use different collection\nnetintel-ocr process pdf document.pdf --collection network_docs_v2\n\n# Append to existing\nnetintel-ocr process pdf document.pdf --append-collection network_docs\n</code></pre></p>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-processing","title":"Slow Processing","text":"<p>Symptoms: Processing takes &gt;30s per page</p> <p>Solutions: <pre><code># Use faster models\nnetintel-ocr process pdf document.pdf --fast-mode\n\n# Enable GPU\nnetintel-ocr process pdf document.pdf --gpu\n\n# Disable context extraction\nnetintel-ocr process pdf document.pdf --no-context\n\n# Use cached models\nnetintel-ocr process pdf document.pdf --cache-models\n</code></pre></p>"},{"location":"troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: System becomes unresponsive</p> <p>Solutions: <pre><code># Limit memory usage\nnetintel-ocr process pdf document.pdf --max-memory 4GB\n\n# Process sequentially\nnetintel-ocr process pdf document.pdf --no-parallel\n\n# Clear cache\nnetintel-ocr system cleanup --cache\nrm -rf ~/.cache/netintel-ocr\n</code></pre></p>"},{"location":"troubleshooting/#output-issues","title":"Output Issues","text":""},{"location":"troubleshooting/#missing-output-files","title":"Missing Output Files","text":"<p><pre><code>No output files generated\n</code></pre> Solution: <pre><code># Check output directory\nls -la output/\n\n# Specify output directory\nnetintel-ocr process pdf document.pdf --output ./my-output\n\n# Check permissions\nchmod 755 output/\nchmod 644 document.pdf\n</code></pre></p>"},{"location":"troubleshooting/#corrupted-mermaid-diagrams","title":"Corrupted Mermaid Diagrams","text":"<p>Symptoms: Mermaid diagrams don't render</p> <p>Solution: <pre><code># Validate Mermaid syntax\nnetintel-ocr system validate-mermaid output/page_005_network.md\n\n# Re-process with fixes\nnetintel-ocr process pdf document.pdf --start 5 --end 5 --fix-mermaid\n\n# Use different Mermaid version\nnetintel-ocr process pdf document.pdf --mermaid-version 10.0.0\n</code></pre></p>"},{"location":"troubleshooting/#v0117-cli-migration-issues","title":"v0.1.17 CLI Migration Issues","text":""},{"location":"troubleshooting/#command-not-found","title":"Command Not Found","text":"<p><pre><code>ERROR: No such command \"document.pdf\"\nERROR: Invalid command\n</code></pre> Cause: Using old v0.1.16 syntax with v0.1.17</p> <p>Solution: <pre><code># OLD (v0.1.16 and earlier) - DEPRECATED\nnetintel-ocr document.pdf\nnetintel-ocr --query \"search term\"\nnetintel-ocr --api\n\n# NEW (v0.1.17) - CORRECT\nnetintel-ocr process pdf document.pdf\nnetintel-ocr db query \"search term\"\nnetintel-ocr server api\n\n# View all command groups\nnetintel-ocr --help\n\n# View specific group commands\nnetintel-ocr process --help\nnetintel-ocr kg --help\nnetintel-ocr config --help\n</code></pre></p>"},{"location":"troubleshooting/#knowledge-graph-issues","title":"Knowledge Graph Issues","text":""},{"location":"troubleshooting/#falkordb-connection-issues","title":"FalkorDB Connection Issues","text":"<p><pre><code>ERROR: FalkorDB connection refused at localhost:6379\nERROR: Cannot connect to graph database\n</code></pre> Solution: <pre><code># Start FalkorDB container\ndocker run -d --name falkordb -p 6379:6379 falkordb/falkordb:latest\n\n# Check if FalkorDB is running\ndocker ps | grep falkordb\nredis-cli -p 6379 ping\n\n# Initialize KG system\nnetintel-ocr kg init\n\n# Use custom FalkorDB host\nexport FALKORDB_HOST=192.168.1.100\nexport FALKORDB_PORT=6379\nnetintel-ocr kg init --falkordb-host $FALKORDB_HOST\n</code></pre></p>"},{"location":"troubleshooting/#pykeen-installation-issues","title":"PyKEEN Installation Issues","text":"<p><pre><code>ERROR: PyKEEN not installed\nERROR: No module named 'pykeen'\n</code></pre> Solution: <pre><code># Install KG dependencies\npip install pykeen torch falkordb\n\n# Check all KG requirements\nnetintel-ocr kg check-requirements --verbose\n\n# If torch fails, install CPU version\npip install torch --index-url https://download.pytorch.org/whl/cpu\n</code></pre></p>"},{"location":"troubleshooting/#kg-training-issues","title":"KG Training Issues","text":"<p><pre><code>ERROR: Failed to train embeddings\nERROR: CUDA out of memory\n</code></pre> Solution: <pre><code># Use CPU for training\nnetintel-ocr kg train-embeddings --device cpu\n\n# Reduce batch size\nnetintel-ocr kg train-embeddings --batch-size 64\n\n# Use simpler model\nnetintel-ocr kg train-embeddings --model TransE --epochs 50\n\n# Process without KG if not needed\nnetintel-ocr process pdf document.pdf --no-kg\n</code></pre></p>"},{"location":"troubleshooting/#minirag-model-issues","title":"MiniRAG Model Issues","text":"<p><pre><code>ERROR: MiniRAG models not found\nERROR: MINIRAG_LLM environment variable not set\n</code></pre> Solution: <pre><code># Set MiniRAG environment variables\nexport MINIRAG_LLM=\"ollama/gemma3:4b-it-qat\"\nexport MINIRAG_EMBEDDING=\"ollama/qwen3-embedding:8b\"\nexport MINIRAG_EMBEDDING_DIM=\"4096\"\n\n# Pull required models\nollama pull gemma3:4b-it-qat\nollama pull qwen3-embedding:8b\n\n# Verify models are available\nollama list | grep -E \"gemma3|qwen3\"\n</code></pre></p>"},{"location":"troubleshooting/#hybrid-retrieval-issues","title":"Hybrid Retrieval Issues","text":"<p><pre><code>ERROR: Strategy 'adaptive' failed\nERROR: RRF fusion error\n</code></pre> Solution: <pre><code># Use specific strategy instead of adaptive\nnetintel-ocr kg hybrid-search \"query\" --strategy vector_first\nnetintel-ocr kg hybrid-search \"query\" --strategy graph_first\n\n# Check both storage systems\nnetintel-ocr kg stats  # Check FalkorDB\nnetintel-ocr db stats  # Check Milvus\n\n# Compare strategies to find working one\nnetintel-ocr kg compare-strategies \"test query\"\n</code></pre></p>"},{"location":"troubleshooting/#kg-query-issues","title":"KG Query Issues","text":"<p><pre><code>ERROR: Invalid Cypher syntax\nERROR: No results found\n</code></pre> Solution: <pre><code># Check graph statistics first\nnetintel-ocr kg stats\n\n# List all node types\nnetintel-ocr kg query \"MATCH (n) RETURN DISTINCT labels(n)\"\n\n# Simple test query\nnetintel-ocr kg query \"MATCH (n) RETURN n LIMIT 5\"\n\n# Use natural language instead\nnetintel-ocr kg rag-query \"show all routers\"\n</code></pre></p>"},{"location":"troubleshooting/#configuration-template-issues","title":"Configuration Template Issues","text":"<p><pre><code>ERROR: Template not found\nERROR: Invalid configuration\n</code></pre> Solution: <pre><code># List available templates\nnetintel-ocr config template list\n\n# Apply template\nnetintel-ocr config init --template production\n\n# View current config\nnetintel-ocr config show\n\n# Validate configuration\nnetintel-ocr config validate\n</code></pre></p>"},{"location":"troubleshooting/#profile-management-issues","title":"Profile Management Issues","text":"<p><pre><code>ERROR: Profile not found\n</code></pre> Solution: <pre><code># List profiles\nnetintel-ocr config profile list\n\n# Create new profile\nnetintel-ocr config profile create production\n\n# Switch profile\nnetintel-ocr config profile use production\n\n# Show current profile\nnetintel-ocr config profile current\n</code></pre></p>"},{"location":"troubleshooting/#environment-verification","title":"Environment Verification","text":""},{"location":"troubleshooting/#check-system-compatibility","title":"Check System Compatibility","text":"<pre><code># Full system check\necho \"OS: $(uname -s)\"  # Must be Linux\necho \"Arch: $(uname -m)\"  # Should be x86_64\necho \"Python: $(python3 --version)\"  # Must be 3.11.x or 3.12.x\necho \"Distro: $(lsb_release -d 2&gt;/dev/null || cat /etc/os-release | grep PRETTY_NAME)\"\n\n# Expected output:\n# OS: Linux\n# Arch: x86_64  \n# Python: Python 3.11.x (or 3.12.x)\n# Distro: Ubuntu 20.04/22.04 or similar\n</code></pre>"},{"location":"troubleshooting/#python-environment-check","title":"Python Environment Check","text":"<pre><code># Verify Python installation\nwhich python3.11 python3.12 2&gt;/dev/null\n\n# Check available Python versions\nls -la /usr/bin/python3*\n\n# Verify pip version matches Python\npip --version  # Should show (python 3.11) or (python 3.12)\n\n# Check virtual environment\npython -c \"import sys; print(f'Python: {sys.version}')\"\npython -c \"import platform; print(f'Platform: {platform.platform()}')\"\n</code></pre>"},{"location":"troubleshooting/#knowledge-graph-deep-dive-troubleshooting","title":"Knowledge Graph Deep Dive Troubleshooting","text":""},{"location":"troubleshooting/#kg-performance-optimization","title":"KG Performance Optimization","text":"<pre><code># Monitor KG processing performance\nnetintel-ocr kg stats --detailed\n\n# Optimize for speed (fewer epochs, simpler model)\nnetintel-ocr process pdf document.pdf \\\n  --kg-model TransE \\\n  --kg-epochs 50 \\\n  --kg-batch-size 256\n\n# Optimize for accuracy (more epochs, complex model)\nnetintel-ocr process pdf document.pdf \\\n  --kg-model ComplEx \\\n  --kg-epochs 200 \\\n  --kg-batch-size 128\n\n# Skip KG for faster processing\nnetintel-ocr process pdf document.pdf --no-kg\n</code></pre>"},{"location":"troubleshooting/#kg-model-selection-guide","title":"KG Model Selection Guide","text":"<pre><code># For simple hierarchical networks\nnetintel-ocr kg train-embeddings --model TransE\n\n# For complex relationships (DEFAULT)\nnetintel-ocr kg train-embeddings --model RotatE\n\n# For symmetric relationships\nnetintel-ocr kg train-embeddings --model ComplEx\n\n# For high accuracy (slower)\nnetintel-ocr kg train-embeddings --model ConvE\n\n# View all available models\nnetintel-ocr kg train-embeddings --list-models\n</code></pre>"},{"location":"troubleshooting/#kg-visualization-issues","title":"KG Visualization Issues","text":"<pre><code># If visualization fails\nnetintel-ocr kg visualize --method pca --dimensions 2\n\n# Alternative visualization methods\nnetintel-ocr kg visualize --method umap\nnetintel-ocr kg visualize --method tsne --perplexity 30\n\n# Save as image instead of HTML\nnetintel-ocr kg visualize --format png --output graph.png\n</code></pre>"},{"location":"troubleshooting/#kg-entity-analysis","title":"KG Entity Analysis","text":"<pre><code># Find orphaned entities\nnetintel-ocr kg query \"MATCH (n) WHERE NOT (n)--() RETURN n\"\n\n# Find most connected entities\nnetintel-ocr kg query \"MATCH (n)-[r]-() RETURN n, count(r) as connections ORDER BY connections DESC LIMIT 10\"\n\n# Find specific entity types\nnetintel-ocr kg query \"MATCH (n:Router) RETURN n\"\nnetintel-ocr kg query \"MATCH (n:Firewall) RETURN n\"\n</code></pre>"},{"location":"troubleshooting/#debugging-commands","title":"Debugging Commands","text":""},{"location":"troubleshooting/#enable-debug-mode","title":"Enable Debug Mode","text":"<pre><code># Full debug output (v0.1.17)\nnetintel-ocr --debug process pdf document.pdf\n\n# Debug KG processing\nnetintel-ocr --debug kg process document.pdf\n\n# Save debug logs\nnetintel-ocr --debug process pdf document.pdf --log-file debug.log\n</code></pre>"},{"location":"troubleshooting/#test-components","title":"Test Components","text":"<pre><code># Test KG system\nnetintel-ocr kg check-requirements --test\n\n# Test FalkorDB connection\nnetintel-ocr kg init --test-only\n\n# Dry run without processing\nnetintel-ocr process pdf document.pdf --dry-run\n</code></pre>"},{"location":"troubleshooting/#health-checks","title":"Health Checks","text":"<pre><code># System health check\nnetintel-ocr system check\n\n# Model availability\nnetintel-ocr model list\n\n# Storage status\nnetintel-ocr system check\n</code></pre>"},{"location":"troubleshooting/#log-analysis","title":"Log Analysis","text":""},{"location":"troubleshooting/#common-log-patterns","title":"Common Log Patterns","text":"<pre><code># Find errors in logs\ngrep ERROR netintel.log\n\n# Find timeout issues\ngrep -i timeout netintel.log\n\n# Find model issues\ngrep -E \"(model|ollama)\" netintel.log\n\n# Find memory issues\ngrep -E \"(memory|OOM|RAM)\" netintel.log\n</code></pre>"},{"location":"troubleshooting/#log-levels","title":"Log Levels","text":"<pre><code># Verbose logging (v0.1.17)\nnetintel-ocr --debug process pdf document.pdf\n\n# Only errors\nnetintel-ocr --log-level ERROR process pdf document.pdf\n\n# Structured JSON logs\nnetintel-ocr --log-format json process pdf document.pdf\n</code></pre>"},{"location":"troubleshooting/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"troubleshooting/#resume-failed-processing","title":"Resume Failed Processing","text":"<pre><code># Save checkpoint (v0.1.17)\nnetintel-ocr process pdf document.pdf --checkpoint state.json\n\n# Resume from checkpoint\nnetintel-ocr process pdf document.pdf --resume state.json\n</code></pre>"},{"location":"troubleshooting/#rebuild-vector-index","title":"Rebuild Vector Index","text":"<pre><code># Rebuild corrupted index (v0.1.17)\nnetintel-ocr db compact --collection network_docs\n\n# Verify index integrity\nnetintel-ocr db stats --collection network_docs\n</code></pre>"},{"location":"troubleshooting/#reset-configuration","title":"Reset Configuration","text":"<pre><code># Reset to defaults (v0.1.17)\nnetintel-ocr config init --force\n\n# Regenerate project\nnetintel-ocr project init --force\n</code></pre>"},{"location":"troubleshooting/#platform-specific-issues","title":"Platform-Specific Issues","text":""},{"location":"troubleshooting/#wsl2-windows-subsystem-for-linux","title":"WSL2 (Windows Subsystem for Linux)","text":"<pre><code># If trying to run on Windows via WSL2\n# Ensure WSL2 is properly configured\nwsl --status\nwsl --list --verbose\n\n# Install Ubuntu 22.04 in WSL2\nwsl --install -d Ubuntu-22.04\n\n# Inside WSL2, install Python 3.11\nsudo apt update\nsudo apt install python3.11 python3.11-venv python3.11-dev\n\n# Install NetIntel-OCR in WSL2 environment\npython3.11 -m pip install netintel-ocr\n</code></pre>"},{"location":"troubleshooting/#docker-on-non-linux-systems","title":"Docker on Non-Linux Systems","text":"<pre><code># Running via Docker on Windows/Mac\n# Note: Performance may be degraded\n\n# Use Linux container mode\ndocker run --platform linux/amd64 \\\n  -v $(pwd):/data \\\n  netintel-ocr:latest document.pdf\n\n# Build for Linux platform\ndocker buildx build --platform linux/amd64 -t netintel-ocr:latest .\n</code></pre>"},{"location":"troubleshooting/#common-linux-distribution-issues","title":"Common Linux Distribution Issues","text":""},{"location":"troubleshooting/#ubuntudebian","title":"Ubuntu/Debian","text":"<pre><code># Missing Python 3.11/3.12\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.11-full\n</code></pre>"},{"location":"troubleshooting/#rhelcentosrocky-linux","title":"RHEL/CentOS/Rocky Linux","text":"<pre><code># Enable EPEL and install Python 3.11\nsudo dnf install epel-release\nsudo dnf install python3.11 python3.11-devel\n</code></pre>"},{"location":"troubleshooting/#arch-linux","title":"Arch Linux","text":"<pre><code># Python versions available in standard repos\nsudo pacman -S python  # Usually latest version\n</code></pre>"},{"location":"troubleshooting/#knowledge-graph-quick-reference","title":"Knowledge Graph Quick Reference","text":""},{"location":"troubleshooting/#essential-kg-environment-variables","title":"Essential KG Environment Variables","text":"<pre><code># Required for KG operation\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\nexport FALKORDB_HOST=\"localhost\"\nexport FALKORDB_PORT=\"6379\"\nexport MINIRAG_LLM=\"ollama/gemma3:4b-it-qat\"\nexport MINIRAG_EMBEDDING=\"ollama/qwen3-embedding:8b\"\n</code></pre>"},{"location":"troubleshooting/#kg-processing-workflow","title":"KG Processing Workflow","text":"<pre><code># 1. Check requirements\nnetintel-ocr kg check-requirements\n\n# 2. Initialize system\nnetintel-ocr kg init\n\n# 3. Process document with KG\nnetintel-ocr process pdf document.pdf  # KG enabled by default\n\n# 4. Train embeddings (if needed)\nnetintel-ocr kg train-embeddings --model RotatE\n\n# 5. Query the graph\nnetintel-ocr kg query \"MATCH (n) RETURN n LIMIT 10\"\nnetintel-ocr kg rag-query \"show network topology\"\n\n# 6. Visualize results\nnetintel-ocr kg visualize --output graph.html\n</code></pre>"},{"location":"troubleshooting/#kg-troubleshooting-checklist","title":"KG Troubleshooting Checklist","text":"<ul> <li>[ ] FalkorDB running and accessible</li> <li>[ ] PyKEEN and torch installed</li> <li>[ ] MiniRAG models pulled in Ollama</li> <li>[ ] Environment variables set</li> <li>[ ] Sufficient memory for embeddings (8GB+ recommended)</li> <li>[ ] Graph initialized with <code>kg init</code></li> </ul>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#generate-diagnostic-report","title":"Generate Diagnostic Report","text":"<pre><code># Full system diagnostic with KG info\nnetintel-ocr system diagnose --include-kg &gt; report.txt\n\n# KG-specific diagnostics\nnetintel-ocr kg stats --format json &gt;&gt; report.txt\nnetintel-ocr kg check-requirements --verbose &gt;&gt; report.txt\n\n# Include system info\necho \"=== System Info ===\" &gt;&gt; report.txt\nuname -a &gt;&gt; report.txt\npython --version &gt;&gt; report.txt\nlsb_release -a 2&gt;/dev/null &gt;&gt; report.txt\n</code></pre>"},{"location":"troubleshooting/#community-support","title":"Community Support","text":"<ul> <li>GitHub Issues: https://github.com/VisionMLNet/NetIntelOCR/issues</li> <li>PyPI Package: https://pypi.org/project/netintel-ocr/</li> <li>Documentation: https://visionml.net/docs</li> <li>Discord: https://discord.gg/netintel-ocr</li> </ul>"},{"location":"troubleshooting/#include-in-bug-reports","title":"Include in Bug Reports","text":"<ol> <li>Operating System: <code>uname -a</code> (MUST be Linux)</li> <li>Python version: <code>python --version</code> (MUST be 3.11.x or 3.12.x)</li> <li>NetIntel-OCR version: <code>netintel-ocr system version</code></li> <li>Linux distribution: <code>cat /etc/os-release</code></li> <li>Ollama models: <code>ollama list</code></li> <li>Error messages and logs</li> <li>Installation method (pip, Docker, source)</li> <li>Sample PDF (if possible)</li> </ol>"},{"location":"troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Model Guide - Optimize model selection</li> <li>Performance Guide - Improve processing speed</li> <li>API Integration - Programmatic troubleshooting</li> </ul>"},{"location":"use-cases/","title":"Knowledge Graph Use Cases","text":"<p>Technical workflows demonstrating NetIntel-OCR v0.1.17's Knowledge Graph capabilities through real-world scenarios.</p>"},{"location":"use-cases/#available-use-cases","title":"Available Use Cases","text":""},{"location":"use-cases/#network-infrastructure-migration","title":"\ud83d\udcca Network Infrastructure Migration","text":"<p>Transform complex network documentation into actionable migration plans with dependency analysis and risk assessment.</p> <p>Key Capabilities: - Dependency mapping across 3,847 components - Hidden connection discovery - Migration wave planning - Cloud compatibility validation - Risk assessment and validation</p> <p>Metrics: - Analysis time: 3 months \u2192 2 days - Accuracy: 94% vs 67% manual - Hidden dependencies found: 23</p>"},{"location":"use-cases/#security-compliance-audit","title":"\ud83d\udd12 Security Compliance Audit","text":"<p>Automate multi-tenant security compliance for Managed Security Service Providers with configuration drift detection and automated remediation.</p> <p>Key Capabilities: - Multi-framework compliance checking - Configuration drift analysis - Access path tracing - Automated remediation scripts - Zero-trust validation</p> <p>Metrics: - Audit time: 3 weeks \u2192 2 days - Compliance score: 78% \u2192 92% - Violations detected: 96% accuracy</p>"},{"location":"use-cases/#intelligent-incident-response","title":"\ud83d\udea8 Intelligent Incident Response","text":"<p>Real-time incident correlation with automated runbook execution and root cause analysis.</p> <p>Key Capabilities: - Multi-source alert correlation - Automated runbook matching - Root cause analysis - Pattern recognition - Prevention recommendations</p> <p>Metrics: - MTTR: 45 min \u2192 15 min (67% reduction) - Auto-resolution: 78.7% of incidents - Revenue protected: $3.2M annually</p>"},{"location":"use-cases/#customer-service-chat-intelligence","title":"\ud83d\udcac Customer Service Chat Intelligence","text":"<p>Enable intelligent customer service for complex enterprise telecom offerings with real-time pricing and availability from ServiceNow and Salesforce.</p> <p>Key Capabilities: - Multi-source data integration (ServiceNow CMDB, Salesforce CRM) - Service matching and recommendation - Dynamic pricing and bundling - Location-based availability checking - Automated chat responses with 94% accuracy</p> <p>Metrics: - Response time: 1.8 seconds average - Lead qualification: +45% improvement - Agent productivity: +210% - Quote accuracy: 99.2%</p>"},{"location":"use-cases/#performance-comparison","title":"Performance Comparison","text":""},{"location":"use-cases/#query-performance-across-use-cases","title":"Query Performance Across Use Cases","text":"Operation Traditional Vector Only Graph Only KG Embeddings Hybrid KG Dependency Analysis 2.3s 450ms 120ms 85ms 180ms Compliance Check 5.1s 780ms 230ms 140ms 290ms Incident Correlation 8.7s 920ms 340ms 190ms 410ms Accuracy 62% 71% 83% 87% 94%"},{"location":"use-cases/#storage-efficiency","title":"Storage Efficiency","text":"<pre><code>Traditional Approach:\n  Separate databases: 15.3 GB\n  Redundant data: 4.7 GB\n  Total: 20 GB\n\nNetIntel-OCR KG:\n  FalkorDB: 3.2 GB\n  Milvus: 8.1 GB\n  Total: 11.3 GB\n  Savings: 43.5%\n</code></pre>"},{"location":"use-cases/#technical-architecture","title":"Technical Architecture","text":""},{"location":"use-cases/#knowledge-graph-stack","title":"Knowledge Graph Stack","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         PDF Documents               \u2502\n\u2502  (Network, Security, Operations)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      NetIntel-OCR v0.1.17          \u2502\n\u2502  \u2022 Diagram Detection                \u2502\n\u2502  \u2022 Table Extraction                 \u2502\n\u2502  \u2022 Entity Recognition               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc                 \u25bc          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502FalkorDB \u2502    \u2502  PyKEEN  \u2502  \u2502 Milvus  \u2502\n\u2502 Graph   \u2502    \u2502Embeddings\u2502  \u2502 Vectors \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502                 \u2502          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Hybrid Retrieval              \u2502\n\u2502  \u2022 Query Classification             \u2502\n\u2502  \u2022 Strategy Selection               \u2502\n\u2502  \u2022 Result Fusion                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"use-cases/#getting-started","title":"Getting Started","text":""},{"location":"use-cases/#prerequisites","title":"Prerequisites","text":"<pre><code># Install NetIntel-OCR\npip install netintel-ocr==0.1.17\n\n# Configure external Ollama server\nexport OLLAMA_HOST=\"http://your-ollama-server:11434\"\n\n# Verify Ollama has required models\ncurl $OLLAMA_HOST/api/tags | jq '.models[].name'\n# Required: qwen2.5vl:7b, gemma3:4b-it-qat, qwen3-embedding:8b\n\n# Start required graph/vector services\ndocker-compose up -d falkordb milvus\n\n# Verify installation\nnetintel-ocr kg check-requirements\n</code></pre>"},{"location":"use-cases/#quick-commands","title":"Quick Commands","text":"<pre><code># Process documents with KG\nnetintel-ocr process batch --kg-model RotatE documents/*.pdf\n\n# Query knowledge graph\nnetintel-ocr kg query --entity \"System-Name\" --max-depth 3\n\n# Run compliance check\nnetintel-ocr kg compliance --framework PCI-DSS-v4.0\n\n# Correlate incident\nnetintel-ocr kg correlate --incident alert.json\n</code></pre>"},{"location":"use-cases/#choosing-the-right-use-case","title":"Choosing the Right Use Case","text":""},{"location":"use-cases/#when-to-use-each-approach","title":"When to Use Each Approach","text":"Scenario Recommended Use Case Key Benefits Cloud migration planning Migration Dependency mapping, risk assessment Compliance audit Compliance Automated validation, remediation Service outage Incident Response Fast correlation, runbook automation Network redesign Migration Impact analysis, validation Security assessment Compliance Vulnerability detection, drift analysis Performance issues Incident Response Pattern recognition, RCA"},{"location":"use-cases/#advanced-features","title":"Advanced Features","text":""},{"location":"use-cases/#knowledge-graph-capabilities","title":"Knowledge Graph Capabilities","text":"<ul> <li>Entity Extraction: Automatic identification of network components, services, and relationships</li> <li>Embedding Training: 8 PyKEEN models for different relationship types</li> <li>Hybrid Retrieval: Combines graph traversal, vector similarity, and KG embeddings</li> <li>Query Routing: Automatic selection of optimal retrieval strategy</li> <li>Real-time Updates: Continuous learning from new documents</li> </ul>"},{"location":"use-cases/#integration-options","title":"Integration Options","text":"<ul> <li>REST API: HTTP endpoints for all operations</li> <li>Python SDK: Native Python library for custom workflows</li> <li>CLI Tools: Command-line interface for automation</li> <li>Docker/K8s: Container deployment for scalability</li> </ul>"},{"location":"use-cases/#support-and-resources","title":"Support and Resources","text":"<ul> <li>Documentation: Knowledge Graph Guide</li> <li>Quick Start: Getting Started</li> <li>API Reference: API Documentation</li> <li>Troubleshooting: Support Guide</li> </ul> <p>Select a use case above to explore detailed technical workflows and command examples.</p>"},{"location":"usecase-compliance/","title":"Security Compliance Audit &amp; Remediation","text":""},{"location":"usecase-compliance/#scenario-overview","title":"Scenario Overview","text":"<p>Organization: Managed Security Service Provider (MSSP) serving 150+ enterprise clients Challenge: Validate compliance across multi-tenant security infrastructure Infrastructure: 500+ firewalls, 200+ VPN gateways, complex segmentation Requirements: Continuous compliance monitoring, automated remediation</p>"},{"location":"usecase-compliance/#technical-workflow","title":"Technical Workflow","text":""},{"location":"usecase-compliance/#step-1-security-audit-setup","title":"Step 1: Security Audit Setup","text":"<pre><code># Initialize security audit project\nmkdir -p security-audit/{docs,analysis,remediation}\ncd security-audit\n\n# Initialize FalkorDB for security analysis\nnetintel-ocr kg init \\\n  --falkordb-host localhost \\\n  --falkordb-port 6379 \\\n  --graph-name security_audit\n\n# Set environment for security-focused processing\nexport FALKORDB_GRAPH=security_audit\nexport KG_MODEL=ComplEx  # Better for bidirectional relationships\nexport KG_EPOCHS=150\n</code></pre>"},{"location":"usecase-compliance/#step-2-process-security-documentation","title":"Step 2: Process Security Documentation","text":"<pre><code># Process network segmentation diagrams with KG\nnetintel-ocr process pdf docs/network-segmentation.pdf \\\n  --network-model qwen2.5vl:7b \\\n  --kg-model ComplEx \\\n  --kg-epochs 150 \\\n  --output analysis/\n\n# Process firewall configurations (multiple vendors)\nfor config in docs/configs/*.pdf; do\n  netintel-ocr process pdf \"$config\" \\\n    --extract-tables \\\n    --table-method llm \\\n    --kg-model ComplEx \\\n    --output \"analysis/$(basename $config .pdf)/\"\ndone\n\n# Process security policies in batch\nnetintel-ocr process batch docs/policies/ \\\n  --pattern \"*.pdf\" \\\n  --output-dir analysis/policies/\n\n# Process each document with KG generation\nnetintel-ocr kg process \\\n  --model ComplEx \\\n  --epochs 150 \\\n  docs/complete-security-docs.pdf\n\n# Verify extraction\nnetintel-ocr kg stats --format json &gt; analysis/stats.json\n\n# View statistics\nnetintel-ocr kg stats --format table\n\n# Example Output:\n# Graph Statistics:\n#   Total nodes: 234\n#   Total edges: 8,456\n#   Node types: Firewall, Rule, Zone, VLAN, Policy\n#   Edge types: HAS_RULE, CONNECTS_TO, ENFORCES\n</code></pre>"},{"location":"usecase-compliance/#step-3-pci-dss-compliance-analysis","title":"Step 3: PCI-DSS Compliance Analysis","text":"<pre><code># Query for network segmentation violations using Cypher\nnetintel-ocr kg query \\\n  \"MATCH (ce:Zone {name: 'Customer_Edge'})-[r]-(other:Zone)\n   WHERE NOT exists(r.firewall) AND other.tenant &lt;&gt; ce.tenant\n   RETURN ce, r, other\" \\\n  --format json &gt; analysis/segmentation_violations.json\n\n# Find any-any firewall rules (security risk)\nnetintel-ocr kg query \\\n  \"MATCH (fw:Firewall)-[:HAS_RULE]-&gt;(r:Rule)\n   WHERE r.source = 'any' AND r.destination = 'any'\n   RETURN fw.name as firewall, count(r) as any_any_rules\n   ORDER BY any_any_rules DESC\" \\\n  --format json &gt; analysis/any_any_rules.json\n\n# Query for unencrypted protocols in sensitive zones\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)\n   WHERE s.protocol IN ['telnet', 'ftp', 'http', 'snmp-v1']\n   AND s.zone IN ['Customer_Edge', 'DMZ']\n   RETURN s.name, s.protocol, s.port\" \\\n  --format json &gt; analysis/unencrypted_services.json\n\n# Use hybrid search to find compliance issues\nnetintel-ocr kg hybrid-search \\\n  \"PCI-DSS compliance violations firewall rules\" \\\n  --strategy adaptive \\\n  --limit 50 &gt; analysis/compliance_issues.json\n\n# Output:\n# PCI-DSS Compliance Score: 78%\n# \n# Critical Violations: 3\n# - Cross-tenant data leakage path detected (SP Req 1.3.1)\n# - Missing inter-tenant segmentation controls (SP Req 1.3.4)\n# - Unencrypted management protocols on provider edge (SP Req 2.3)\n# \n# High Risk: 8\n# Medium Risk: 15\n# Low Risk: 42\n</code></pre>"},{"location":"usecase-compliance/#step-4-configuration-analysis-using-embeddings","title":"Step 4: Configuration Analysis Using Embeddings","text":"<pre><code># Train embeddings on security configurations\nnetintel-ocr kg train-embeddings \\\n  --model ComplEx \\\n  --epochs 150 \\\n  --force\n\n# Find similar firewall configurations using KG embeddings\nnetintel-ocr kg find-similar \"FW-Template-PCI\" \\\n  --limit 20 \\\n  --threshold 0.85 &gt; analysis/similar_configs.json\n\n# Compare configurations between firewalls\nnetintel-ocr kg similarity \"FW-PROD-01\" \"FW-DR-01\" \\\n  --method cosine &gt; analysis/config_similarity.txt\n\n# Cluster firewalls by configuration similarity\nnetintel-ocr kg cluster \\\n  --n-clusters 5 \\\n  --method kmeans &gt; analysis/firewall_clusters.json\n\n# Visualize configuration landscape\nnetintel-ocr kg visualize \\\n  --method tsne \\\n  --dimensions 2 \\\n  --color-by type \\\n  --save-plot analysis/config_landscape.png\n\n# Show drift summary\ncat analysis/config_drift.json | jq '.drift_summary'\n\n# Output:\n# {\n#   \"total_devices\": 234,\n#   \"compliant\": 187,\n#   \"drift_detected\": 47,\n#   \"critical_drift\": 12,\n#   \"parameters_changed\": {\n#     \"acl_rules\": 23,\n#     \"nat_policies\": 15,\n#     \"logging_config\": 34,\n#     \"timeout_values\": 18\n#   }\n# }\n\n# Generate detailed comparison for each firewall\nfor fw in $(cat analysis/firewall_clusters.json | jq -r '.outliers[].name'); do\n  netintel-ocr kg similarity \"$fw\" \"FW-Template-PCI\" \\\n    --method cosine &gt; \"analysis/drift/${fw}_similarity.txt\"\n\n  # Query for specific configuration differences\n  netintel-ocr kg query \\\n    \"MATCH (fw:Firewall {name:'$fw'})-[:HAS_CONFIG]-&gt;(c:Config)\n     RETURN c.parameter, c.value\" \\\n    --format json &gt; \"analysis/drift/${fw}_config.json\"\ndone\n</code></pre>"},{"location":"usecase-compliance/#step-5-access-path-analysis","title":"Step 5: Access Path Analysis","text":"<pre><code># Find paths between security zones\nnetintel-ocr kg path-find \"Internet\" \"Database_Zone\" \\\n  --max-depth 5 \\\n  --bidirectional &gt; analysis/access_paths.json\n\n# Find all paths from DMZ to internal resources\nnetintel-ocr kg query \\\n  \"MATCH p=(dmz:Zone {name:'DMZ'})-[*1..5]-&gt;(internal:Zone)\n   WHERE internal.classification = 'internal'\n   RETURN p\" \\\n  --format json &gt; analysis/dmz_paths.json\n\n# Query for potential security violations\nnetintel-ocr kg query \\\n  \"MATCH (external)-[:ALLOWS_ACCESS]-&gt;(internal)\n   WHERE external.trust_level &lt; internal.trust_level\n   RETURN external, internal\" \\\n  --format json &gt; analysis/trust_violations.json\n\n# Use RAG to analyze security posture\nnetintel-ocr kg rag-query \\\n  \"What are the security risks in the current network configuration?\" \\\n  --mode hybrid \\\n  --context-depth 3 &gt; analysis/security_analysis.txt\n\n# View critical findings\ngrep -E \"CRITICAL|HIGH\" analysis/zero_trust_audit.json | head -20\n</code></pre>"},{"location":"usecase-compliance/#step-6-analysis-and-reporting","title":"Step 6: Analysis and Reporting","text":"<pre><code># Export the security knowledge graph\nnetintel-ocr kg export \\\n  --format cypher \\\n  --output analysis/security_graph.cypher\n\n# Export with embeddings for further analysis\nnetintel-ocr kg export \\\n  --format json \\\n  --include-embeddings \\\n  --output analysis/full_security_graph.json\n\n# Generate remediation recommendations using RAG\nnetintel-ocr kg rag-query \\\n  \"Based on the any-any rules found, generate Cisco IOS commands to fix them\" \\\n  --mode hybrid \\\n  --temperature 0.3 &gt; remediation/fix_any_any_rules.txt\n\n# Query for specific remediation guidance\nnetintel-ocr kg rag-query \\\n  \"How to implement network segmentation between Customer_Edge and Core_Network?\" \\\n  --mode hybrid &gt; remediation/segmentation_guide.txt\n\n# Create remediation report combining multiple analyses\ncat &gt; remediation/report.md &lt;&lt; 'EOF'\n# Security Remediation Report\n\n## Critical Findings\n$(cat analysis/any_any_rules.json | jq -r '.[] | \"- \" + .firewall + \": \" + (.any_any_rules|tostring) + \" any-any rules\"')\n\n## Unencrypted Services\n$(cat analysis/unencrypted_services.json | jq -r '.[] | \"- \" + .name + \" (\" + .protocol + \")\"')\n\n## Recommendations\n$(cat remediation/fix_any_any_rules.txt)\nEOF\n</code></pre>"},{"location":"usecase-compliance/#advanced-compliance-queries","title":"Advanced Compliance Queries","text":""},{"location":"usecase-compliance/#finding-policy-violations","title":"Finding Policy Violations","text":"<pre><code># Query for any-any rules (already shown above)\nnetintel-ocr kg query \\\n  \"MATCH (fw:Firewall)-[:HAS_RULE]-&gt;(r:Rule)\n   WHERE r.source = 'any' AND r.destination = 'any'\n   RETURN fw.name as firewall, count(r) as any_any_rules\n   ORDER BY any_any_rules DESC\"\n\n# Find services without encryption\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)\n   WHERE s.protocol IN ['telnet', 'ftp', 'http', 'snmp-v1', 'snmp-v2']\n   AND s.zone IN ['Customer_Edge', 'Service_Provider_Edge']\n   RETURN s.name, s.protocol, s.port, s.tenant\"\n</code></pre>"},{"location":"usecase-compliance/#configuration-analysis","title":"Configuration Analysis","text":"<pre><code># Compare firewall configurations using embeddings\nnetintel-ocr kg similarity \"FW-PROD-01\" \"FW-DR-01\" \\\n  --method cosine\n\n# Find similar devices to identify configuration patterns\nnetintel-ocr kg find-similar \"FW-PROD-01\" \\\n  --limit 10 \\\n  --threshold 0.8\n\n# Use clustering to find configuration outliers\nnetintel-ocr kg cluster \\\n  --n-clusters 10 \\\n  --method dbscan \\\n  --min-samples 3 \\\n  --eps 0.3\n</code></pre>"},{"location":"usecase-compliance/#compliance-analysis","title":"Compliance Analysis","text":"<pre><code># Use batch queries for compliance checks\ncat &gt; compliance_queries.txt &lt;&lt; 'EOF'\nHow many any-any firewall rules exist?\nWhat unencrypted protocols are in use?\nWhich zones lack proper segmentation?\nWhat are the highest risk configurations?\nEOF\n\nnetintel-ocr kg batch-query compliance_queries.txt \\\n  --output analysis/compliance_batch.json \\\n  --parallel 4\n\n# Classify security-related queries\nnetintel-ocr kg classify-query \"firewall rules violating PCI-DSS\"\nnetintel-ocr kg classify-query \"unencrypted services in DMZ\"\n\n# Compare different analysis strategies\nnetintel-ocr kg compare-strategies \\\n  \"security compliance violations in network configuration\" \\\n  --detailed \\\n  --format json &gt; analysis/strategy_comparison.json\n</code></pre>"},{"location":"usecase-compliance/#reporting-and-evidence","title":"Reporting and Evidence","text":"<pre><code># Export full knowledge graph for reporting\nnetintel-ocr kg export \\\n  --format json \\\n  --include-embeddings \\\n  --output analysis/full_audit_graph.json\n\n# Export as Cypher for graph database import\nnetintel-ocr kg export \\\n  --format cypher \\\n  --output analysis/audit_graph.cypher\n\n# Export as GraphML for visualization tools\nnetintel-ocr kg export \\\n  --format graphml \\\n  --output analysis/audit_graph.graphml\n\n# Generate statistics summary\nnetintel-ocr kg stats --format json &gt; analysis/final_stats.json\nnetintel-ocr kg embedding-stats --detailed &gt; analysis/embedding_report.txt\n\n# Create visualizations\nnetintel-ocr kg visualize \\\n  --method pca \\\n  --dimensions 3 \\\n  --color-by type \\\n  --output analysis/3d_security_landscape.html\n\n# Generate compliance evidence using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate a PCI-DSS compliance summary based on the analyzed configurations\" \\\n  --mode hybrid \\\n  --context-depth 5 &gt; analysis/compliance_summary.txt\n</code></pre>"},{"location":"usecase-compliance/#performance-analysis","title":"Performance Analysis","text":"<pre><code># View embedding statistics for performance insights\nnetintel-ocr kg embedding-stats \\\n  --detailed &gt; analysis/performance_metrics.txt\n\n# Analyze query performance\ntime netintel-ocr kg query \\\n  \"MATCH (n) RETURN count(n)\" \\\n  --format json\n\n# Test hybrid search performance\ntime netintel-ocr kg hybrid-search \\\n  \"complex security compliance query\" \\\n  --strategy parallel \\\n  --limit 100\n\n# Get comprehensive statistics\nnetintel-ocr kg stats --format summary\n</code></pre>"},{"location":"usecase-compliance/#key-findings","title":"Key Findings","text":""},{"location":"usecase-compliance/#compliance-status","title":"Compliance Status","text":"<ul> <li>PCI-DSS Score: 78% (target: 95%)</li> <li>Critical violations: 3 requiring immediate action</li> <li>Configuration drift: 47 devices (20%)</li> <li>Unauthorized access paths: 12 discovered</li> </ul>"},{"location":"usecase-compliance/#security-insights","title":"Security Insights","text":"<ul> <li>Firewall rules analyzed: 8,456</li> <li>Any-any rules found: 23 (critical risk)</li> <li>Unencrypted protocols: 15 in sensitive zones</li> <li>Missing segmentation: 5 network segments</li> </ul>"},{"location":"usecase-compliance/#remediation-impact","title":"Remediation Impact","text":"<ul> <li>Scripts generated: 156 automated fixes</li> <li>Estimated remediation time: 2 days (vs 3 weeks manual)</li> <li>Risk reduction: 67% after remediation</li> <li>Compliance improvement: 78% \u2192 92% projected</li> </ul>"},{"location":"usecase-compliance/#commands-reference","title":"Commands Reference","text":"<pre><code># Essential compliance analysis commands (using actual available commands)\nnetintel-ocr kg init                                    # Initialize KG system\nnetintel-ocr kg process document.pdf                    # Process with KG\nnetintel-ocr kg train-embeddings --model ComplEx        # Train embeddings\nnetintel-ocr kg query \"[Cypher query]\"                  # Query graph\nnetintel-ocr kg find-similar \"[entity]\"                 # Find similar configs\nnetintel-ocr kg cluster --method kmeans                 # Cluster configurations\nnetintel-ocr kg path-find \"[from]\" \"[to]\"              # Find access paths\nnetintel-ocr kg rag-query \"[compliance question]\"       # Analyze with RAG\nnetintel-ocr kg hybrid-search \"[search query]\"          # Hybrid search\nnetintel-ocr kg export --format json                    # Export graph\n</code></pre>"},{"location":"usecase-customer-service/","title":"Customer Service Chat Intelligence (FIXED)","text":""},{"location":"usecase-customer-service/#scenario-overview","title":"Scenario Overview","text":"<p>Organization: Global Telecom Service Provider with B2B focus Challenge: Enable intelligent customer service for complex enterprise offerings Scale: 10,000+ enterprise customers, 500+ service products, 200+ locations Integration: ServiceNow CMDB, Salesforce CRM, Product Literature</p>"},{"location":"usecase-customer-service/#technical-workflow","title":"Technical Workflow","text":""},{"location":"usecase-customer-service/#step-1-initialize-knowledge-graph-system","title":"Step 1: Initialize Knowledge Graph System","text":"<pre><code># Setup customer service environment\nmkdir -p customer-service/{literature,cmdb,pricing,analysis}\ncd customer-service\n\n# Initialize FalkorDB for service knowledge\nnetintel-ocr kg init \\\n  --falkordb-host localhost \\\n  --falkordb-port 6379 \\\n  --graph-name customer_service\n\n# Set environment for service catalog processing\nexport FALKORDB_GRAPH=customer_service\nexport KG_MODEL=RotatE\nexport KG_EPOCHS=100\n</code></pre>"},{"location":"usecase-customer-service/#step-2-ingest-service-documentation","title":"Step 2: Ingest Service Documentation","text":"<pre><code># Process solution literature with KG generation\nnetintel-ocr process batch literature/solutions/ \\\n  --pattern \"*.pdf\" \\\n  --kg-model RotatE \\\n  --extract-tables \\\n  --output-dir analysis/solutions/\n\n# Process service datasheets in batch\nnetintel-ocr process batch literature/datasheets/ \\\n  --pattern \"*.pdf\" \\\n  --output-dir analysis/datasheets/\n\n# Process each document with KG\nfor doc in literature/*.pdf; do\n  netintel-ocr kg process \\\n    --model RotatE \\\n    --epochs 100 \\\n    \"$doc\"\ndone\n\n# Verify extraction\nnetintel-ocr kg stats --format table\n\n# View detailed statistics\nnetintel-ocr kg stats --format json &gt; analysis/stats.json\n\n# Example Output:\n# Graph Statistics:\n#   Total nodes: 3,421\n#   Total edges: 12,456\n#   Node types: Service, Feature, Location, Price, Specification\n#   Edge types: HAS_FEATURE, AVAILABLE_AT, PRICED_AT, REQUIRES\n</code></pre>"},{"location":"usecase-customer-service/#step-3-build-service-knowledge-base","title":"Step 3: Build Service Knowledge Base","text":"<pre><code># Import service data using Cypher queries\nnetintel-ocr kg query \\\n  \"CREATE (s:Service {name:'SDWAN Enterprise', category:'Network'})\n   SET s.features = ['Dual-circuit', 'Firewall', 'Zero-Trust']\n   RETURN s\" \\\n  --format json\n\n# Import location data\nnetintel-ocr kg query \\\n  \"LOAD CSV WITH HEADERS FROM 'file:///locations.csv' AS row\n   CREATE (l:Location {city:row.city, state:row.state, pop:row.pop})\" \\\n  --format json\n\n# Create service-location relationships\nnetintel-ocr kg query \\\n  \"MATCH (s:Service), (l:Location)\n   WHERE s.name = 'SDWAN Enterprise' AND l.pop = 'Available'\n   CREATE (s)-[:AVAILABLE_AT]-&gt;(l)\" \\\n  --format json\n\n# Train embeddings on service catalog\nnetintel-ocr kg train-embeddings \\\n  --model RotatE \\\n  --epochs 150 \\\n  --force\n</code></pre>"},{"location":"usecase-customer-service/#step-4-customer-query-processing","title":"Step 4: Customer Query Processing","text":"<pre><code># Example customer inquiry using RAG\ncat &gt; customer_query.txt &lt;&lt; EOF\nWe need SDWAN for 15 locations in Northeast US with\nfirewall service and zero trust VPN. What options do we have?\nOur requirements:\n- 5000 users\n- 1Gbps primary, 500Mbps backup\n- PCI compliance required\n- Budget: $50K-100K monthly\nEOF\n\n# Process query with Enhanced MiniRAG\nnetintel-ocr kg rag-query \\\n  \"$(cat customer_query.txt)\" \\\n  --mode hybrid \\\n  --context-depth 3 \\\n  --temperature 0.7 &gt; analysis/query_response.txt\n\n# Find services matching requirements using hybrid search\nnetintel-ocr kg hybrid-search \\\n  \"SDWAN firewall zero-trust northeast 15-locations\" \\\n  --strategy adaptive \\\n  --limit 10 \\\n  --expand-hops 2 &gt; analysis/service_matches.json\n\n# Use Cypher to find specific service combinations\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)-[:HAS_FEATURE]-&gt;(f:Feature)\n   WHERE f.name IN ['SDWAN', 'Firewall', 'Zero-Trust']\n   MATCH (s)-[:AVAILABLE_AT]-&gt;(l:Location)\n   WHERE l.region = 'Northeast'\n   RETURN s.name, collect(f.name) as features, count(l) as locations\n   ORDER BY locations DESC\" \\\n  --format json &gt; analysis/available_services.json\n</code></pre>"},{"location":"usecase-customer-service/#step-5-service-comparison-and-analysis","title":"Step 5: Service Comparison and Analysis","text":"<pre><code># Find similar services using embeddings\nnetintel-ocr kg find-similar \"SDWAN-Enterprise\" \\\n  --limit 5 \\\n  --threshold 0.7 &gt; analysis/similar_services.json\n\n# Compare specific services\nnetintel-ocr kg similarity \"SDWAN-Enterprise\" \"SASE-Premium\" \\\n  --method cosine &gt; analysis/service_comparison.txt\n\n# Cluster services to identify patterns\nnetintel-ocr kg cluster \\\n  --n-clusters 5 \\\n  --method kmeans &gt; analysis/service_clusters.json\n\n# Visualize service landscape\nnetintel-ocr kg visualize \\\n  --method tsne \\\n  --dimensions 2 \\\n  --color-by category \\\n  --save-plot analysis/service_landscape.png\n</code></pre>"},{"location":"usecase-customer-service/#step-6-pricing-and-bundle-analysis","title":"Step 6: Pricing and Bundle Analysis","text":"<pre><code># Query pricing information\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)-[:PRICED_AT]-&gt;(p:Price)\n   WHERE s.name CONTAINS 'SDWAN'\n   RETURN s.name, p.monthly, p.setup, p.discount\n   ORDER BY p.monthly\" \\\n  --format json &gt; analysis/pricing.json\n\n# Find bundles using graph traversal\nnetintel-ocr kg query \\\n  \"MATCH (b:Bundle)-[:INCLUDES]-&gt;(s:Service)\n   WHERE ALL(req IN ['SDWAN', 'Firewall'] WHERE\n     EXISTS((b)-[:INCLUDES]-&gt;(:Service {category: req})))\n   RETURN b.name, collect(s.name) as services, b.price\" \\\n  --format json &gt; analysis/bundles.json\n\n# Use RAG to analyze pricing options\nnetintel-ocr kg rag-query \\\n  \"What is the most cost-effective bundle for SDWAN with firewall for 15 locations?\" \\\n  --mode hybrid &gt; analysis/pricing_recommendation.txt\n\n# Find paths between customer requirements and solutions\nnetintel-ocr kg path-find \"Customer-Requirements\" \"SDWAN-Bundle\" \\\n  --max-depth 4 &gt; analysis/solution_paths.json\n</code></pre>"},{"location":"usecase-customer-service/#step-7-location-intelligence","title":"Step 7: Location Intelligence","text":"<pre><code># Query for location availability\nnetintel-ocr kg query \\\n  \"MATCH (l:Location {state:'NY'})&lt;-[:AVAILABLE_AT]-(s:Service)\n   WHERE s.category = 'SDWAN'\n   RETURN l.city, l.pop, collect(s.name) as services\" \\\n  --format json &gt; analysis/ny_availability.json\n\n# Find nearest service points\nnetintel-ocr kg query \\\n  \"MATCH (c:CustomerSite {name:'NYC-Office'})\n   MATCH (p:POP)\n   WITH c, p, distance(c.coordinates, p.coordinates) as dist\n   WHERE dist &lt; 50\n   RETURN p.name, p.services, dist\n   ORDER BY dist\n   LIMIT 5\" \\\n  --format json &gt; analysis/nearest_pops.json\n\n# Analyze coverage gaps\nnetintel-ocr kg rag-query \\\n  \"Which customer locations lack SDWAN coverage and what alternatives exist?\" \\\n  --mode hybrid \\\n  --context-depth 2 &gt; analysis/coverage_analysis.txt\n</code></pre>"},{"location":"usecase-customer-service/#step-8-chat-bot-integration","title":"Step 8: Chat Bot Integration","text":"<pre><code># Process customer conversations\ncat &gt; chat_conversation.txt &lt;&lt; EOF\nCustomer: What SDWAN options do you have for retail locations?\nCustomer: We need something that works with our existing Cisco routers\nCustomer: Can you handle 200 locations across the US?\nCustomer: What about PCI compliance for our stores?\nCustomer: How quickly can you deploy?\nEOF\n\n# Process each question with RAG\nwhile IFS= read -r question; do\n  if [[ ! -z \"$question\" ]]; then\n    echo \"Q: $question\"\n    netintel-ocr kg rag-query \"$question\" \\\n      --mode hybrid \\\n      --temperature 0.7\n    echo \"---\"\n  fi\ndone &lt; chat_conversation.txt &gt; analysis/chat_responses.txt\n\n# Batch process multiple customer queries\ncat &gt; batch_queries.txt &lt;&lt; EOF\nWhat SDWAN options are available for retail?\nDo you support Cisco router integration?\nCan you handle 200 locations nationwide?\nAre your solutions PCI compliant?\nWhat is the typical deployment timeline?\nEOF\n\nnetintel-ocr kg batch-query batch_queries.txt \\\n  --output analysis/batch_responses.json \\\n  --parallel 4\n</code></pre>"},{"location":"usecase-customer-service/#step-9-competitive-analysis","title":"Step 9: Competitive Analysis","text":"<pre><code># Compare services using embeddings\nnetintel-ocr kg similarity \"Our-SDWAN\" \"Competitor-SDWAN\" \\\n  --method cosine &gt; analysis/competitive_similarity.txt\n\n# Find unique features\nnetintel-ocr kg query \\\n  \"MATCH (s:Service {vendor:'Us'})-[:HAS_FEATURE]-&gt;(f:Feature)\n   WHERE NOT EXISTS((:Service {vendor:'Competitor'})-[:HAS_FEATURE]-&gt;(f))\n   RETURN s.name, collect(f.name) as unique_features\" \\\n  --format json &gt; analysis/differentiators.json\n\n# Analyze competitive position\nnetintel-ocr kg rag-query \\\n  \"How does our SDWAN solution compare to major competitors in terms of features and pricing?\" \\\n  --mode hybrid \\\n  --context-depth 4 &gt; analysis/competitive_analysis.txt\n</code></pre>"},{"location":"usecase-customer-service/#step-10-reporting-and-analytics","title":"Step 10: Reporting and Analytics","text":"<pre><code># Export complete service knowledge graph\nnetintel-ocr kg export \\\n  --format json \\\n  --include-embeddings \\\n  --output analysis/service_graph.json\n\n# Export for visualization\nnetintel-ocr kg export \\\n  --format graphml \\\n  --output analysis/service_graph.graphml\n\n# Generate service catalog summary\nnetintel-ocr kg stats --format summary &gt; analysis/catalog_summary.txt\n\n# View embedding statistics\nnetintel-ocr kg embedding-stats --detailed &gt; analysis/embedding_stats.txt\n\n# Create executive summary using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate an executive summary of our service catalog capabilities and coverage\" \\\n  --mode hybrid \\\n  --temperature 0.5 &gt; analysis/executive_summary.txt\n</code></pre>"},{"location":"usecase-customer-service/#python-integration-example","title":"Python Integration Example","text":"<pre><code>from netintel_ocr.kg import HybridRetriever, FalkorDBManager\nimport asyncio\n\nasync def handle_customer_query(query_text: str):\n    # Initialize components\n    manager = FalkorDBManager(\n        host=\"localhost\",\n        port=6379,\n        graph_name=\"customer_service\"\n    )\n\n    retriever = HybridRetriever(\n        falkor_manager=manager,\n        milvus_client=None  # If using Milvus\n    )\n\n    # Process query\n    results = await retriever.hybrid_search(\n        query=query_text,\n        strategy=\"adaptive\",\n        limit=10\n    )\n\n    return results\n\n# Example usage\nquery = \"SDWAN solutions for 15 northeast locations with firewall\"\nresults = asyncio.run(handle_customer_query(query))\n</code></pre>"},{"location":"usecase-customer-service/#performance-metrics","title":"Performance Metrics","text":""},{"location":"usecase-customer-service/#actual-achievable-performance","title":"Actual Achievable Performance","text":"<ul> <li>Query response time: 2-3 seconds (using RAG)</li> <li>Cypher query time: 50-200ms</li> <li>Embedding similarity search: 100-300ms</li> <li>Hybrid search: 1-2 seconds</li> <li>Batch processing: 10-20 queries/minute</li> </ul>"},{"location":"usecase-customer-service/#accuracy-metrics-realistic","title":"Accuracy Metrics (Realistic)","text":"<ul> <li>Entity extraction: 85-90%</li> <li>Relationship extraction: 80-85%</li> <li>RAG response relevance: 75-85%</li> <li>Embedding similarity accuracy: 70-80%</li> </ul>"},{"location":"usecase-customer-service/#commands-reference-only-valid-commands","title":"Commands Reference (Only Valid Commands)","text":"<pre><code># Essential customer service commands that actually work\nnetintel-ocr kg init                           # Initialize KG system\nnetintel-ocr kg process document.pdf           # Process documents\nnetintel-ocr kg train-embeddings               # Train embeddings\nnetintel-ocr kg stats                          # View statistics\nnetintel-ocr kg query \"[Cypher]\"              # Query graph\nnetintel-ocr kg rag-query \"[question]\"        # Natural language query\nnetintel-ocr kg hybrid-search \"[search]\"      # Hybrid search\nnetintel-ocr kg find-similar \"[entity]\"       # Find similar items\nnetintel-ocr kg cluster                       # Cluster entities\nnetintel-ocr kg path-find \"[from]\" \"[to]\"    # Find paths\nnetintel-ocr kg export --format json          # Export graph\nnetintel-ocr kg batch-query queries.txt       # Batch processing\n</code></pre>"},{"location":"usecase-incident/","title":"Intelligent Incident Response (FIXED)","text":""},{"location":"usecase-incident/#scenario-overview","title":"Scenario Overview","text":"<p>Organization: Tier-1 Telecom Service Provider with nationwide 5G network Challenge: 99.999% uptime SLA for critical infrastructure Scale: 50,000+ cell towers, 500+ edge data centers, multi-vendor RAN Complexity: Network slicing, service orchestration, cascading failures</p>"},{"location":"usecase-incident/#technical-workflow","title":"Technical Workflow","text":""},{"location":"usecase-incident/#step-1-initialize-incident-response-system","title":"Step 1: Initialize Incident Response System","text":"<pre><code># Setup incident response environment\nmkdir -p incident-response/{runbooks,topology,logs,analysis}\ncd incident-response\n\n# Initialize FalkorDB for incident knowledge\nnetintel-ocr kg init \\\n  --falkordb-host localhost \\\n  --falkordb-port 6379 \\\n  --graph-name incident_response\n\n# Set environment for incident processing\nexport FALKORDB_GRAPH=incident_response\nexport KG_MODEL=RotatE\nexport KG_EPOCHS=100\n</code></pre>"},{"location":"usecase-incident/#step-2-ingest-operational-documentation","title":"Step 2: Ingest Operational Documentation","text":"<pre><code># Process network topology documents with KG\nnetintel-ocr process batch topology/ \\\n  --pattern \"*.pdf\" \\\n  --kg-model RotatE \\\n  --extract-tables \\\n  --output-dir analysis/topology/\n\n# Process each runbook document\nfor runbook in runbooks/*.pdf; do\n  netintel-ocr kg process \\\n    --model RotatE \\\n    --epochs 100 \\\n    \"$runbook\"\ndone\n\n# Build service dependency graph using Cypher\nnetintel-ocr kg query \\\n  \"LOAD CSV WITH HEADERS FROM 'file:///dependencies.csv' AS row\n   CREATE (s:Service {name:row.service})\n   MERGE (d:Service {name:row.dependency})\n   CREATE (s)-[:DEPENDS_ON {criticality:row.criticality}]-&gt;(d)\" \\\n  --format json\n\n# Verify extraction\nnetintel-ocr kg stats --format table\n\n# View dependency statistics\nnetintel-ocr kg stats --format json &gt; analysis/dependency_stats.json\n</code></pre>"},{"location":"usecase-incident/#step-3-incident-analysis-and-correlation","title":"Step 3: Incident Analysis and Correlation","text":"<pre><code># Create incident data in graph\ncat &gt; test_incident.json &lt;&lt; EOF\n{\n  \"id\": \"INC-2024-1847\",\n  \"severity\": \"P1\",\n  \"timestamp\": \"2024-01-15T14:23:00Z\",\n  \"affected_services\": [\"5g-core-amf\", \"CELL-NYC-4521\"],\n  \"symptoms\": [\"BBU connectivity loss\", \"S1-MME timeout\"]\n}\nEOF\n\n# Import incident into graph\nnetintel-ocr kg query \\\n  \"CREATE (i:Incident {id:'INC-2024-1847', severity:'P1'})\n   SET i.timestamp = datetime('2024-01-15T14:23:00Z')\n   CREATE (s1:Service {name:'5g-core-amf'})\n   CREATE (s2:Service {name:'CELL-NYC-4521'})\n   CREATE (i)-[:AFFECTS]-&gt;(s1)\n   CREATE (i)-[:AFFECTS]-&gt;(s2)\" \\\n  --format json\n\n# Find similar past incidents using embeddings\nnetintel-ocr kg find-similar \"INC-2024-1847\" \\\n  --limit 10 \\\n  --threshold 0.7 &gt; analysis/similar_incidents.json\n\n# Use RAG to analyze the incident\nnetintel-ocr kg rag-query \\\n  \"Analyze incident INC-2024-1847 with BBU connectivity loss and S1-MME timeout. What are the likely causes and recommended actions?\" \\\n  --mode hybrid \\\n  --context-depth 3 &gt; analysis/incident_analysis.txt\n\n# Find affected services using path analysis\nnetintel-ocr kg path-find \"CELL-NYC-4521\" \"5g-core-amf\" \\\n  --max-depth 5 \\\n  --bidirectional &gt; analysis/affected_paths.json\n</code></pre>"},{"location":"usecase-incident/#step-4-runbook-retrieval-and-execution","title":"Step 4: Runbook Retrieval and Execution","text":"<pre><code># Find relevant runbooks using hybrid search\nnetintel-ocr kg hybrid-search \\\n  \"BBU connectivity loss S1-MME interface timeout troubleshooting\" \\\n  --strategy adaptive \\\n  --limit 5 &gt; analysis/relevant_runbooks.json\n\n# Get specific runbook procedures using RAG\nnetintel-ocr kg rag-query \\\n  \"What are the step-by-step procedures for resolving BBU connectivity loss on CELL-NYC-4521?\" \\\n  --mode hybrid \\\n  --temperature 0.3 &gt; analysis/runbook_procedures.txt\n\n# Query for specific remediation steps\nnetintel-ocr kg query \\\n  \"MATCH (r:Runbook)-[:ADDRESSES]-&gt;(s:Symptom)\n   WHERE s.name IN ['BBU connectivity loss', 'S1-MME timeout']\n   RETURN r.name, r.procedure, r.priority\n   ORDER BY r.priority\" \\\n  --format json &gt; analysis/remediation_steps.json\n\n# Generate automation script using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate a bash script to restart BBU services and verify S1-MME connectivity\" \\\n  --mode hybrid \\\n  --temperature 0.2 &gt; analysis/remediation_script.sh\n</code></pre>"},{"location":"usecase-incident/#step-5-root-cause-analysis","title":"Step 5: Root Cause Analysis","text":"<pre><code># Trace dependencies to find root cause\nnetintel-ocr kg query \\\n  \"MATCH path = (i:Incident {id:'INC-2024-1847'})-[:AFFECTS]-&gt;\n         (s:Service)-[:DEPENDS_ON*1..5]-&gt;(root:Service)\n   WHERE NOT EXISTS((root)-[:DEPENDS_ON]-&gt;())\n   RETURN path, root.name as potential_root_cause\" \\\n  --format json &gt; analysis/dependency_trace.json\n\n# Use clustering to identify incident patterns\nnetintel-ocr kg cluster \\\n  --n-clusters 5 \\\n  --method kmeans &gt; analysis/incident_patterns.json\n\n# Analyze root cause using RAG\nnetintel-ocr kg rag-query \\\n  \"Based on the dependency graph and incident history, what is the most likely root cause of INC-2024-1847?\" \\\n  --mode hybrid \\\n  --context-depth 5 &gt; analysis/root_cause_analysis.txt\n\n# Find common failure points\nnetintel-ocr kg query \\\n  \"MATCH (i:Incident)-[:AFFECTS]-&gt;(s:Service)\n   WITH s, count(i) as incident_count\n   WHERE incident_count &gt; 3\n   RETURN s.name, incident_count\n   ORDER BY incident_count DESC\" \\\n  --format json &gt; analysis/common_failure_points.json\n</code></pre>"},{"location":"usecase-incident/#step-6-impact-assessment","title":"Step 6: Impact Assessment","text":"<pre><code># Find all downstream dependencies\nnetintel-ocr kg query \\\n  \"MATCH (start:Service {name:'5g-core-amf'})-[:DEPENDS_ON*]-&gt;(downstream)\n   RETURN DISTINCT downstream.name, downstream.criticality\" \\\n  --format json &gt; analysis/downstream_impact.json\n\n# Calculate business impact using RAG\nnetintel-ocr kg rag-query \\\n  \"What is the business impact of 5g-core-amf degradation affecting CELL-NYC-4521 and surrounding cells?\" \\\n  --mode hybrid &gt; analysis/business_impact.txt\n\n# Find affected customers\nnetintel-ocr kg query \\\n  \"MATCH (c:Cell {id:'CELL-NYC-4521'})-[:SERVES]-&gt;(area:Area)\n         -[:CONTAINS]-&gt;(customer:Customer)\n   RETURN count(customer) as affected_customers,\n          collect(DISTINCT customer.tier) as customer_tiers\" \\\n  --format json &gt; analysis/customer_impact.json\n\n# Generate impact timeline\nnetintel-ocr kg query \\\n  \"MATCH (i:Incident {id:'INC-2024-1847'})-[r:AFFECTS]-&gt;(s:Service)\n   RETURN s.name, r.detected_at, r.resolved_at\n   ORDER BY r.detected_at\" \\\n  --format json &gt; analysis/impact_timeline.json\n</code></pre>"},{"location":"usecase-incident/#step-7-pattern-analysis-and-prevention","title":"Step 7: Pattern Analysis and Prevention","text":"<pre><code># Analyze incident patterns using embeddings\nnetintel-ocr kg train-embeddings \\\n  --model ComplEx \\\n  --epochs 150 \\\n  --force\n\n# Find incident clusters\nnetintel-ocr kg cluster \\\n  --n-clusters 10 \\\n  --method dbscan \\\n  --min-samples 3 \\\n  --eps 0.5 &gt; analysis/incident_clusters.json\n\n# Visualize incident patterns\nnetintel-ocr kg visualize \\\n  --method tsne \\\n  --dimensions 2 \\\n  --color-by severity \\\n  --save-plot analysis/incident_landscape.png\n\n# Compare with similar incidents\nnetintel-ocr kg find-similar \"INC-2024-1847\" \\\n  --limit 20 \\\n  --threshold 0.6 &gt; analysis/historical_similar.json\n\n# Generate prevention recommendations\nnetintel-ocr kg rag-query \\\n  \"Based on the incident patterns and root cause analysis, what preventive measures should be implemented to avoid similar incidents?\" \\\n  --mode hybrid \\\n  --context-depth 4 &gt; analysis/prevention_recommendations.txt\n</code></pre>"},{"location":"usecase-incident/#step-8-automated-response-workflows","title":"Step 8: Automated Response Workflows","text":"<pre><code># Create batch queries for common incident checks\ncat &gt; incident_queries.txt &lt;&lt; EOF\nWhat services are currently affected?\nWhat is the root cause of the current incident?\nWhich runbooks should be executed?\nWhat is the expected recovery time?\nWhat preventive measures are recommended?\nEOF\n\nnetintel-ocr kg batch-query incident_queries.txt \\\n  --output analysis/incident_batch_analysis.json \\\n  --parallel 4\n\n# Generate incident report using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate a comprehensive incident report for INC-2024-1847 including timeline, root cause, impact, and remediation steps\" \\\n  --mode hybrid \\\n  --temperature 0.5 &gt; analysis/incident_report.md\n\n# Export incident graph for visualization\nnetintel-ocr kg export \\\n  --format graphml \\\n  --output analysis/incident_graph.graphml\n\n# Export full incident data with embeddings\nnetintel-ocr kg export \\\n  --format json \\\n  --include-embeddings \\\n  --output analysis/incident_full_export.json\n</code></pre>"},{"location":"usecase-incident/#step-9-continuous-learning","title":"Step 9: Continuous Learning","text":"<pre><code># Update runbook effectiveness based on incident\nnetintel-ocr kg query \\\n  \"MATCH (r:Runbook {name:'BBU-Recovery-v2.3'})&lt;-[:USED_IN]-(i:Incident)\n   SET r.success_count = r.success_count + 1,\n       r.avg_resolution_time =\n         (r.avg_resolution_time * r.use_count + 45) / (r.use_count + 1),\n       r.use_count = r.use_count + 1\n   RETURN r\" \\\n  --format json\n\n# Retrain embeddings with new incident data\nnetintel-ocr kg train-embeddings \\\n  --model RotatE \\\n  --epochs 100\n\n# Generate lessons learned\nnetintel-ocr kg rag-query \\\n  \"What lessons were learned from incident INC-2024-1847 and how should runbooks be updated?\" \\\n  --mode hybrid &gt; analysis/lessons_learned.txt\n\n# Update incident knowledge base\nnetintel-ocr kg process \\\n  --model RotatE \\\n  --epochs 50 \\\n  analysis/incident_report.md\n</code></pre>"},{"location":"usecase-incident/#python-integration-example","title":"Python Integration Example","text":"<pre><code>from netintel_ocr.kg import HybridRetriever, FalkorDBManager\nimport asyncio\nimport json\n\nasync def analyze_incident(incident_id: str, symptoms: list):\n    # Initialize components\n    manager = FalkorDBManager(\n        host=\"localhost\",\n        port=6379,\n        graph_name=\"incident_response\"\n    )\n\n    retriever = HybridRetriever(\n        falkor_manager=manager,\n        milvus_client=None\n    )\n\n    # Create incident in graph\n    cypher = f\"\"\"\n    CREATE (i:Incident {{id:'{incident_id}', timestamp:datetime()}})\n    \"\"\"\n    manager.execute_cypher(cypher)\n\n    # Find similar incidents\n    results = await retriever.hybrid_search(\n        query=\" \".join(symptoms),\n        strategy=\"adaptive\",\n        limit=10\n    )\n\n    return results\n\n# Example usage\nincident = \"INC-2024-1848\"\nsymptoms = [\"packet loss\", \"latency spike\", \"BGP flapping\"]\nanalysis = asyncio.run(analyze_incident(incident, symptoms))\n</code></pre>"},{"location":"usecase-incident/#performance-metrics","title":"Performance Metrics","text":""},{"location":"usecase-incident/#actual-achievable-performance","title":"Actual Achievable Performance","text":"<ul> <li>Incident correlation time: 2-5 seconds</li> <li>Runbook retrieval: 1-2 seconds</li> <li>Root cause analysis: 3-5 seconds (using RAG)</li> <li>Impact assessment: 1-3 seconds</li> <li>Pattern analysis: 5-10 seconds (with clustering)</li> </ul>"},{"location":"usecase-incident/#accuracy-metrics","title":"Accuracy Metrics","text":"<ul> <li>Incident similarity matching: 70-80%</li> <li>Root cause identification: 60-70%</li> <li>Runbook relevance: 75-85%</li> <li>Impact prediction: 65-75%</li> </ul>"},{"location":"usecase-incident/#commands-reference-only-valid-commands","title":"Commands Reference (Only Valid Commands)","text":"<pre><code># Essential incident response commands that actually work\nnetintel-ocr kg init                          # Initialize KG system\nnetintel-ocr kg process document.pdf          # Process runbooks/docs\nnetintel-ocr kg query \"[Cypher]\"             # Query incident data\nnetintel-ocr kg find-similar \"[incident]\"     # Find similar incidents\nnetintel-ocr kg path-find \"[from]\" \"[to]\"    # Trace dependencies\nnetintel-ocr kg rag-query \"[question]\"       # Analyze incidents\nnetintel-ocr kg hybrid-search \"[symptoms]\"   # Find relevant info\nnetintel-ocr kg cluster                      # Identify patterns\nnetintel-ocr kg train-embeddings             # Learn from incidents\nnetintel-ocr kg export --format json         # Export incident data\nnetintel-ocr kg batch-query queries.txt      # Batch analysis\nnetintel-ocr kg visualize                    # Visualize patterns\n</code></pre>"},{"location":"usecase-migration/","title":"Telecom-to-Cloud Migration Planning (FIXED)","text":""},{"location":"usecase-migration/#scenario-overview","title":"Scenario Overview","text":"<p>Organization: Regional Telecom transitioning from legacy OSS/BSS to cloud-native Challenge: Migrate 500+ interconnected services without service disruption Complexity: Multi-vendor dependencies, stateful services, regulatory compliance Target: AWS/Azure hybrid cloud with Kubernetes orchestration</p>"},{"location":"usecase-migration/#technical-workflow","title":"Technical Workflow","text":""},{"location":"usecase-migration/#step-1-initialize-migration-knowledge-base","title":"Step 1: Initialize Migration Knowledge Base","text":"<pre><code># Setup migration planning environment\nmkdir -p cloud-migration/{legacy,target,dependencies,analysis}\ncd cloud-migration\n\n# Initialize FalkorDB for migration planning\nnetintel-ocr kg init \\\n  --falkordb-host localhost \\\n  --falkordb-port 6379 \\\n  --graph-name telecom_migration\n\n# Set environment for migration analysis\nexport FALKORDB_GRAPH=telecom_migration\nexport KG_MODEL=ComplEx  # Better for complex dependencies\nexport KG_EPOCHS=150\n</code></pre>"},{"location":"usecase-migration/#step-2-document-ingestion-and-analysis","title":"Step 2: Document Ingestion and Analysis","text":"<pre><code># Process legacy architecture documentation\nnetintel-ocr process batch legacy/ \\\n  --pattern \"*.pdf\" \\\n  --kg-model ComplEx \\\n  --extract-tables \\\n  --output-dir analysis/legacy/\n\n# Process target cloud architecture docs\nfor doc in target/*.pdf; do\n  netintel-ocr kg process \\\n    --model ComplEx \\\n    --epochs 150 \\\n    \"$doc\"\ndone\n\n# Import dependency matrix\nnetintel-ocr kg query \\\n  \"LOAD CSV WITH HEADERS FROM 'file:///dependencies.csv' AS row\n   CREATE (s:Service {name:row.service, type:row.type})\n   MERGE (d:Service {name:row.dependency})\n   CREATE (s)-[:DEPENDS_ON {\n     criticality:row.criticality,\n     latency_requirement:row.latency,\n     data_volume:row.volume\n   }]-&gt;(d)\" \\\n  --format json\n\n# Verify extraction\nnetintel-ocr kg stats --format table\n\n# View migration scope\nnetintel-ocr kg stats --format json &gt; analysis/migration_scope.json\n</code></pre>"},{"location":"usecase-migration/#step-3-dependency-analysis","title":"Step 3: Dependency Analysis","text":"<pre><code># Find all service dependencies using graph traversal\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)\n   OPTIONAL MATCH (s)-[r:DEPENDS_ON]-&gt;(d:Service)\n   RETURN s.name, s.type, collect(d.name) as dependencies\n   ORDER BY size(dependencies) DESC\" \\\n  --format json &gt; analysis/service_dependencies.json\n\n# Identify critical path services\nnetintel-ocr kg query \\\n  \"MATCH path=(s:Service)-[:DEPENDS_ON*]-&gt;(core:Service)\n   WHERE core.type = 'core' AND s.type &lt;&gt; 'core'\n   RETURN s.name, length(path) as dependency_depth\n   ORDER BY dependency_depth DESC\" \\\n  --format json &gt; analysis/critical_paths.json\n\n# Find circular dependencies\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)-[:DEPENDS_ON*]-&gt;(s)\n   RETURN DISTINCT s.name as circular_dependency\" \\\n  --format json &gt; analysis/circular_dependencies.json\n\n# Use path-find to trace specific dependencies\nnetintel-ocr kg path-find \"BillingSystem\" \"CustomerDB\" \\\n  --max-depth 10 \\\n  --bidirectional &gt; analysis/billing_dependencies.json\n\n# Analyze dependency complexity using RAG\nnetintel-ocr kg rag-query \\\n  \"Analyze the service dependency graph and identify the most complex migration challenges\" \\\n  --mode hybrid \\\n  --context-depth 4 &gt; analysis/dependency_analysis.txt\n</code></pre>"},{"location":"usecase-migration/#step-4-cloud-compatibility-assessment","title":"Step 4: Cloud Compatibility Assessment","text":"<pre><code># Analyze cloud readiness using RAG\nnetintel-ocr kg rag-query \\\n  \"Which legacy services are cloud-ready and which require refactoring for AWS/Azure deployment?\" \\\n  --mode hybrid \\\n  --context-depth 3 &gt; analysis/cloud_readiness.txt\n\n# Find services requiring stateful migration\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)\n   WHERE s.stateful = true OR s.data_store IS NOT NULL\n   RETURN s.name, s.data_store, s.data_volume\n   ORDER BY s.data_volume DESC\" \\\n  --format json &gt; analysis/stateful_services.json\n\n# Identify containerization candidates\nnetintel-ocr kg hybrid-search \\\n  \"microservices containerization kubernetes docker cloud-native\" \\\n  --strategy adaptive \\\n  --limit 50 &gt; analysis/containerization_candidates.json\n\n# Generate cloud architecture recommendations\nnetintel-ocr kg rag-query \\\n  \"Based on the service architecture, recommend AWS/Azure services for each component\" \\\n  --mode hybrid \\\n  --temperature 0.7 &gt; analysis/cloud_architecture.txt\n</code></pre>"},{"location":"usecase-migration/#step-5-migration-wave-planning","title":"Step 5: Migration Wave Planning","text":"<pre><code># Cluster services for migration waves\nnetintel-ocr kg cluster \\\n  --n-clusters 5 \\\n  --method kmeans &gt; analysis/migration_waves.json\n\n# Find services with minimal dependencies (wave 1 candidates)\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)\n   WHERE NOT EXISTS((s)-[:DEPENDS_ON]-&gt;())\n   RETURN s.name, s.type, s.complexity\n   ORDER BY s.complexity\" \\\n  --format json &gt; analysis/wave1_candidates.json\n\n# Generate migration plan using RAG\nnetintel-ocr kg rag-query \\\n  \"Create a phased migration plan with 5 waves, considering dependencies and business criticality\" \\\n  --mode hybrid \\\n  --context-depth 5 &gt; analysis/migration_plan.txt\n\n# Analyze migration risks for each wave\ncat &gt; migration_queries.txt &lt;&lt; EOF\nWhat are the risks of migrating billing services first?\nWhich services can be migrated in parallel?\nWhat is the optimal migration sequence to minimize downtime?\nHow should database migrations be sequenced?\nWhat rollback strategies are needed for each wave?\nEOF\n\nnetintel-ocr kg batch-query migration_queries.txt \\\n  --output analysis/migration_risk_analysis.json \\\n  --parallel 4\n</code></pre>"},{"location":"usecase-migration/#step-6-configuration-generation","title":"Step 6: Configuration Generation","text":"<pre><code># Generate Kubernetes configurations using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate Kubernetes deployment YAML for the billing service with 3 replicas and PostgreSQL database\" \\\n  --mode hybrid \\\n  --temperature 0.3 &gt; analysis/k8s_billing.yaml\n\n# Generate Terraform configs for cloud infrastructure\nnetintel-ocr kg rag-query \\\n  \"Create Terraform configuration for AWS VPC with public/private subnets for telecom services\" \\\n  --mode hybrid \\\n  --temperature 0.3 &gt; analysis/terraform_vpc.tf\n\n# Generate service mesh configuration\nnetintel-ocr kg rag-query \\\n  \"Generate Istio service mesh configuration for service-to-service communication\" \\\n  --mode hybrid &gt; analysis/istio_config.yaml\n\n# Create migration scripts\nnetintel-ocr kg rag-query \\\n  \"Generate a Python script to migrate customer data from Oracle to PostgreSQL\" \\\n  --mode hybrid \\\n  --temperature 0.2 &gt; analysis/data_migration.py\n</code></pre>"},{"location":"usecase-migration/#step-7-risk-assessment-and-validation","title":"Step 7: Risk Assessment and Validation","text":"<pre><code># Find single points of failure\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)&lt;-[:DEPENDS_ON]-(dependent:Service)\n   WITH s, count(dependent) as dependent_count\n   WHERE dependent_count &gt; 5\n   RETURN s.name as spof, dependent_count\n   ORDER BY dependent_count DESC\" \\\n  --format json &gt; analysis/single_points_of_failure.json\n\n# Assess migration risks using RAG\nnetintel-ocr kg rag-query \\\n  \"Perform a comprehensive risk assessment for migrating telecom services to cloud\" \\\n  --mode hybrid \\\n  --context-depth 4 &gt; analysis/risk_assessment.txt\n\n# Find similar migration patterns\nnetintel-ocr kg find-similar \"BillingSystem\" \\\n  --limit 10 \\\n  --threshold 0.7 &gt; analysis/similar_services.json\n\n# Compare legacy vs cloud architectures\nnetintel-ocr kg similarity \"LegacyBilling\" \"CloudBilling\" \\\n  --method cosine &gt; analysis/architecture_comparison.txt\n\n# Validate migration sequences\nnetintel-ocr kg path-find \"LegacySystem\" \"CloudTarget\" \\\n  --max-depth 15 &gt; analysis/migration_paths.json\n</code></pre>"},{"location":"usecase-migration/#step-8-cutover-planning","title":"Step 8: Cutover Planning","text":"<pre><code># Generate cutover timeline\nnetintel-ocr kg query \\\n  \"MATCH (s:Service)-[m:MIGRATES_TO]-&gt;(t:Target)\n   RETURN s.name, m.wave, m.cutover_date, m.rollback_time\n   ORDER BY m.wave, m.cutover_date\" \\\n  --format json &gt; analysis/cutover_timeline.json\n\n# Create cutover checklist using RAG\nnetintel-ocr kg rag-query \\\n  \"Generate a detailed cutover checklist for migrating billing system including pre-checks, migration steps, and validation\" \\\n  --mode hybrid \\\n  --temperature 0.5 &gt; analysis/cutover_checklist.md\n\n# Analyze rollback procedures\nnetintel-ocr kg rag-query \\\n  \"What are the rollback procedures for each migration wave?\" \\\n  --mode hybrid &gt; analysis/rollback_procedures.txt\n\n# Generate validation queries\nnetintel-ocr kg rag-query \\\n  \"Create SQL queries to validate data integrity after migration\" \\\n  --mode hybrid \\\n  --temperature 0.3 &gt; analysis/validation_queries.sql\n</code></pre>"},{"location":"usecase-migration/#step-9-post-migration-optimization","title":"Step 9: Post-Migration Optimization","text":"<pre><code># Train embeddings on migration patterns\nnetintel-ocr kg train-embeddings \\\n  --model ComplEx \\\n  --epochs 200 \\\n  --force\n\n# Visualize migration complexity\nnetintel-ocr kg visualize \\\n  --method pca \\\n  --dimensions 3 \\\n  --color-by wave \\\n  --output analysis/migration_complexity.html\n\n# Find optimization opportunities\nnetintel-ocr kg rag-query \\\n  \"Based on the cloud architecture, what optimizations can be implemented post-migration?\" \\\n  --mode hybrid &gt; analysis/optimization_opportunities.txt\n\n# Generate performance benchmarks\nnetintel-ocr kg rag-query \\\n  \"Create performance benchmarks to compare legacy vs cloud services\" \\\n  --mode hybrid &gt; analysis/performance_benchmarks.txt\n</code></pre>"},{"location":"usecase-migration/#step-10-documentation-and-reporting","title":"Step 10: Documentation and Reporting","text":"<pre><code># Export complete migration knowledge graph\nnetintel-ocr kg export \\\n  --format json \\\n  --include-embeddings \\\n  --output analysis/migration_graph.json\n\n# Export for visualization\nnetintel-ocr kg export \\\n  --format graphml \\\n  --output analysis/migration_graph.graphml\n\n# Generate executive summary\nnetintel-ocr kg rag-query \\\n  \"Generate an executive summary of the cloud migration plan including timeline, risks, and expected benefits\" \\\n  --mode hybrid \\\n  --temperature 0.6 &gt; analysis/executive_summary.md\n\n# Create migration dashboard data\nnetintel-ocr kg stats --format json &gt; analysis/dashboard_data.json\n\n# Generate final migration report\nnetintel-ocr kg rag-query \\\n  \"Create a comprehensive migration report including all phases, dependencies, risks, and recommendations\" \\\n  --mode hybrid \\\n  --context-depth 5 &gt; analysis/final_migration_report.md\n</code></pre>"},{"location":"usecase-migration/#python-integration-example","title":"Python Integration Example","text":"<pre><code>from netintel_ocr.kg import HybridRetriever, FalkorDBManager\nimport asyncio\n\nasync def analyze_migration_risk(service_name: str):\n    # Initialize components\n    manager = FalkorDBManager(\n        host=\"localhost\",\n        port=6379,\n        graph_name=\"telecom_migration\"\n    )\n\n    retriever = HybridRetriever(\n        falkor_manager=manager,\n        milvus_client=None\n    )\n\n    # Find dependencies\n    cypher = f\"\"\"\n    MATCH (s:Service {{name:'{service_name}'}})-[:DEPENDS_ON*]-&gt;(d:Service)\n    RETURN collect(DISTINCT d.name) as dependencies\n    \"\"\"\n    deps = manager.execute_cypher(cypher)\n\n    # Analyze migration risk\n    risk_query = f\"What are the migration risks for {service_name}?\"\n    risks = await retriever.hybrid_search(\n        query=risk_query,\n        strategy=\"adaptive\",\n        limit=10\n    )\n\n    return {\n        \"service\": service_name,\n        \"dependencies\": deps,\n        \"risks\": risks\n    }\n\n# Example usage\nservice = \"BillingSystem\"\nrisk_analysis = asyncio.run(analyze_migration_risk(service))\n</code></pre>"},{"location":"usecase-migration/#performance-metrics","title":"Performance Metrics","text":""},{"location":"usecase-migration/#actual-achievable-performance","title":"Actual Achievable Performance","text":"<ul> <li>Dependency analysis: 2-5 seconds</li> <li>Migration plan generation: 5-10 seconds (using RAG)</li> <li>Risk assessment: 3-5 seconds</li> <li>Configuration generation: 3-7 seconds</li> <li>Graph traversal: 100-500ms per query</li> </ul>"},{"location":"usecase-migration/#migration-success-metrics","title":"Migration Success Metrics","text":"<ul> <li>Dependency mapping accuracy: 85-90%</li> <li>Risk identification: 70-80%</li> <li>Configuration generation accuracy: 75-85%</li> <li>Migration sequence optimization: 70-75%</li> </ul>"},{"location":"usecase-migration/#commands-reference-only-valid-commands","title":"Commands Reference (Only Valid Commands)","text":"<pre><code># Essential migration planning commands that actually work\nnetintel-ocr kg init                          # Initialize KG system\nnetintel-ocr kg process document.pdf          # Process migration docs\nnetintel-ocr kg query \"[Cypher]\"             # Query dependencies\nnetintel-ocr kg path-find \"[from]\" \"[to]\"    # Trace dependencies\nnetintel-ocr kg find-similar \"[service]\"     # Find similar services\nnetintel-ocr kg cluster                      # Group services for waves\nnetintel-ocr kg rag-query \"[question]\"       # Generate plans/configs\nnetintel-ocr kg hybrid-search \"[criteria]\"   # Search for information\nnetintel-ocr kg similarity \"[A]\" \"[B]\"       # Compare architectures\nnetintel-ocr kg train-embeddings             # Learn patterns\nnetintel-ocr kg visualize                    # Visualize complexity\nnetintel-ocr kg export --format json         # Export migration data\nnetintel-ocr kg batch-query queries.txt      # Batch risk analysis\n</code></pre>"},{"location":"vector-search/","title":"Vector Search Guide","text":""},{"location":"vector-search/#overview","title":"Overview","text":"<p>NetIntel-OCR integrates with Milvus to enable semantic search across processed documents, network components, and architectural patterns.</p>"},{"location":"vector-search/#milvus-setup","title":"Milvus Setup","text":""},{"location":"vector-search/#docker-installation","title":"Docker Installation","text":"<pre><code># Start Milvus standalone\ndocker run -d \\\n  --name milvus-standalone \\\n  -p 19530:19530 \\\n  -p 9091:9091 \\\n  -v milvus_data:/var/lib/milvus \\\n  milvusdb/milvus:latest \\\n  milvus run standalone\n</code></pre>"},{"location":"vector-search/#kubernetes-installation","title":"Kubernetes Installation","text":"<pre><code># Install with Helm\nhelm repo add milvus https://milvus-io.github.io/milvus-helm/\nhelm install milvus milvus/milvus --set cluster.enabled=false\n</code></pre>"},{"location":"vector-search/#document-ingestion","title":"Document Ingestion","text":""},{"location":"vector-search/#basic-ingestion","title":"Basic Ingestion","text":"<pre><code># Process and ingest document\nnetintel-ocr db set-store milvus \\\n             --milvus-host localhost:19530 \\\n             --ingest \\\n             document.pdf\n</code></pre>"},{"location":"vector-search/#batch-ingestion","title":"Batch Ingestion","text":"<pre><code># Ingest multiple documents\nfor pdf in *.pdf; do\n  netintel-ocr process batch --ingest --collection network-docs \"$pdf\"\ndone\n\n# Or use batch mode\nnetintel-ocr process batch --collection network-docs *.pdf\n</code></pre>"},{"location":"vector-search/#collection-configuration","title":"Collection Configuration","text":"<pre><code># Define collection schema\nfrom netintel_ocr.vector import create_collection\n\ncreate_collection(\n    name=\"network_components\",\n    dim=768,  # Embedding dimension\n    fields={\n        \"component_type\": \"VARCHAR\",\n        \"security_zone\": \"VARCHAR\", \n        \"criticality\": \"INT32\",\n        \"document_id\": \"VARCHAR\",\n        \"page_number\": \"INT32\"\n    }\n)\n</code></pre>"},{"location":"vector-search/#embedding-generation","title":"Embedding Generation","text":""},{"location":"vector-search/#component-embeddings","title":"Component Embeddings","text":"<p>Documents are processed into multiple embedding types:</p> <pre><code># Generated embeddings\nembeddings = {\n    \"document\": [...],      # Full document embedding\n    \"pages\": [...],        # Per-page embeddings\n    \"components\": [...],   # Network component embeddings\n    \"relationships\": [...] # Connection embeddings\n}\n</code></pre>"},{"location":"vector-search/#custom-embedding-model","title":"Custom Embedding Model","text":"<pre><code># Use specific embedding model\nnetintel-ocr config set embedding.model all-MiniLM-L6-v2 \\\n             --ingest document.pdf\n\n# Or use Ollama embeddings\nnetintel-ocr config set embedding.model ollama/nomic-embed-text \\\n             --ingest document.pdf\n</code></pre>"},{"location":"vector-search/#search-queries","title":"Search Queries","text":""},{"location":"vector-search/#cli-search","title":"CLI Search","text":"<pre><code># Search for components\nnetintel-ocr db search \"firewall in DMZ zone\"\n\n# Search with filters\nnetintel-ocr db search \"router\" \\\n             --filter \"security_zone=external\" \\\n             --limit 10\n</code></pre>"},{"location":"vector-search/#python-api","title":"Python API","text":"<pre><code>from netintel_ocr.vector import VectorSearch\n\nsearch = VectorSearch(host=\"localhost:19530\")\n\n# Semantic search\nresults = search.query(\n    text=\"Find all components with internet exposure\",\n    collection=\"network_components\",\n    limit=20\n)\n\n# Filtered search\nresults = search.query(\n    text=\"database servers\",\n    filter=\"criticality &gt;= 8\",\n    limit=10\n)\n\n# Component relationship search\nconnections = search.find_connections(\n    source=\"web_server\",\n    max_hops=3\n)\n</code></pre>"},{"location":"vector-search/#rest-api","title":"REST API","text":"<pre><code># Search endpoint\ncurl -X POST http://localhost:8000/search \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"firewall configurations\",\n    \"collection\": \"network_docs\",\n    \"limit\": 10,\n    \"filter\": {\n      \"document_type\": \"security\"\n    }\n  }'\n</code></pre>"},{"location":"vector-search/#query-examples","title":"Query Examples","text":""},{"location":"vector-search/#find-similar-network-architectures","title":"Find Similar Network Architectures","text":"<pre><code># Upload reference architecture\nreference = process_diagram(\"reference_architecture.png\")\n\n# Find similar architectures\nsimilar = search.find_similar(\n    embedding=reference.embedding,\n    threshold=0.85,\n    limit=5\n)\n</code></pre>"},{"location":"vector-search/#security-zone-analysis","title":"Security Zone Analysis","text":"<pre><code># Find all components in DMZ\ndmz_components = search.query(\n    filter=\"security_zone='DMZ'\",\n    include_metadata=True\n)\n\n# Find cross-zone connections\ncross_zone = search.query(\n    text=\"connections between internal and external zones\",\n    include_relationships=True\n)\n</code></pre>"},{"location":"vector-search/#compliance-queries","title":"Compliance Queries","text":"<pre><code># Find exposed services\nexposed = search.query(\n    text=\"services accessible from internet\",\n    filter=\"exposure='external'\"\n)\n\n# Find unencrypted connections\nunencrypted = search.query(\n    text=\"connections without encryption\",\n    filter=\"encrypted=false\"\n)\n</code></pre>"},{"location":"vector-search/#index-management","title":"Index Management","text":""},{"location":"vector-search/#create-indexes","title":"Create Indexes","text":"<pre><code>from netintel_ocr.vector import IndexManager\n\nindex = IndexManager()\n\n# Create IVF index for large collections\nindex.create_index(\n    collection=\"network_components\",\n    index_type=\"IVF_FLAT\",\n    metric_type=\"L2\",\n    params={\"nlist\": 1024}\n)\n\n# Create HNSW index for high accuracy\nindex.create_index(\n    collection=\"critical_components\",\n    index_type=\"HNSW\",\n    params={\"M\": 16, \"efConstruction\": 200}\n)\n</code></pre>"},{"location":"vector-search/#optimize-performance","title":"Optimize Performance","text":"<pre><code># Compact collection\nnetintel-ocr db compact network_components\n\n# Build index\nnetintel-ocr db build-index network_components\n\n# Load collection to memory\nnetintel-ocr db load network_components\n</code></pre>"},{"location":"vector-search/#integration-examples","title":"Integration Examples","text":""},{"location":"vector-search/#cmdb-population","title":"CMDB Population","text":"<pre><code>from netintel_ocr import DocumentProcessor\nfrom cmdb_client import CMDBClient\n\n# Process document\nprocessor = DocumentProcessor()\nresults = processor.process(\"network_design.pdf\")\n\n# Populate CMDB\ncmdb = CMDBClient()\nfor component in results.components:\n    cmdb.create_ci({\n        \"name\": component.name,\n        \"type\": component.type,\n        \"attributes\": component.metadata,\n        \"relationships\": component.connections\n    })\n</code></pre>"},{"location":"vector-search/#change-detection","title":"Change Detection","text":"<pre><code># Compare document versions\nold_doc = search.get_document(\"design_v1.pdf\")\nnew_doc = process_document(\"design_v2.pdf\")\n\n# Find changes\nchanges = search.compare_architectures(\n    old_doc.embedding,\n    new_doc.embedding\n)\n\nprint(f\"Added components: {changes.added}\")\nprint(f\"Removed components: {changes.removed}\")\nprint(f\"Modified connections: {changes.modified}\")\n</code></pre>"},{"location":"vector-search/#knowledge-graph","title":"Knowledge Graph","text":"<pre><code># Build knowledge graph\nfrom netintel_ocr.graph import KnowledgeGraph\n\nkg = KnowledgeGraph()\n\n# Add documents to graph\nfor doc in documents:\n    kg.add_document(doc)\n\n# Query relationships\npaths = kg.find_path(\n    from_component=\"internet_gateway\",\n    to_component=\"database_server\"\n)\n\n# Find critical paths\ncritical = kg.find_critical_paths(\n    metric=\"security_exposure\"\n)\n</code></pre>"},{"location":"vector-search/#monitoring","title":"Monitoring","text":""},{"location":"vector-search/#collection-statistics","title":"Collection Statistics","text":"<pre><code># View collection stats\nnetintel-ocr db stats --collection network_components\n\n# Monitor query performance\nnetintel-ocr db query-stats --last 24h\n</code></pre>"},{"location":"vector-search/#health-checks","title":"Health Checks","text":"<pre><code># Check Milvus health\nfrom netintel_ocr.vector import health_check\n\nstatus = health_check()\nprint(f\"Milvus status: {status.state}\")\nprint(f\"Collections: {status.collections}\")\nprint(f\"Total vectors: {status.total_vectors}\")\n</code></pre>"},{"location":"vector-search/#best-practices","title":"Best Practices","text":"<ol> <li>Collection Partitioning: Partition by document type or date</li> <li>Embedding Cache: Cache frequently accessed embeddings</li> <li>Batch Operations: Use batch insert for large datasets</li> <li>Index Selection: Choose index based on dataset size</li> <li>Regular Compaction: Compact collections weekly</li> </ol>"},{"location":"vector-search/#next-steps","title":"Next Steps","text":"<ul> <li>Customization Guide - Tune extraction and embeddings</li> <li>Deployment Guide - Production Milvus setup</li> <li>Quick Start Guide - Basic usage examples</li> </ul>"}]}